{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE247_CNN-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lpm1onbvmTh7"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Conv1D, MaxPooling1D\n",
        "from keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten,Dropout\n",
        "from keras.layers import Conv2D,BatchNormalization,MaxPooling2D,Reshape\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, TimeDistributed, BatchNormalization, Flatten, Activation"
      ],
      "metadata": {
        "id": "NiZZ2Aq9meeT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive/\")\n",
        "%cd '/content/drive/MyDrive/ECE247/project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYvZ7aS6mm8t",
        "outputId": "290a4093-f56d-436d-d335-744c49439b3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/ECE247/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JoEnvdgYnFat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "7WMc7h_5nKqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading and visualizing the data\n",
        "\n",
        "## Loading the dataset\n",
        "\n",
        "\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Printing the shapes of the numpy arrays\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF6LFCMinLx9",
        "outputId": "ac755bbb-58d8-4c26-f166-75df03cf4bc1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "print(y_train_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hWFwAjRnNAm",
        "outputId": "76abeb01-1813-4438-fcba-f35924c5c0cc"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 0 ... 3 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing the data\n",
        "\n",
        "ch_data = X_train_valid[:,8,:]\n",
        "\n",
        "\n",
        "class_0_ind = np.where(y_train_valid == 0)\n",
        "ch_data_class_0 = ch_data[class_0_ind]\n",
        "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n",
        "\n",
        "\n",
        "class_1_ind = np.where(y_train_valid == 1)\n",
        "ch_data_class_1 = ch_data[class_1_ind]\n",
        "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
        "\n",
        "class_2_ind = np.where(y_train_valid == 2)\n",
        "ch_data_class_2 = ch_data[class_2_ind]\n",
        "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
        "\n",
        "class_3_ind = np.where(y_train_valid == 3)\n",
        "ch_data_class_3 = ch_data[class_3_ind]\n",
        "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
        "\n",
        "\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
        "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
        "\n",
        "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "c8SETT3ZnOzt",
        "outputId": "442e0eea-8318-42ba-8e39-6395c61d4087"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46a9a34f50>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(X,y,sub_sample,average,noise):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n",
        "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qppjvN1oiXz",
        "outputId": "f28854bd-0f80-4200-d8e9-185d65331174"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (2115, 22, 500)\n",
            "Shape of X after maxpooling: (2115, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Preprocessing the dataset\n",
        "\n",
        "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n",
        "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
        "\n",
        "print(X_train_valid_prep.shape)\n",
        "print(y_train_valid_prep.shape)\n",
        "print(X_test_prep.shape)\n",
        "print(y_test_prep.shape)\n",
        "\n",
        "\n",
        "\n",
        "## Random splitting and reshaping the data\n",
        "\n",
        "# First generating the training and validation indices using random splitting\n",
        "ind_valid = np.random.choice(8460, 1500, replace=False)\n",
        "ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n",
        "\n",
        "# Creating the training and validation sets using the generated indices\n",
        "(x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
        "(y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
        "print('Shape of training set:',x_train.shape)\n",
        "print('Shape of validation set:',x_valid.shape)\n",
        "print('Shape of training labels:',y_train.shape)\n",
        "print('Shape of validation labels:',y_valid.shape)\n",
        "\n",
        "\n",
        "# Converting the labels to categorical variables for multiclass classification\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 4)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 4)\n",
        "y_test = tf.keras.utils.to_categorical(y_test_prep, 4)\n",
        "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "# Adding width of the segment to be 1\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "print('Shape of training set after adding width info:',x_train.shape)\n",
        "print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "\n",
        "# Reshaping the training and validation dataset\n",
        "x_train = np.swapaxes(x_train, 1,3)\n",
        "x_train = np.swapaxes(x_train, 1,2)\n",
        "x_valid = np.swapaxes(x_valid, 1,3)\n",
        "x_valid = np.swapaxes(x_valid, 1,2)\n",
        "x_test = np.swapaxes(x_test, 1,3)\n",
        "x_test = np.swapaxes(x_test, 1,2)\n",
        "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L64siY6LqBnT",
        "outputId": "be1d8411-6766-460e-e721-f59754314ef4"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (2115, 22, 500)\n",
            "Shape of X after maxpooling: (2115, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (8460, 22, 250)\n",
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after maxpooling: (443, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
            "(8460, 22, 250)\n",
            "(8460,)\n",
            "(1772, 22, 250)\n",
            "(1772,)\n",
            "Shape of training set: (6960, 22, 250)\n",
            "Shape of validation set: (1500, 22, 250)\n",
            "Shape of training labels: (6960,)\n",
            "Shape of validation labels: (1500,)\n",
            "Shape of training labels after categorical conversion: (6960, 4)\n",
            "Shape of validation labels after categorical conversion: (1500, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
            "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
            "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "FL2qiS5LrPxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5t69Lxn5o3-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "#1\n",
        "model.add(LSTM(200, return_sequences=True, stateful=False,\n",
        "          recurrent_dropout=0.6, dropout = 0.6, input_shape=(250, 22)))\n",
        "\n",
        "# #2\n",
        "# model.add(LSTM(100, return_sequences=True, stateful=False,\n",
        "#           recurrent_dropout=0.5, dropout = 0.5))\n",
        "\n",
        "#3\n",
        "model.add(LSTM(50, return_sequences=True, stateful=False,\n",
        "          recurrent_dropout=0.4, dropout = 0.4))\n",
        "model.add(Flatten())\n",
        "\n",
        "#4\n",
        "model.add(Dense(100))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#5\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4ZmsqPRyliz",
        "outputId": "325454e9-db15-4a06-aefc-92be45d737a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "learning_rate = 1e-3\n",
        "epochs = 40\n",
        "cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "audfl-nu0Q8n",
        "outputId": "0f298d79-27d6-4f34-f88f-5ed176ba95ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model parameters\n",
        "learning_rate = 1e-3\n",
        "epochs = 40\n",
        "cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Training and validating the model\n",
        "basic_cnn_model_results = model.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=64,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_valid, y_valid), verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR3jLkgE0ezu",
        "outputId": "19edf25a-ba2d-40e4-9e52-ddbb40277f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "109/109 [==============================] - 270s 2s/step - loss: 1.4291 - accuracy: 0.4389 - val_loss: 1.6241 - val_accuracy: 0.4233\n",
            "Epoch 2/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 1.0119 - accuracy: 0.5842 - val_loss: 1.6287 - val_accuracy: 0.4087\n",
            "Epoch 3/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.8463 - accuracy: 0.6575 - val_loss: 1.1693 - val_accuracy: 0.5240\n",
            "Epoch 4/40\n",
            "109/109 [==============================] - 254s 2s/step - loss: 0.7351 - accuracy: 0.7105 - val_loss: 0.6985 - val_accuracy: 0.7220\n",
            "Epoch 5/40\n",
            "109/109 [==============================] - 254s 2s/step - loss: 0.6341 - accuracy: 0.7555 - val_loss: 0.6366 - val_accuracy: 0.7460\n",
            "Epoch 6/40\n",
            "109/109 [==============================] - 255s 2s/step - loss: 0.5424 - accuracy: 0.7951 - val_loss: 0.5994 - val_accuracy: 0.7593\n",
            "Epoch 7/40\n",
            "109/109 [==============================] - 255s 2s/step - loss: 0.4656 - accuracy: 0.8306 - val_loss: 0.6467 - val_accuracy: 0.7427\n",
            "Epoch 8/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.4055 - accuracy: 0.8566 - val_loss: 0.3865 - val_accuracy: 0.8647\n",
            "Epoch 9/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.3400 - accuracy: 0.8813 - val_loss: 0.3092 - val_accuracy: 0.8907\n",
            "Epoch 10/40\n",
            "109/109 [==============================] - 257s 2s/step - loss: 0.2943 - accuracy: 0.8967 - val_loss: 0.4061 - val_accuracy: 0.8440\n",
            "Epoch 11/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.2549 - accuracy: 0.9149 - val_loss: 0.3116 - val_accuracy: 0.8760\n",
            "Epoch 12/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.2190 - accuracy: 0.9300 - val_loss: 0.1806 - val_accuracy: 0.9367\n",
            "Epoch 13/40\n",
            "109/109 [==============================] - 270s 2s/step - loss: 0.1940 - accuracy: 0.9316 - val_loss: 0.3395 - val_accuracy: 0.8693\n",
            "Epoch 14/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.1748 - accuracy: 0.9444 - val_loss: 0.0954 - val_accuracy: 0.9740\n",
            "Epoch 15/40\n",
            "109/109 [==============================] - 262s 2s/step - loss: 0.1454 - accuracy: 0.9532 - val_loss: 0.1907 - val_accuracy: 0.9287\n",
            "Epoch 16/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 0.1405 - accuracy: 0.9553 - val_loss: 0.1685 - val_accuracy: 0.9373\n",
            "Epoch 17/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.1157 - accuracy: 0.9657 - val_loss: 0.1115 - val_accuracy: 0.9587\n",
            "Epoch 18/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.1152 - accuracy: 0.9585 - val_loss: 0.0779 - val_accuracy: 0.9753\n",
            "Epoch 19/40\n",
            "109/109 [==============================] - 262s 2s/step - loss: 0.1070 - accuracy: 0.9661 - val_loss: 0.1549 - val_accuracy: 0.9427\n",
            "Epoch 20/40\n",
            "109/109 [==============================] - 262s 2s/step - loss: 0.0946 - accuracy: 0.9700 - val_loss: 0.0703 - val_accuracy: 0.9807\n",
            "Epoch 21/40\n",
            "109/109 [==============================] - 257s 2s/step - loss: 0.0863 - accuracy: 0.9736 - val_loss: 0.1206 - val_accuracy: 0.9593\n",
            "Epoch 22/40\n",
            "109/109 [==============================] - 258s 2s/step - loss: 0.0953 - accuracy: 0.9681 - val_loss: 0.1322 - val_accuracy: 0.9553\n",
            "Epoch 23/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.0904 - accuracy: 0.9711 - val_loss: 0.0997 - val_accuracy: 0.9633\n",
            "Epoch 24/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 0.0809 - accuracy: 0.9740 - val_loss: 0.0759 - val_accuracy: 0.9747\n",
            "Epoch 25/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 0.0663 - accuracy: 0.9786 - val_loss: 0.0421 - val_accuracy: 0.9867\n",
            "Epoch 26/40\n",
            "109/109 [==============================] - 262s 2s/step - loss: 0.0759 - accuracy: 0.9764 - val_loss: 0.1033 - val_accuracy: 0.9640\n",
            "Epoch 27/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.0306 - val_accuracy: 0.9920\n",
            "Epoch 28/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.0696 - accuracy: 0.9769 - val_loss: 0.0628 - val_accuracy: 0.9780\n",
            "Epoch 29/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 0.0768 - accuracy: 0.9737 - val_loss: 0.0352 - val_accuracy: 0.9860\n",
            "Epoch 30/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.0489 - val_accuracy: 0.9827\n",
            "Epoch 31/40\n",
            "109/109 [==============================] - 261s 2s/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.0885 - val_accuracy: 0.9733\n",
            "Epoch 32/40\n",
            "109/109 [==============================] - 257s 2s/step - loss: 0.0570 - accuracy: 0.9818 - val_loss: 0.0254 - val_accuracy: 0.9913\n",
            "Epoch 33/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.0799 - val_accuracy: 0.9733\n",
            "Epoch 34/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.0563 - accuracy: 0.9813 - val_loss: 0.0283 - val_accuracy: 0.9913\n",
            "Epoch 35/40\n",
            "109/109 [==============================] - 257s 2s/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.0198 - val_accuracy: 0.9933\n",
            "Epoch 36/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
            "Epoch 37/40\n",
            "109/109 [==============================] - 256s 2s/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.0403 - val_accuracy: 0.9833\n",
            "Epoch 38/40\n",
            "109/109 [==============================] - 259s 2s/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.0305 - val_accuracy: 0.9887\n",
            "Epoch 39/40\n",
            "109/109 [==============================] - 260s 2s/step - loss: 0.0622 - accuracy: 0.9786 - val_loss: 0.0528 - val_accuracy: 0.9820\n",
            "Epoch 40/40\n",
            "109/109 [==============================] - 257s 2s/step - loss: 0.0455 - accuracy: 0.9846 - val_loss: 0.0188 - val_accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting accuracy trajectory\n",
        "plt.plot(basic_cnn_model_results.history['accuracy'])\n",
        "plt.plot(basic_cnn_model_results.history['val_accuracy'])\n",
        "plt.title('Basic CNN model accuracy trajectory')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plotting loss trajectory\n",
        "plt.plot(basic_cnn_model_results.history['loss'],'o')\n",
        "plt.plot(basic_cnn_model_results.history['val_loss'],'o')\n",
        "plt.title('Basic CNN model loss trajectory')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "iQ3ivMXy0nuq",
        "outputId": "5078419e-31c3-412c-c3b2-95e4ab1d38a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing the basic CNN model\n",
        "\n",
        "cnn_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy of the basic CNN model:',cnn_score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ANBQ_-l1YFb",
        "outputId": "cc7f223e-9892-4a61-cc7c-07c4147bca5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the basic CNN model: 0.5141083598136902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3p_ncbfio5gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_test = np.load(\"person_test.npy\")"
      ],
      "metadata": {
        "id": "KRnya1Ebqxmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_test=np.reshape(person_test,(person_test.shape[0],))\n",
        "print(person_test.shape)\n",
        "\n",
        "person_train_valid=np.reshape(person_train_valid,(person_train_valid.shape[0],))\n",
        "print(person_train_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550c65ed-d86f-4d44-8bca-baaa6fbabaa9",
        "id": "_NUAPx1Uqxmt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(443,)\n",
            "(2115,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Preprocessing the dataset\n",
        "\n",
        "_ , person_test_prep = data_prep(X_test,person_test,2,2,True)\n",
        "\n",
        "print(person_test_prep.shape)\n",
        "\n",
        "\n",
        "# person_test = tf.keras.utils.to_categorical(person_test_prep, 9)\n",
        "person_test= person_test_prep\n",
        "\n",
        "print('Shape of test labels:',person_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d89917-7641-46c2-fa2a-acc4662c7f8e",
        "id": "JfkjTQkaqxmt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after maxpooling: (443, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
            "(1772,)\n",
            "Shape of test labels: (1772,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BhpL_bxtqxmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):    \n",
        "  score_person = model.evaluate(x_test[person_test.T==i], y_test[person_test.T==i], verbose=0)  \n",
        "  print(\"Test accuracy person \" + str(i) +  \" \" + str(score_person[1]))        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a889c001-bbca-41b0-d52e-fd213f781481",
        "id": "qn_lNcIaqxmu"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy person 0 0.3799999713897705\n",
            "Test accuracy person 1 0.3799999713897705\n",
            "Test accuracy person 2 0.6249999761581421\n",
            "Test accuracy person 3 0.49499998092651365\n",
            "Test accuracy person 4 0.5627659320831299\n",
            "Test accuracy person 5 0.5438775777816772\n",
            "Test accuracy person 6 0.5700000286102295\n",
            "Test accuracy person 7 0.49499998092651365\n",
            "Test accuracy person 8 0.6106382966041565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN-LSTM"
      ],
      "metadata": {
        "id": "w2d9r23yrMyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_lr=[]\n",
        "learning= [0.00073]\n",
        "for learning_rate in learning:\n",
        "      # Building the CNN model using sequential class\n",
        "      basic_cnn_model = Sequential()\n",
        "\n",
        "      # Conv. block 1\n",
        "      basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(250,1,22)))\n",
        "      basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
        "      basic_cnn_model.add(BatchNormalization())\n",
        "      basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "      # Conv. block 2\n",
        "      basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "      basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "      basic_cnn_model.add(BatchNormalization())\n",
        "      basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "      # Conv. block 3\n",
        "      basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "      basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "      basic_cnn_model.add(BatchNormalization())\n",
        "      basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "      # Conv. block 4\n",
        "      basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "      basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "      basic_cnn_model.add(BatchNormalization())\n",
        "      basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "\n",
        "      # Output layer with Softmax activation\n",
        "      basic_cnn_model.add(Flatten()) # Flattens the input\n",
        "\n",
        "      basic_cnn_model.add(tf.keras.layers.Dense((100)))\n",
        "      basic_cnn_model.add(tf.keras.layers.Reshape((100,1)))\n",
        "      basic_cnn_model.add(tf.keras.layers.LSTM(20, dropout=0.6, recurrent_dropout= 0.15, input_shape=(100,1), return_sequences=False))\n",
        "      basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "      basic_cnn_model.summary()\n",
        "\n",
        "\n",
        "      # Model parameters\n",
        "      learning_rate =  learning_rate\n",
        "      epochs = 95\n",
        "      cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "      # Compiling the model\n",
        "      basic_cnn_model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=cnn_optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "      # Training and validating the model\n",
        "      basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
        "                  y_train,\n",
        "                  batch_size=64,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_valid, y_valid), verbose=True)\n",
        "      \n",
        "      \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnw95WEqG4C",
        "outputId": "bdbde0d9-9fc0-4e4e-ff2b-9c63899c8c31"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_84 (Conv2D)          (None, 250, 1, 25)        5525      \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 84, 1, 25)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 84, 1, 25)        100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 84, 1, 25)         0         \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 84, 1, 50)         12550     \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 28, 1, 50)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 28, 1, 50)        200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 28, 1, 50)         0         \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 28, 1, 100)        50100     \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 10, 1, 100)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_86 (Bat  (None, 10, 1, 100)       400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 10, 1, 100)        0         \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 10, 1, 200)        200200    \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 4, 1, 200)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 4, 1, 200)        800       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 4, 1, 200)         0         \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 800)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 100)               80100     \n",
            "                                                                 \n",
            " reshape_21 (Reshape)        (None, 100, 1)            0         \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 20)                1760      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,819\n",
            "Trainable params: 351,069\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/95\n",
            "109/109 [==============================] - 4s 17ms/step - loss: 1.3749 - accuracy: 0.2810 - val_loss: 1.3477 - val_accuracy: 0.3547\n",
            "Epoch 2/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.3267 - accuracy: 0.3588 - val_loss: 1.2981 - val_accuracy: 0.3980\n",
            "Epoch 3/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.2810 - accuracy: 0.3968 - val_loss: 1.2205 - val_accuracy: 0.4667\n",
            "Epoch 4/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.2456 - accuracy: 0.4216 - val_loss: 1.2005 - val_accuracy: 0.4787\n",
            "Epoch 5/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.2224 - accuracy: 0.4339 - val_loss: 1.2114 - val_accuracy: 0.4727\n",
            "Epoch 6/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1935 - accuracy: 0.4572 - val_loss: 1.1990 - val_accuracy: 0.4613\n",
            "Epoch 7/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1778 - accuracy: 0.4573 - val_loss: 1.1918 - val_accuracy: 0.4393\n",
            "Epoch 8/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1607 - accuracy: 0.4721 - val_loss: 1.2040 - val_accuracy: 0.4413\n",
            "Epoch 9/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1347 - accuracy: 0.4820 - val_loss: 1.2041 - val_accuracy: 0.4547\n",
            "Epoch 10/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1295 - accuracy: 0.4927 - val_loss: 1.1717 - val_accuracy: 0.4200\n",
            "Epoch 11/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1207 - accuracy: 0.4892 - val_loss: 1.1784 - val_accuracy: 0.4233\n",
            "Epoch 12/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.1009 - accuracy: 0.5079 - val_loss: 1.1419 - val_accuracy: 0.4593\n",
            "Epoch 13/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0984 - accuracy: 0.5085 - val_loss: 1.2069 - val_accuracy: 0.4787\n",
            "Epoch 14/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0828 - accuracy: 0.5177 - val_loss: 1.1911 - val_accuracy: 0.4600\n",
            "Epoch 15/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0724 - accuracy: 0.5170 - val_loss: 1.1553 - val_accuracy: 0.4887\n",
            "Epoch 16/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0676 - accuracy: 0.5207 - val_loss: 1.1185 - val_accuracy: 0.5133\n",
            "Epoch 17/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0529 - accuracy: 0.5290 - val_loss: 1.1412 - val_accuracy: 0.4753\n",
            "Epoch 18/95\n",
            "109/109 [==============================] - 1s 13ms/step - loss: 1.0369 - accuracy: 0.5338 - val_loss: 1.1743 - val_accuracy: 0.4640\n",
            "Epoch 19/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0330 - accuracy: 0.5478 - val_loss: 1.1129 - val_accuracy: 0.5333\n",
            "Epoch 20/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0276 - accuracy: 0.5424 - val_loss: 1.1428 - val_accuracy: 0.5240\n",
            "Epoch 21/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0235 - accuracy: 0.5431 - val_loss: 1.1674 - val_accuracy: 0.5187\n",
            "Epoch 22/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 1.0083 - accuracy: 0.5536 - val_loss: 1.1356 - val_accuracy: 0.5140\n",
            "Epoch 23/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9884 - accuracy: 0.5787 - val_loss: 1.1461 - val_accuracy: 0.5100\n",
            "Epoch 24/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9905 - accuracy: 0.5697 - val_loss: 1.0916 - val_accuracy: 0.5613\n",
            "Epoch 25/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9933 - accuracy: 0.5664 - val_loss: 1.1197 - val_accuracy: 0.5447\n",
            "Epoch 26/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9688 - accuracy: 0.5830 - val_loss: 1.1087 - val_accuracy: 0.5367\n",
            "Epoch 27/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9568 - accuracy: 0.5993 - val_loss: 1.1012 - val_accuracy: 0.5100\n",
            "Epoch 28/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9552 - accuracy: 0.5907 - val_loss: 1.0687 - val_accuracy: 0.5873\n",
            "Epoch 29/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9558 - accuracy: 0.5872 - val_loss: 1.0964 - val_accuracy: 0.5460\n",
            "Epoch 30/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9382 - accuracy: 0.5968 - val_loss: 1.0721 - val_accuracy: 0.5653\n",
            "Epoch 31/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9300 - accuracy: 0.6101 - val_loss: 1.1280 - val_accuracy: 0.5033\n",
            "Epoch 32/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9145 - accuracy: 0.6135 - val_loss: 1.0848 - val_accuracy: 0.5253\n",
            "Epoch 33/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9211 - accuracy: 0.6030 - val_loss: 1.0527 - val_accuracy: 0.5600\n",
            "Epoch 34/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9063 - accuracy: 0.6230 - val_loss: 1.0785 - val_accuracy: 0.5120\n",
            "Epoch 35/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.9090 - accuracy: 0.6162 - val_loss: 1.0396 - val_accuracy: 0.5580\n",
            "Epoch 36/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8937 - accuracy: 0.6299 - val_loss: 1.0722 - val_accuracy: 0.5167\n",
            "Epoch 37/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8824 - accuracy: 0.6336 - val_loss: 1.0273 - val_accuracy: 0.5573\n",
            "Epoch 38/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8633 - accuracy: 0.6453 - val_loss: 1.0124 - val_accuracy: 0.5567\n",
            "Epoch 39/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8783 - accuracy: 0.6388 - val_loss: 0.9945 - val_accuracy: 0.6167\n",
            "Epoch 40/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8567 - accuracy: 0.6506 - val_loss: 0.9811 - val_accuracy: 0.5940\n",
            "Epoch 41/95\n",
            "109/109 [==============================] - 1s 12ms/step - loss: 0.8479 - accuracy: 0.6556 - val_loss: 0.9370 - val_accuracy: 0.6653\n",
            "Epoch 42/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8313 - accuracy: 0.6634 - val_loss: 0.9771 - val_accuracy: 0.5993\n",
            "Epoch 43/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8152 - accuracy: 0.6746 - val_loss: 0.9282 - val_accuracy: 0.6400\n",
            "Epoch 44/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.8078 - accuracy: 0.6761 - val_loss: 0.8911 - val_accuracy: 0.7093\n",
            "Epoch 45/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7838 - accuracy: 0.6918 - val_loss: 0.8854 - val_accuracy: 0.7220\n",
            "Epoch 46/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7774 - accuracy: 0.6958 - val_loss: 0.8806 - val_accuracy: 0.6920\n",
            "Epoch 47/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7713 - accuracy: 0.7026 - val_loss: 0.8256 - val_accuracy: 0.7673\n",
            "Epoch 48/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7602 - accuracy: 0.7063 - val_loss: 0.8629 - val_accuracy: 0.7447\n",
            "Epoch 49/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7547 - accuracy: 0.7029 - val_loss: 0.8223 - val_accuracy: 0.7673\n",
            "Epoch 50/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7415 - accuracy: 0.7111 - val_loss: 0.8423 - val_accuracy: 0.7580\n",
            "Epoch 51/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7260 - accuracy: 0.7159 - val_loss: 0.8608 - val_accuracy: 0.7200\n",
            "Epoch 52/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7299 - accuracy: 0.7185 - val_loss: 0.8293 - val_accuracy: 0.7507\n",
            "Epoch 53/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7279 - accuracy: 0.7211 - val_loss: 0.8461 - val_accuracy: 0.7587\n",
            "Epoch 54/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7088 - accuracy: 0.7259 - val_loss: 0.8325 - val_accuracy: 0.7773\n",
            "Epoch 55/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7028 - accuracy: 0.7333 - val_loss: 0.8015 - val_accuracy: 0.7860\n",
            "Epoch 56/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.7077 - accuracy: 0.7306 - val_loss: 0.7933 - val_accuracy: 0.7787\n",
            "Epoch 57/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6883 - accuracy: 0.7326 - val_loss: 0.8391 - val_accuracy: 0.7520\n",
            "Epoch 58/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.7320 - val_loss: 0.7891 - val_accuracy: 0.7587\n",
            "Epoch 59/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6878 - accuracy: 0.7353 - val_loss: 0.7954 - val_accuracy: 0.7880\n",
            "Epoch 60/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6783 - accuracy: 0.7399 - val_loss: 0.7673 - val_accuracy: 0.8180\n",
            "Epoch 61/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6570 - accuracy: 0.7527 - val_loss: 0.7455 - val_accuracy: 0.8167\n",
            "Epoch 62/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6641 - accuracy: 0.7440 - val_loss: 0.8009 - val_accuracy: 0.7727\n",
            "Epoch 63/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6589 - accuracy: 0.7480 - val_loss: 0.7131 - val_accuracy: 0.8093\n",
            "Epoch 64/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6615 - accuracy: 0.7402 - val_loss: 0.8004 - val_accuracy: 0.7567\n",
            "Epoch 65/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6600 - accuracy: 0.7461 - val_loss: 0.7787 - val_accuracy: 0.7947\n",
            "Epoch 66/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6314 - accuracy: 0.7589 - val_loss: 0.7117 - val_accuracy: 0.8227\n",
            "Epoch 67/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6437 - accuracy: 0.7562 - val_loss: 0.6813 - val_accuracy: 0.8380\n",
            "Epoch 68/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6360 - accuracy: 0.7509 - val_loss: 0.7009 - val_accuracy: 0.8067\n",
            "Epoch 69/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6412 - accuracy: 0.7570 - val_loss: 0.7321 - val_accuracy: 0.8447\n",
            "Epoch 70/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6126 - accuracy: 0.7664 - val_loss: 0.7011 - val_accuracy: 0.8193\n",
            "Epoch 71/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6241 - accuracy: 0.7625 - val_loss: 0.7000 - val_accuracy: 0.8340\n",
            "Epoch 72/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6161 - accuracy: 0.7609 - val_loss: 0.6732 - val_accuracy: 0.8300\n",
            "Epoch 73/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6130 - accuracy: 0.7698 - val_loss: 0.7056 - val_accuracy: 0.8387\n",
            "Epoch 74/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6206 - accuracy: 0.7654 - val_loss: 0.7063 - val_accuracy: 0.8100\n",
            "Epoch 75/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6115 - accuracy: 0.7665 - val_loss: 0.7180 - val_accuracy: 0.8353\n",
            "Epoch 76/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6019 - accuracy: 0.7747 - val_loss: 0.6742 - val_accuracy: 0.8527\n",
            "Epoch 77/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6082 - accuracy: 0.7695 - val_loss: 0.7178 - val_accuracy: 0.8353\n",
            "Epoch 78/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5906 - accuracy: 0.7774 - val_loss: 0.7019 - val_accuracy: 0.8560\n",
            "Epoch 79/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5943 - accuracy: 0.7782 - val_loss: 0.7203 - val_accuracy: 0.7987\n",
            "Epoch 80/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5814 - accuracy: 0.7838 - val_loss: 0.6664 - val_accuracy: 0.8407\n",
            "Epoch 81/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.6017 - accuracy: 0.7747 - val_loss: 0.7012 - val_accuracy: 0.8100\n",
            "Epoch 82/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5839 - accuracy: 0.7777 - val_loss: 0.6207 - val_accuracy: 0.8660\n",
            "Epoch 83/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5733 - accuracy: 0.7832 - val_loss: 0.6722 - val_accuracy: 0.8420\n",
            "Epoch 84/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5724 - accuracy: 0.7828 - val_loss: 0.6208 - val_accuracy: 0.8700\n",
            "Epoch 85/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5723 - accuracy: 0.7812 - val_loss: 0.6444 - val_accuracy: 0.8633\n",
            "Epoch 86/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5703 - accuracy: 0.7828 - val_loss: 0.6780 - val_accuracy: 0.8620\n",
            "Epoch 87/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5626 - accuracy: 0.7841 - val_loss: 0.6495 - val_accuracy: 0.8653\n",
            "Epoch 88/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5572 - accuracy: 0.7882 - val_loss: 0.6261 - val_accuracy: 0.8793\n",
            "Epoch 89/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5573 - accuracy: 0.7907 - val_loss: 0.6358 - val_accuracy: 0.8773\n",
            "Epoch 90/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5610 - accuracy: 0.7868 - val_loss: 0.6393 - val_accuracy: 0.8887\n",
            "Epoch 91/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5661 - accuracy: 0.7819 - val_loss: 0.5935 - val_accuracy: 0.8220\n",
            "Epoch 92/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5629 - accuracy: 0.7861 - val_loss: 0.6621 - val_accuracy: 0.8073\n",
            "Epoch 93/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5455 - accuracy: 0.7938 - val_loss: 0.6114 - val_accuracy: 0.8493\n",
            "Epoch 94/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5459 - accuracy: 0.7973 - val_loss: 0.6332 - val_accuracy: 0.8687\n",
            "Epoch 95/95\n",
            "109/109 [==============================] - 1s 11ms/step - loss: 0.5377 - accuracy: 0.7974 - val_loss: 0.6296 - val_accuracy: 0.8540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy of the CNN-LSTM model with lr {}:'.format(learning_rate),cnn_score[1])\n",
        "\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EXwJUxCmegH",
        "outputId": "8b0c21e0-059f-4761-9c44-db0fc4035174"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the CNN-LSTM model with lr 0.00073: 0.7270429110527039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JwOAFkWni2Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting accuracy trajectory\n",
        "plt.plot(basic_cnn_model_results.history['accuracy'])\n",
        "plt.plot(basic_cnn_model_results.history['val_accuracy'])\n",
        "plt.title('CNN-LSTM model accuracy trajectory')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plotting loss trajectory\n",
        "plt.plot(basic_cnn_model_results.history['loss'],'o')\n",
        "plt.plot(basic_cnn_model_results.history['val_loss'],'o')\n",
        "plt.title('CNN-LSTM model loss trajectory')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i8z18ihjqUbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "1a93c300-c870-46a4-97a7-8b436d20320a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subject wise evaluation"
      ],
      "metadata": {
        "id": "IqYTrO3Qqhvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_test = np.load(\"person_test.npy\")"
      ],
      "metadata": {
        "id": "VZNDX144vPzl"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_test=np.reshape(person_test,(person_test.shape[0],))\n",
        "print(person_test.shape)\n",
        "\n",
        "person_train_valid=np.reshape(person_train_valid,(person_train_valid.shape[0],))\n",
        "print(person_train_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWb0eKcIrrYa",
        "outputId": "50897002-ca28-4e32-da3a-27db75ab2487"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(443,)\n",
            "(2115,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Preprocessing the dataset\n",
        "\n",
        "_ , person_test_prep = data_prep(X_test,person_test,2,2,True)\n",
        "\n",
        "print(person_test_prep.shape)\n",
        "\n",
        "\n",
        "# person_test = tf.keras.utils.to_categorical(person_test_prep, 9)\n",
        "person_test= person_test_prep\n",
        "\n",
        "print('Shape of test labels:',person_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI1hSVTStpwp",
        "outputId": "222db748-0242-4181-cea9-bc16c34e6583"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after maxpooling: (443, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
            "(1772,)\n",
            "Shape of test labels: (1772,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z4EFMEFVvGUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):    \n",
        "  score_person = basic_cnn_model.evaluate(x_test[person_test.T==i], y_test[person_test.T==i], verbose=0)  \n",
        "  print(\"Test accuracy person \" + str(i) +  \" \" + str(score_person[1]))        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_YQOXswqkdf",
        "outputId": "5427cd99-2ca4-4240-ade4-b38e5006bc10"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy person 0 0.6549999904632569\n",
            "Test accuracy person 1 0.6049999785423279\n",
            "Test accuracy person 2 0.8250000071525574\n",
            "Test accuracy person 3 0.7550000143051148\n",
            "Test accuracy person 4 0.8231914830207825\n",
            "Test accuracy person 5 0.7291836929321289\n",
            "Test accuracy person 6 0.7249999833106995\n",
            "Test accuracy person 7 0.7199999880790711\n",
            "Test accuracy person 8 0.791276593208313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rxM3-f8Uqr6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subject wise training"
      ],
      "metadata": {
        "id": "F5KMA-HOwS4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xGeaAHZyKbcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "y_train_valid[y_train_valid==769] = 0\n",
        "y_train_valid[y_train_valid==770] = 1\n",
        "y_train_valid[y_train_valid==771] = 2\n",
        "y_train_valid[y_train_valid==772] = 3\n",
        "\n",
        "y_test[y_test==769] = 0\n",
        "y_test[y_test==770] = 1\n",
        "y_test[y_test==771] = 2\n",
        "y_test[y_test==772] = 3"
      ],
      "metadata": {
        "id": "FhtAFdk5wWEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "__bz-p8EwouU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_person=[]\n",
        "for idx in range(9):\n",
        "\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    y_train_valid[y_train_valid==769] = 0\n",
        "    y_train_valid[y_train_valid==770] = 1\n",
        "    y_train_valid[y_train_valid==771] = 2\n",
        "    y_train_valid[y_train_valid==772] = 3\n",
        "\n",
        "    y_test[y_test==769] = 0\n",
        "    y_test[y_test==770] = 1\n",
        "    y_test[y_test==771] = 2\n",
        "    y_test[y_test==772] = 3\n",
        "\n",
        "    X_train_valid_sub = X_train_valid[np.where(person_train_valid == idx)[0]]\n",
        "    y_train_valid_sub = y_train_valid[np.where(person_train_valid == idx)[0]]\n",
        "    X_test_sub = X_test[np.where(np.squeeze(person_test) == idx)[0]]\n",
        "    y_test_sub = y_test[np.where(np.squeeze(person_test) == idx)[0]]\n",
        "\n",
        "    X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid_sub,y_train_valid_sub,2,2,True)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test_sub ,y_test_sub,2,2,True)\n",
        "\n",
        "\n",
        "  ## Random splitting and reshaping the data\n",
        "  # First generating the training and validation indices using random splitting\n",
        "    ind_valid = np.random.choice(X_train_valid_sub.shape[0], 50, replace=False)\n",
        "    ind_train = np.array(list(set(range(X_train_valid_sub.shape[0])).difference(set(ind_valid))))\n",
        "  # Creating the training and validation sets using the generated indices\n",
        "    (x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid]\n",
        "    (y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
        "  # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 4)\n",
        "    y_valid = tf.keras.utils.to_categorical(y_valid, 4)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test_prep, 4)\n",
        "  # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "  # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "\n",
        "    # print()\n",
        "\n",
        "    basic_cnn_model = Sequential()\n",
        "\n",
        "    # Conv. block 1\n",
        "    basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(250,1,22)))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 2\n",
        "    basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 3\n",
        "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 4\n",
        "    basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "\n",
        "    # Output layer with Softmax activation\n",
        "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
        "\n",
        "    basic_cnn_model.add(tf.keras.layers.Dense((100)))\n",
        "    basic_cnn_model.add(tf.keras.layers.Reshape((100,1)))\n",
        "    basic_cnn_model.add(tf.keras.layers.LSTM(20, dropout=0.6, input_shape=(100,1), return_sequences=False))\n",
        "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "\n",
        "    # Model parameters\n",
        "    learning_rate =  learning_rate\n",
        "    epochs = 95\n",
        "    cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    # Compiling the model\n",
        "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=cnn_optimizer,\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    # Training and validating the model\n",
        "    basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
        "                y_train,\n",
        "                batch_size=64,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_valid, y_valid), verbose=True)\n",
        "    \n",
        "    cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test accuracy of the CNN-LSTM model for subject {}:'.format(idx),cnn_score[1])\n",
        "\n",
        "    test_score_person.append(cnn_score[1])\n",
        "\n",
        "print(\"Test Accuracy CNN-LSTM on subject wise training:\", test_score_person)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edMraQ1y0rYB",
        "outputId": "1ab097aa-f162-4ca8-eab8-1e1ff1894a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (237, 22, 500)\n",
            "Shape of X after maxpooling: (237, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (474, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (948, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 173ms/step - loss: 2.7392 - accuracy: 0.2567 - val_loss: 4.5688 - val_accuracy: 0.3600\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.4698 - accuracy: 0.3422 - val_loss: 4.3953 - val_accuracy: 0.3200\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.4425 - accuracy: 0.2995 - val_loss: 4.9580 - val_accuracy: 0.2600\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.2127 - accuracy: 0.3369 - val_loss: 5.1980 - val_accuracy: 0.2600\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1065 - accuracy: 0.3904 - val_loss: 4.8528 - val_accuracy: 0.3400\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8594 - accuracy: 0.4011 - val_loss: 4.5037 - val_accuracy: 0.3600\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.9012 - accuracy: 0.4171 - val_loss: 4.2179 - val_accuracy: 0.4000\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.2336 - accuracy: 0.3102 - val_loss: 3.9604 - val_accuracy: 0.3200\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1044 - accuracy: 0.4118 - val_loss: 3.8115 - val_accuracy: 0.3200\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.3042 - accuracy: 0.3476 - val_loss: 3.6714 - val_accuracy: 0.3000\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8557 - accuracy: 0.4171 - val_loss: 3.3594 - val_accuracy: 0.3200\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.9298 - accuracy: 0.4011 - val_loss: 3.1122 - val_accuracy: 0.3600\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8667 - accuracy: 0.4064 - val_loss: 3.0311 - val_accuracy: 0.3200\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.0464 - accuracy: 0.4118 - val_loss: 2.9289 - val_accuracy: 0.3200\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0433 - accuracy: 0.3690 - val_loss: 2.7218 - val_accuracy: 0.3400\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9515 - accuracy: 0.4225 - val_loss: 2.6045 - val_accuracy: 0.3400\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9700 - accuracy: 0.3797 - val_loss: 2.4892 - val_accuracy: 0.3200\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1451 - accuracy: 0.3529 - val_loss: 2.4126 - val_accuracy: 0.3200\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9533 - accuracy: 0.3850 - val_loss: 2.2861 - val_accuracy: 0.3000\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8150 - accuracy: 0.4011 - val_loss: 2.1866 - val_accuracy: 0.3000\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8949 - accuracy: 0.3850 - val_loss: 2.0383 - val_accuracy: 0.3600\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8362 - accuracy: 0.3904 - val_loss: 1.8861 - val_accuracy: 0.4000\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9502 - accuracy: 0.4064 - val_loss: 1.7594 - val_accuracy: 0.4200\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7391 - accuracy: 0.4332 - val_loss: 1.6755 - val_accuracy: 0.4200\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6803 - accuracy: 0.4064 - val_loss: 1.6170 - val_accuracy: 0.4400\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.7627 - accuracy: 0.4064 - val_loss: 1.5777 - val_accuracy: 0.4400\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7565 - accuracy: 0.4439 - val_loss: 1.5484 - val_accuracy: 0.4800\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6808 - accuracy: 0.3797 - val_loss: 1.5371 - val_accuracy: 0.4600\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6264 - accuracy: 0.4920 - val_loss: 1.5490 - val_accuracy: 0.4200\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5737 - accuracy: 0.4332 - val_loss: 1.5423 - val_accuracy: 0.3800\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7646 - accuracy: 0.4011 - val_loss: 1.5066 - val_accuracy: 0.4000\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.5984 - accuracy: 0.4278 - val_loss: 1.4530 - val_accuracy: 0.4400\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6117 - accuracy: 0.4118 - val_loss: 1.4035 - val_accuracy: 0.5000\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7248 - accuracy: 0.4545 - val_loss: 1.3539 - val_accuracy: 0.4800\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.5648 - accuracy: 0.4759 - val_loss: 1.3212 - val_accuracy: 0.4600\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.5835 - accuracy: 0.4225 - val_loss: 1.3015 - val_accuracy: 0.4600\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6602 - accuracy: 0.4278 - val_loss: 1.3040 - val_accuracy: 0.4800\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.5795 - accuracy: 0.4706 - val_loss: 1.3278 - val_accuracy: 0.4800\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6535 - accuracy: 0.4171 - val_loss: 1.3630 - val_accuracy: 0.4600\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.5057 - accuracy: 0.4599 - val_loss: 1.3934 - val_accuracy: 0.4000\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6926 - accuracy: 0.3797 - val_loss: 1.4239 - val_accuracy: 0.4000\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3474 - accuracy: 0.5294 - val_loss: 1.4501 - val_accuracy: 0.4200\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4738 - accuracy: 0.4759 - val_loss: 1.4589 - val_accuracy: 0.3600\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.3397 - accuracy: 0.4920 - val_loss: 1.4572 - val_accuracy: 0.3600\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5478 - accuracy: 0.4011 - val_loss: 1.4591 - val_accuracy: 0.4000\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4976 - accuracy: 0.4973 - val_loss: 1.4521 - val_accuracy: 0.4200\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4789 - accuracy: 0.4866 - val_loss: 1.4647 - val_accuracy: 0.4200\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3901 - accuracy: 0.4225 - val_loss: 1.4878 - val_accuracy: 0.4200\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3827 - accuracy: 0.5187 - val_loss: 1.5076 - val_accuracy: 0.4200\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.4700 - accuracy: 0.4706 - val_loss: 1.5528 - val_accuracy: 0.4000\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3414 - accuracy: 0.5241 - val_loss: 1.5985 - val_accuracy: 0.3800\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3466 - accuracy: 0.5294 - val_loss: 1.6490 - val_accuracy: 0.3200\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3432 - accuracy: 0.4973 - val_loss: 1.7191 - val_accuracy: 0.2600\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3037 - accuracy: 0.4813 - val_loss: 1.7688 - val_accuracy: 0.2600\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2039 - accuracy: 0.5722 - val_loss: 1.8178 - val_accuracy: 0.2800\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3546 - accuracy: 0.4973 - val_loss: 1.8669 - val_accuracy: 0.2400\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2414 - accuracy: 0.5508 - val_loss: 1.8746 - val_accuracy: 0.2600\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2044 - accuracy: 0.5241 - val_loss: 1.8669 - val_accuracy: 0.2600\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2531 - accuracy: 0.5027 - val_loss: 1.8397 - val_accuracy: 0.2800\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1260 - accuracy: 0.5348 - val_loss: 1.8067 - val_accuracy: 0.2800\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1319 - accuracy: 0.5241 - val_loss: 1.7889 - val_accuracy: 0.2800\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.1667 - accuracy: 0.6043 - val_loss: 1.7958 - val_accuracy: 0.2800\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2588 - accuracy: 0.5187 - val_loss: 1.7942 - val_accuracy: 0.2800\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1535 - accuracy: 0.5668 - val_loss: 1.8269 - val_accuracy: 0.2600\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.2805 - accuracy: 0.5080 - val_loss: 1.8849 - val_accuracy: 0.2600\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1882 - accuracy: 0.5508 - val_loss: 1.9771 - val_accuracy: 0.2600\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0592 - accuracy: 0.5989 - val_loss: 2.0784 - val_accuracy: 0.2600\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0073 - accuracy: 0.5989 - val_loss: 2.1523 - val_accuracy: 0.2600\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1044 - accuracy: 0.5882 - val_loss: 2.2442 - val_accuracy: 0.2400\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0365 - accuracy: 0.6043 - val_loss: 2.3000 - val_accuracy: 0.2400\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0639 - accuracy: 0.5722 - val_loss: 2.3515 - val_accuracy: 0.2400\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1629 - accuracy: 0.5561 - val_loss: 2.3890 - val_accuracy: 0.2400\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0366 - accuracy: 0.5936 - val_loss: 2.4484 - val_accuracy: 0.2400\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0631 - accuracy: 0.5561 - val_loss: 2.4585 - val_accuracy: 0.2400\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0930 - accuracy: 0.5775 - val_loss: 2.5138 - val_accuracy: 0.2400\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9354 - accuracy: 0.6471 - val_loss: 2.5348 - val_accuracy: 0.2400\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0984 - accuracy: 0.5561 - val_loss: 2.5253 - val_accuracy: 0.2600\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9789 - accuracy: 0.5722 - val_loss: 2.4791 - val_accuracy: 0.2600\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1046 - accuracy: 0.5829 - val_loss: 2.4866 - val_accuracy: 0.2600\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0315 - accuracy: 0.5561 - val_loss: 2.4602 - val_accuracy: 0.2600\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0925 - accuracy: 0.5348 - val_loss: 2.4412 - val_accuracy: 0.2400\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9423 - accuracy: 0.5829 - val_loss: 2.4392 - val_accuracy: 0.2600\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8716 - accuracy: 0.6364 - val_loss: 2.4594 - val_accuracy: 0.2600\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.9144 - accuracy: 0.6203 - val_loss: 2.5103 - val_accuracy: 0.2600\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8389 - accuracy: 0.6471 - val_loss: 2.5735 - val_accuracy: 0.2600\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9726 - accuracy: 0.6310 - val_loss: 2.6011 - val_accuracy: 0.2600\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.9836 - accuracy: 0.6203 - val_loss: 2.5608 - val_accuracy: 0.2800\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9124 - accuracy: 0.6257 - val_loss: 2.5587 - val_accuracy: 0.2800\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9727 - accuracy: 0.6150 - val_loss: 2.5343 - val_accuracy: 0.2800\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0149 - accuracy: 0.6096 - val_loss: 2.5329 - val_accuracy: 0.2800\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.8398 - accuracy: 0.6738 - val_loss: 2.5004 - val_accuracy: 0.2800\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0903 - accuracy: 0.5936 - val_loss: 2.4506 - val_accuracy: 0.2800\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8321 - accuracy: 0.6578 - val_loss: 2.4314 - val_accuracy: 0.2800\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7938 - accuracy: 0.6524 - val_loss: 2.4473 - val_accuracy: 0.2800\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8123 - accuracy: 0.6417 - val_loss: 2.4398 - val_accuracy: 0.2800\n",
            "Test accuracy of the CNN-LSTM model for subject 0: 0.3149999976158142\n",
            "Shape of X after trimming: (236, 22, 500)\n",
            "Shape of X after maxpooling: (236, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (472, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (944, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 2.7087 - accuracy: 0.2312 - val_loss: 2.1853 - val_accuracy: 0.1600\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.6644 - accuracy: 0.2742 - val_loss: 1.7706 - val_accuracy: 0.2600\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.3549 - accuracy: 0.2742 - val_loss: 2.1353 - val_accuracy: 0.2600\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.4146 - accuracy: 0.2742 - val_loss: 2.2894 - val_accuracy: 0.3600\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.2365 - accuracy: 0.2957 - val_loss: 2.4505 - val_accuracy: 0.3200\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 2.4065 - accuracy: 0.3280 - val_loss: 2.6207 - val_accuracy: 0.3000\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.1042 - accuracy: 0.3280 - val_loss: 2.8647 - val_accuracy: 0.2600\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.2037 - accuracy: 0.2957 - val_loss: 2.8482 - val_accuracy: 0.2600\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.3649 - accuracy: 0.2796 - val_loss: 2.7828 - val_accuracy: 0.2600\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2.5703 - accuracy: 0.2419 - val_loss: 2.8018 - val_accuracy: 0.2600\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9443 - accuracy: 0.3763 - val_loss: 2.4838 - val_accuracy: 0.2600\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.2252 - accuracy: 0.2634 - val_loss: 2.2349 - val_accuracy: 0.2600\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1978 - accuracy: 0.3280 - val_loss: 2.1444 - val_accuracy: 0.2600\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0320 - accuracy: 0.3387 - val_loss: 1.9334 - val_accuracy: 0.2800\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0497 - accuracy: 0.3333 - val_loss: 1.7857 - val_accuracy: 0.3000\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.0308 - accuracy: 0.3065 - val_loss: 1.6507 - val_accuracy: 0.2800\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9382 - accuracy: 0.3763 - val_loss: 1.6705 - val_accuracy: 0.3200\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.0857 - accuracy: 0.3118 - val_loss: 1.7308 - val_accuracy: 0.3000\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2.0276 - accuracy: 0.3925 - val_loss: 1.7579 - val_accuracy: 0.3000\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0071 - accuracy: 0.3065 - val_loss: 1.6883 - val_accuracy: 0.2800\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0737 - accuracy: 0.2688 - val_loss: 1.6238 - val_accuracy: 0.2800\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.0111 - accuracy: 0.3172 - val_loss: 1.5893 - val_accuracy: 0.3000\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8747 - accuracy: 0.3871 - val_loss: 1.5693 - val_accuracy: 0.2800\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.7580 - accuracy: 0.4194 - val_loss: 1.5245 - val_accuracy: 0.2800\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8870 - accuracy: 0.3495 - val_loss: 1.5048 - val_accuracy: 0.3200\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.8620 - accuracy: 0.4032 - val_loss: 1.4913 - val_accuracy: 0.3000\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7695 - accuracy: 0.3925 - val_loss: 1.4894 - val_accuracy: 0.3000\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.8474 - accuracy: 0.4301 - val_loss: 1.5036 - val_accuracy: 0.3600\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.9857 - accuracy: 0.3710 - val_loss: 1.5020 - val_accuracy: 0.3800\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.8318 - accuracy: 0.4247 - val_loss: 1.4817 - val_accuracy: 0.3400\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.7745 - accuracy: 0.4032 - val_loss: 1.4912 - val_accuracy: 0.3400\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.9137 - accuracy: 0.3172 - val_loss: 1.5017 - val_accuracy: 0.3400\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7991 - accuracy: 0.3333 - val_loss: 1.5086 - val_accuracy: 0.3600\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7287 - accuracy: 0.4086 - val_loss: 1.5101 - val_accuracy: 0.3600\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7252 - accuracy: 0.4140 - val_loss: 1.5045 - val_accuracy: 0.3800\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6775 - accuracy: 0.3978 - val_loss: 1.4644 - val_accuracy: 0.4200\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7538 - accuracy: 0.4247 - val_loss: 1.4341 - val_accuracy: 0.4000\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6440 - accuracy: 0.4409 - val_loss: 1.4321 - val_accuracy: 0.3600\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8039 - accuracy: 0.4247 - val_loss: 1.4263 - val_accuracy: 0.3800\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5595 - accuracy: 0.4409 - val_loss: 1.4262 - val_accuracy: 0.3600\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.7936 - accuracy: 0.3333 - val_loss: 1.4208 - val_accuracy: 0.4200\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6700 - accuracy: 0.3871 - val_loss: 1.4221 - val_accuracy: 0.3800\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5592 - accuracy: 0.4247 - val_loss: 1.4331 - val_accuracy: 0.3600\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6092 - accuracy: 0.3925 - val_loss: 1.4434 - val_accuracy: 0.3600\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5590 - accuracy: 0.4194 - val_loss: 1.4458 - val_accuracy: 0.4200\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8670 - accuracy: 0.3387 - val_loss: 1.4402 - val_accuracy: 0.4200\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5688 - accuracy: 0.4247 - val_loss: 1.4364 - val_accuracy: 0.4800\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6764 - accuracy: 0.4301 - val_loss: 1.4375 - val_accuracy: 0.4600\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5751 - accuracy: 0.4194 - val_loss: 1.4247 - val_accuracy: 0.4800\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5822 - accuracy: 0.4032 - val_loss: 1.4096 - val_accuracy: 0.4600\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.5148 - accuracy: 0.3871 - val_loss: 1.4038 - val_accuracy: 0.4600\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5412 - accuracy: 0.4409 - val_loss: 1.4037 - val_accuracy: 0.4200\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.5788 - accuracy: 0.4032 - val_loss: 1.4086 - val_accuracy: 0.4200\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6580 - accuracy: 0.3871 - val_loss: 1.4303 - val_accuracy: 0.4400\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4607 - accuracy: 0.4731 - val_loss: 1.4545 - val_accuracy: 0.4000\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5037 - accuracy: 0.4677 - val_loss: 1.4786 - val_accuracy: 0.4200\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4458 - accuracy: 0.4516 - val_loss: 1.4952 - val_accuracy: 0.4200\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5177 - accuracy: 0.4355 - val_loss: 1.4942 - val_accuracy: 0.4000\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4015 - accuracy: 0.4462 - val_loss: 1.4847 - val_accuracy: 0.3800\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7116 - accuracy: 0.3978 - val_loss: 1.4686 - val_accuracy: 0.3400\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4179 - accuracy: 0.4624 - val_loss: 1.4570 - val_accuracy: 0.3200\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4326 - accuracy: 0.4624 - val_loss: 1.4392 - val_accuracy: 0.3600\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5417 - accuracy: 0.4355 - val_loss: 1.4213 - val_accuracy: 0.3600\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4473 - accuracy: 0.4624 - val_loss: 1.4006 - val_accuracy: 0.3800\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.3165 - accuracy: 0.4570 - val_loss: 1.3834 - val_accuracy: 0.3800\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4588 - accuracy: 0.4355 - val_loss: 1.3760 - val_accuracy: 0.4000\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5124 - accuracy: 0.4086 - val_loss: 1.3785 - val_accuracy: 0.4000\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.5433 - accuracy: 0.4355 - val_loss: 1.3837 - val_accuracy: 0.4000\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1879 - accuracy: 0.5323 - val_loss: 1.3858 - val_accuracy: 0.4000\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3426 - accuracy: 0.4731 - val_loss: 1.3987 - val_accuracy: 0.3600\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5261 - accuracy: 0.4355 - val_loss: 1.4148 - val_accuracy: 0.3200\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3952 - accuracy: 0.4946 - val_loss: 1.4245 - val_accuracy: 0.3200\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3417 - accuracy: 0.4892 - val_loss: 1.4168 - val_accuracy: 0.3400\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2648 - accuracy: 0.5215 - val_loss: 1.3839 - val_accuracy: 0.3600\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3579 - accuracy: 0.4785 - val_loss: 1.3698 - val_accuracy: 0.3600\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.4116 - accuracy: 0.5269 - val_loss: 1.3604 - val_accuracy: 0.3400\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.3284 - accuracy: 0.4462 - val_loss: 1.3595 - val_accuracy: 0.3800\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2647 - accuracy: 0.4892 - val_loss: 1.3632 - val_accuracy: 0.3400\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4021 - accuracy: 0.4785 - val_loss: 1.3764 - val_accuracy: 0.3600\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4450 - accuracy: 0.4677 - val_loss: 1.3826 - val_accuracy: 0.3800\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3773 - accuracy: 0.4785 - val_loss: 1.3778 - val_accuracy: 0.3800\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3391 - accuracy: 0.5054 - val_loss: 1.3592 - val_accuracy: 0.3400\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1863 - accuracy: 0.5161 - val_loss: 1.3345 - val_accuracy: 0.4000\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2708 - accuracy: 0.4946 - val_loss: 1.3227 - val_accuracy: 0.3800\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2298 - accuracy: 0.5430 - val_loss: 1.3227 - val_accuracy: 0.4200\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3284 - accuracy: 0.4624 - val_loss: 1.3212 - val_accuracy: 0.4200\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3685 - accuracy: 0.5323 - val_loss: 1.3211 - val_accuracy: 0.4600\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3125 - accuracy: 0.4785 - val_loss: 1.3194 - val_accuracy: 0.4000\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1866 - accuracy: 0.4892 - val_loss: 1.3120 - val_accuracy: 0.4400\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3518 - accuracy: 0.4785 - val_loss: 1.3036 - val_accuracy: 0.4600\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.2964 - accuracy: 0.5215 - val_loss: 1.2989 - val_accuracy: 0.4200\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2101 - accuracy: 0.5323 - val_loss: 1.2960 - val_accuracy: 0.4000\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2597 - accuracy: 0.5215 - val_loss: 1.2960 - val_accuracy: 0.3800\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0233 - accuracy: 0.5538 - val_loss: 1.2971 - val_accuracy: 0.3600\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2328 - accuracy: 0.4462 - val_loss: 1.3011 - val_accuracy: 0.4000\n",
            "Test accuracy of the CNN-LSTM model for subject 1: 0.3700000047683716\n",
            "Shape of X after trimming: (236, 22, 500)\n",
            "Shape of X after maxpooling: (236, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (472, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (944, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 1s 151ms/step - loss: 2.6500 - accuracy: 0.2634 - val_loss: 3.4009 - val_accuracy: 0.3400\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.3700 - accuracy: 0.2796 - val_loss: 3.5451 - val_accuracy: 0.3000\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.7474 - accuracy: 0.2473 - val_loss: 3.5454 - val_accuracy: 0.3200\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.5070 - accuracy: 0.2796 - val_loss: 3.3958 - val_accuracy: 0.3400\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2.0947 - accuracy: 0.3065 - val_loss: 3.2547 - val_accuracy: 0.3000\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1845 - accuracy: 0.3495 - val_loss: 3.0399 - val_accuracy: 0.2600\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0300 - accuracy: 0.3710 - val_loss: 2.6976 - val_accuracy: 0.2800\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.9934 - accuracy: 0.3333 - val_loss: 2.3685 - val_accuracy: 0.3200\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.2252 - accuracy: 0.3441 - val_loss: 2.2488 - val_accuracy: 0.3400\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.1234 - accuracy: 0.3065 - val_loss: 2.0882 - val_accuracy: 0.3400\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.0601 - accuracy: 0.3656 - val_loss: 2.0835 - val_accuracy: 0.3400\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0645 - accuracy: 0.3441 - val_loss: 1.9925 - val_accuracy: 0.3400\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9994 - accuracy: 0.3387 - val_loss: 1.8780 - val_accuracy: 0.3400\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0786 - accuracy: 0.3387 - val_loss: 1.8191 - val_accuracy: 0.3600\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0043 - accuracy: 0.3280 - val_loss: 1.7874 - val_accuracy: 0.3000\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8358 - accuracy: 0.3763 - val_loss: 1.7991 - val_accuracy: 0.3400\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7178 - accuracy: 0.4247 - val_loss: 1.7899 - val_accuracy: 0.3800\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8252 - accuracy: 0.4301 - val_loss: 1.7458 - val_accuracy: 0.3400\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.1266 - accuracy: 0.3333 - val_loss: 1.6789 - val_accuracy: 0.3800\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9489 - accuracy: 0.3495 - val_loss: 1.5995 - val_accuracy: 0.3800\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8711 - accuracy: 0.3817 - val_loss: 1.5769 - val_accuracy: 0.3600\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8707 - accuracy: 0.3871 - val_loss: 1.5520 - val_accuracy: 0.3800\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.8051 - accuracy: 0.3925 - val_loss: 1.5272 - val_accuracy: 0.3800\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7195 - accuracy: 0.3925 - val_loss: 1.4955 - val_accuracy: 0.3600\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.8177 - accuracy: 0.4140 - val_loss: 1.4459 - val_accuracy: 0.3800\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7648 - accuracy: 0.4140 - val_loss: 1.4288 - val_accuracy: 0.3800\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5390 - accuracy: 0.4194 - val_loss: 1.4166 - val_accuracy: 0.3600\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7322 - accuracy: 0.4247 - val_loss: 1.4214 - val_accuracy: 0.3400\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7072 - accuracy: 0.4301 - val_loss: 1.4255 - val_accuracy: 0.3400\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8163 - accuracy: 0.3978 - val_loss: 1.4100 - val_accuracy: 0.3800\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4728 - accuracy: 0.4516 - val_loss: 1.3838 - val_accuracy: 0.3800\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7735 - accuracy: 0.4140 - val_loss: 1.3593 - val_accuracy: 0.4000\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4427 - accuracy: 0.5054 - val_loss: 1.3482 - val_accuracy: 0.3800\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4656 - accuracy: 0.4677 - val_loss: 1.3301 - val_accuracy: 0.3800\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5727 - accuracy: 0.4247 - val_loss: 1.2992 - val_accuracy: 0.3800\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5188 - accuracy: 0.4194 - val_loss: 1.2779 - val_accuracy: 0.4200\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6200 - accuracy: 0.4140 - val_loss: 1.2571 - val_accuracy: 0.4400\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7776 - accuracy: 0.3978 - val_loss: 1.2607 - val_accuracy: 0.4800\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7570 - accuracy: 0.3602 - val_loss: 1.2695 - val_accuracy: 0.4200\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6175 - accuracy: 0.4409 - val_loss: 1.2727 - val_accuracy: 0.4200\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6488 - accuracy: 0.4355 - val_loss: 1.2697 - val_accuracy: 0.4200\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.5643 - accuracy: 0.4516 - val_loss: 1.2620 - val_accuracy: 0.4800\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5166 - accuracy: 0.4301 - val_loss: 1.2633 - val_accuracy: 0.4800\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5086 - accuracy: 0.4086 - val_loss: 1.2607 - val_accuracy: 0.4800\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5268 - accuracy: 0.4516 - val_loss: 1.2513 - val_accuracy: 0.4600\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5636 - accuracy: 0.4247 - val_loss: 1.2470 - val_accuracy: 0.5000\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.2860 - accuracy: 0.5161 - val_loss: 1.2498 - val_accuracy: 0.4600\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2757 - accuracy: 0.5000 - val_loss: 1.2547 - val_accuracy: 0.4600\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2596 - accuracy: 0.5645 - val_loss: 1.2627 - val_accuracy: 0.4600\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5537 - accuracy: 0.4785 - val_loss: 1.2586 - val_accuracy: 0.4600\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3139 - accuracy: 0.4839 - val_loss: 1.2563 - val_accuracy: 0.4800\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4331 - accuracy: 0.4946 - val_loss: 1.2622 - val_accuracy: 0.4800\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2368 - accuracy: 0.5323 - val_loss: 1.2601 - val_accuracy: 0.4600\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2706 - accuracy: 0.5376 - val_loss: 1.2565 - val_accuracy: 0.4600\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2763 - accuracy: 0.5699 - val_loss: 1.2546 - val_accuracy: 0.4600\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2416 - accuracy: 0.5108 - val_loss: 1.2654 - val_accuracy: 0.4600\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3127 - accuracy: 0.5108 - val_loss: 1.2924 - val_accuracy: 0.4600\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3738 - accuracy: 0.5215 - val_loss: 1.3314 - val_accuracy: 0.4200\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3275 - accuracy: 0.5108 - val_loss: 1.3664 - val_accuracy: 0.4200\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2250 - accuracy: 0.5430 - val_loss: 1.3984 - val_accuracy: 0.4400\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2101 - accuracy: 0.5430 - val_loss: 1.4163 - val_accuracy: 0.4400\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2403 - accuracy: 0.5323 - val_loss: 1.4358 - val_accuracy: 0.4200\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3104 - accuracy: 0.5108 - val_loss: 1.4425 - val_accuracy: 0.4200\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2527 - accuracy: 0.5269 - val_loss: 1.4573 - val_accuracy: 0.3800\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3715 - accuracy: 0.4785 - val_loss: 1.4836 - val_accuracy: 0.4000\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2508 - accuracy: 0.5323 - val_loss: 1.4701 - val_accuracy: 0.4000\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1891 - accuracy: 0.5591 - val_loss: 1.4656 - val_accuracy: 0.4000\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.2316 - accuracy: 0.5484 - val_loss: 1.4797 - val_accuracy: 0.3800\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2426 - accuracy: 0.4946 - val_loss: 1.4991 - val_accuracy: 0.3600\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1088 - accuracy: 0.5968 - val_loss: 1.5146 - val_accuracy: 0.3600\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2565 - accuracy: 0.5108 - val_loss: 1.5576 - val_accuracy: 0.3400\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2398 - accuracy: 0.5215 - val_loss: 1.6150 - val_accuracy: 0.3600\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1595 - accuracy: 0.5269 - val_loss: 1.7249 - val_accuracy: 0.3400\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0393 - accuracy: 0.6075 - val_loss: 1.8203 - val_accuracy: 0.3000\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1273 - accuracy: 0.5699 - val_loss: 1.8538 - val_accuracy: 0.2800\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0184 - accuracy: 0.6022 - val_loss: 1.8199 - val_accuracy: 0.2800\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0735 - accuracy: 0.5968 - val_loss: 1.7457 - val_accuracy: 0.2800\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9850 - accuracy: 0.5860 - val_loss: 1.7116 - val_accuracy: 0.3000\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0652 - accuracy: 0.5591 - val_loss: 1.7210 - val_accuracy: 0.2800\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0188 - accuracy: 0.5860 - val_loss: 1.7402 - val_accuracy: 0.2800\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2197 - accuracy: 0.5645 - val_loss: 1.7986 - val_accuracy: 0.2800\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1826 - accuracy: 0.5430 - val_loss: 1.8786 - val_accuracy: 0.2800\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1700 - accuracy: 0.5591 - val_loss: 1.9603 - val_accuracy: 0.3000\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1655 - accuracy: 0.5699 - val_loss: 2.0592 - val_accuracy: 0.2800\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0440 - accuracy: 0.6183 - val_loss: 2.0917 - val_accuracy: 0.2800\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9958 - accuracy: 0.6398 - val_loss: 2.0865 - val_accuracy: 0.2600\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2556 - accuracy: 0.5376 - val_loss: 2.0981 - val_accuracy: 0.2800\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0622 - accuracy: 0.6183 - val_loss: 2.0646 - val_accuracy: 0.2800\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0811 - accuracy: 0.5753 - val_loss: 2.0230 - val_accuracy: 0.2600\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1712 - accuracy: 0.5699 - val_loss: 1.9839 - val_accuracy: 0.2600\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0700 - accuracy: 0.5806 - val_loss: 1.9364 - val_accuracy: 0.2800\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8114 - accuracy: 0.6613 - val_loss: 1.8953 - val_accuracy: 0.2800\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0695 - accuracy: 0.5806 - val_loss: 1.8750 - val_accuracy: 0.2800\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9088 - accuracy: 0.6398 - val_loss: 1.8913 - val_accuracy: 0.2800\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0048 - accuracy: 0.5914 - val_loss: 1.9054 - val_accuracy: 0.2800\n",
            "Test accuracy of the CNN-LSTM model for subject 2: 0.5149999856948853\n",
            "Shape of X after trimming: (234, 22, 500)\n",
            "Shape of X after maxpooling: (234, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (468, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (936, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 2s 280ms/step - loss: 2.8241 - accuracy: 0.2120 - val_loss: 2.8004 - val_accuracy: 0.2800\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.6509 - accuracy: 0.2717 - val_loss: 3.7114 - val_accuracy: 0.2600\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1252 - accuracy: 0.3261 - val_loss: 4.1854 - val_accuracy: 0.2200\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.4594 - accuracy: 0.2880 - val_loss: 4.1256 - val_accuracy: 0.2200\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.2727 - accuracy: 0.3587 - val_loss: 3.6801 - val_accuracy: 0.2400\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.5306 - accuracy: 0.2880 - val_loss: 3.1430 - val_accuracy: 0.2400\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1718 - accuracy: 0.3641 - val_loss: 2.8564 - val_accuracy: 0.2600\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1771 - accuracy: 0.2935 - val_loss: 2.7245 - val_accuracy: 0.2600\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.4102 - accuracy: 0.2935 - val_loss: 2.4310 - val_accuracy: 0.3200\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.0202 - accuracy: 0.3098 - val_loss: 2.2405 - val_accuracy: 0.3200\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0791 - accuracy: 0.3424 - val_loss: 2.0666 - val_accuracy: 0.3200\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9324 - accuracy: 0.3152 - val_loss: 1.8955 - val_accuracy: 0.3200\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9928 - accuracy: 0.3641 - val_loss: 1.8269 - val_accuracy: 0.3200\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.1929 - accuracy: 0.3315 - val_loss: 1.6894 - val_accuracy: 0.3200\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.3540 - accuracy: 0.2772 - val_loss: 1.5840 - val_accuracy: 0.3400\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0078 - accuracy: 0.3098 - val_loss: 1.5212 - val_accuracy: 0.3600\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.0040 - accuracy: 0.3587 - val_loss: 1.5425 - val_accuracy: 0.3800\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.0698 - accuracy: 0.3370 - val_loss: 1.5582 - val_accuracy: 0.3800\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8684 - accuracy: 0.3641 - val_loss: 1.5700 - val_accuracy: 0.3400\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1217 - accuracy: 0.3750 - val_loss: 1.5246 - val_accuracy: 0.3800\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1906 - accuracy: 0.3152 - val_loss: 1.5161 - val_accuracy: 0.4000\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8220 - accuracy: 0.3967 - val_loss: 1.4868 - val_accuracy: 0.4000\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9617 - accuracy: 0.3750 - val_loss: 1.4164 - val_accuracy: 0.4200\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8957 - accuracy: 0.3478 - val_loss: 1.3838 - val_accuracy: 0.4200\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.9068 - accuracy: 0.3587 - val_loss: 1.3838 - val_accuracy: 0.3200\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.7955 - accuracy: 0.3804 - val_loss: 1.3746 - val_accuracy: 0.3400\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5775 - accuracy: 0.4293 - val_loss: 1.3674 - val_accuracy: 0.3400\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8102 - accuracy: 0.3913 - val_loss: 1.3325 - val_accuracy: 0.3800\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9425 - accuracy: 0.3370 - val_loss: 1.3117 - val_accuracy: 0.3400\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.7183 - accuracy: 0.3370 - val_loss: 1.2993 - val_accuracy: 0.3200\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7202 - accuracy: 0.3804 - val_loss: 1.2970 - val_accuracy: 0.3200\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9545 - accuracy: 0.3696 - val_loss: 1.2801 - val_accuracy: 0.3400\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8004 - accuracy: 0.3641 - val_loss: 1.2723 - val_accuracy: 0.3600\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8997 - accuracy: 0.3696 - val_loss: 1.2635 - val_accuracy: 0.3600\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7427 - accuracy: 0.3913 - val_loss: 1.2482 - val_accuracy: 0.3600\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4828 - accuracy: 0.4837 - val_loss: 1.2291 - val_accuracy: 0.3600\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6240 - accuracy: 0.3587 - val_loss: 1.2225 - val_accuracy: 0.3400\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5166 - accuracy: 0.3913 - val_loss: 1.2150 - val_accuracy: 0.3600\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6620 - accuracy: 0.3913 - val_loss: 1.2043 - val_accuracy: 0.4000\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7032 - accuracy: 0.3533 - val_loss: 1.1953 - val_accuracy: 0.4000\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7775 - accuracy: 0.4076 - val_loss: 1.1845 - val_accuracy: 0.4600\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.8791 - accuracy: 0.3587 - val_loss: 1.1899 - val_accuracy: 0.4400\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6169 - accuracy: 0.4348 - val_loss: 1.1889 - val_accuracy: 0.4000\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4547 - accuracy: 0.4022 - val_loss: 1.1866 - val_accuracy: 0.3800\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6085 - accuracy: 0.4185 - val_loss: 1.1826 - val_accuracy: 0.4200\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.6568 - accuracy: 0.3859 - val_loss: 1.1757 - val_accuracy: 0.4200\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6430 - accuracy: 0.4185 - val_loss: 1.1673 - val_accuracy: 0.3800\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5288 - accuracy: 0.4130 - val_loss: 1.1580 - val_accuracy: 0.4000\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5483 - accuracy: 0.3967 - val_loss: 1.1500 - val_accuracy: 0.4400\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5051 - accuracy: 0.4239 - val_loss: 1.1445 - val_accuracy: 0.4600\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6309 - accuracy: 0.4565 - val_loss: 1.1437 - val_accuracy: 0.4400\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.5259 - accuracy: 0.3859 - val_loss: 1.1388 - val_accuracy: 0.4600\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6766 - accuracy: 0.4076 - val_loss: 1.1406 - val_accuracy: 0.4600\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6073 - accuracy: 0.3641 - val_loss: 1.1499 - val_accuracy: 0.4400\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5762 - accuracy: 0.4185 - val_loss: 1.1614 - val_accuracy: 0.4200\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4955 - accuracy: 0.4293 - val_loss: 1.1666 - val_accuracy: 0.4400\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5052 - accuracy: 0.4076 - val_loss: 1.1648 - val_accuracy: 0.4600\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3836 - accuracy: 0.4457 - val_loss: 1.1680 - val_accuracy: 0.4400\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.4536 - accuracy: 0.4728 - val_loss: 1.1595 - val_accuracy: 0.4200\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3730 - accuracy: 0.4022 - val_loss: 1.1478 - val_accuracy: 0.4400\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5661 - accuracy: 0.4293 - val_loss: 1.1453 - val_accuracy: 0.4600\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4084 - accuracy: 0.4674 - val_loss: 1.1478 - val_accuracy: 0.4200\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6002 - accuracy: 0.3967 - val_loss: 1.1536 - val_accuracy: 0.4400\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.6210 - accuracy: 0.3641 - val_loss: 1.1620 - val_accuracy: 0.4400\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.5704 - accuracy: 0.3913 - val_loss: 1.1655 - val_accuracy: 0.4600\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4991 - accuracy: 0.4457 - val_loss: 1.1547 - val_accuracy: 0.4800\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4400 - accuracy: 0.4130 - val_loss: 1.1453 - val_accuracy: 0.5000\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3796 - accuracy: 0.4511 - val_loss: 1.1348 - val_accuracy: 0.5000\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2294 - accuracy: 0.4783 - val_loss: 1.1285 - val_accuracy: 0.4800\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3611 - accuracy: 0.4457 - val_loss: 1.1359 - val_accuracy: 0.4200\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3612 - accuracy: 0.5000 - val_loss: 1.1450 - val_accuracy: 0.4800\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.4638 - accuracy: 0.4511 - val_loss: 1.1684 - val_accuracy: 0.4200\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3991 - accuracy: 0.4783 - val_loss: 1.1999 - val_accuracy: 0.4000\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.3753 - accuracy: 0.4837 - val_loss: 1.2217 - val_accuracy: 0.3800\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.3415 - accuracy: 0.4293 - val_loss: 1.2438 - val_accuracy: 0.3600\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5103 - accuracy: 0.4402 - val_loss: 1.2346 - val_accuracy: 0.3800\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4040 - accuracy: 0.4185 - val_loss: 1.2243 - val_accuracy: 0.4000\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5250 - accuracy: 0.4185 - val_loss: 1.2066 - val_accuracy: 0.3800\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2786 - accuracy: 0.4728 - val_loss: 1.1980 - val_accuracy: 0.3800\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4711 - accuracy: 0.3641 - val_loss: 1.2019 - val_accuracy: 0.3400\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4327 - accuracy: 0.4130 - val_loss: 1.2223 - val_accuracy: 0.3400\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3748 - accuracy: 0.4511 - val_loss: 1.2531 - val_accuracy: 0.3600\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3957 - accuracy: 0.4837 - val_loss: 1.2948 - val_accuracy: 0.3800\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3455 - accuracy: 0.4402 - val_loss: 1.3037 - val_accuracy: 0.3800\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3633 - accuracy: 0.4891 - val_loss: 1.2855 - val_accuracy: 0.4000\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2546 - accuracy: 0.5163 - val_loss: 1.2694 - val_accuracy: 0.4000\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2077 - accuracy: 0.5326 - val_loss: 1.2653 - val_accuracy: 0.4200\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.3880 - accuracy: 0.4511 - val_loss: 1.2703 - val_accuracy: 0.4200\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1370 - accuracy: 0.5489 - val_loss: 1.2794 - val_accuracy: 0.4000\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3375 - accuracy: 0.4891 - val_loss: 1.2689 - val_accuracy: 0.4000\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2168 - accuracy: 0.5054 - val_loss: 1.2725 - val_accuracy: 0.4200\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2330 - accuracy: 0.5489 - val_loss: 1.2628 - val_accuracy: 0.4200\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2871 - accuracy: 0.5000 - val_loss: 1.2617 - val_accuracy: 0.4000\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2231 - accuracy: 0.5489 - val_loss: 1.2745 - val_accuracy: 0.4200\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2632 - accuracy: 0.4348 - val_loss: 1.3035 - val_accuracy: 0.4000\n",
            "Test accuracy of the CNN-LSTM model for subject 3: 0.3149999976158142\n",
            "Shape of X after trimming: (235, 22, 500)\n",
            "Shape of X after maxpooling: (235, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (470, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (940, 22, 250)\n",
            "Shape of X after trimming: (47, 22, 500)\n",
            "Shape of X after maxpooling: (47, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (94, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (188, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 2s 298ms/step - loss: 2.8027 - accuracy: 0.2216 - val_loss: 1.8234 - val_accuracy: 0.3600\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.5969 - accuracy: 0.2595 - val_loss: 2.3507 - val_accuracy: 0.2600\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.4304 - accuracy: 0.2865 - val_loss: 2.6749 - val_accuracy: 0.2600\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.0862 - accuracy: 0.3784 - val_loss: 2.8378 - val_accuracy: 0.2600\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.0623 - accuracy: 0.2973 - val_loss: 2.7654 - val_accuracy: 0.2600\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1461 - accuracy: 0.2541 - val_loss: 2.6312 - val_accuracy: 0.2800\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.0055 - accuracy: 0.3459 - val_loss: 2.5877 - val_accuracy: 0.3000\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.2601 - accuracy: 0.2541 - val_loss: 2.4798 - val_accuracy: 0.3400\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1380 - accuracy: 0.3027 - val_loss: 2.2962 - val_accuracy: 0.3600\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.4597 - accuracy: 0.2811 - val_loss: 2.2649 - val_accuracy: 0.3400\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0614 - accuracy: 0.2919 - val_loss: 2.2468 - val_accuracy: 0.3400\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9231 - accuracy: 0.4162 - val_loss: 2.1915 - val_accuracy: 0.3400\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2.1506 - accuracy: 0.3297 - val_loss: 2.1686 - val_accuracy: 0.3200\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.0237 - accuracy: 0.3568 - val_loss: 2.1488 - val_accuracy: 0.3000\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7835 - accuracy: 0.4054 - val_loss: 2.1152 - val_accuracy: 0.3000\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8663 - accuracy: 0.3838 - val_loss: 1.9717 - val_accuracy: 0.3000\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7390 - accuracy: 0.4324 - val_loss: 1.9130 - val_accuracy: 0.3600\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9084 - accuracy: 0.4324 - val_loss: 1.8622 - val_accuracy: 0.3600\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.8188 - accuracy: 0.4162 - val_loss: 1.8311 - val_accuracy: 0.4000\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8268 - accuracy: 0.3946 - val_loss: 1.7407 - val_accuracy: 0.3800\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.7116 - accuracy: 0.4054 - val_loss: 1.6637 - val_accuracy: 0.3800\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7425 - accuracy: 0.4324 - val_loss: 1.5946 - val_accuracy: 0.4400\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9453 - accuracy: 0.3676 - val_loss: 1.5513 - val_accuracy: 0.4400\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8999 - accuracy: 0.4108 - val_loss: 1.5086 - val_accuracy: 0.4600\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4967 - accuracy: 0.4919 - val_loss: 1.4513 - val_accuracy: 0.4800\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6473 - accuracy: 0.4486 - val_loss: 1.3988 - val_accuracy: 0.4600\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5602 - accuracy: 0.4270 - val_loss: 1.3573 - val_accuracy: 0.5000\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.6405 - accuracy: 0.4270 - val_loss: 1.3491 - val_accuracy: 0.5200\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6495 - accuracy: 0.4162 - val_loss: 1.3465 - val_accuracy: 0.5200\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5653 - accuracy: 0.4649 - val_loss: 1.3560 - val_accuracy: 0.5400\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5874 - accuracy: 0.4865 - val_loss: 1.3659 - val_accuracy: 0.5600\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7276 - accuracy: 0.4378 - val_loss: 1.3834 - val_accuracy: 0.5200\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5533 - accuracy: 0.4595 - val_loss: 1.3907 - val_accuracy: 0.4800\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3915 - accuracy: 0.5081 - val_loss: 1.3889 - val_accuracy: 0.5200\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.7000 - accuracy: 0.3946 - val_loss: 1.3756 - val_accuracy: 0.5800\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.4015 - accuracy: 0.5135 - val_loss: 1.3651 - val_accuracy: 0.5800\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4551 - accuracy: 0.5351 - val_loss: 1.3623 - val_accuracy: 0.5600\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4174 - accuracy: 0.5243 - val_loss: 1.3453 - val_accuracy: 0.5400\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3046 - accuracy: 0.5568 - val_loss: 1.3235 - val_accuracy: 0.5600\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3996 - accuracy: 0.5189 - val_loss: 1.3073 - val_accuracy: 0.6200\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2580 - accuracy: 0.5730 - val_loss: 1.2981 - val_accuracy: 0.5800\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.3608 - accuracy: 0.4973 - val_loss: 1.3146 - val_accuracy: 0.5400\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2687 - accuracy: 0.5892 - val_loss: 1.3075 - val_accuracy: 0.5000\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.2453 - accuracy: 0.5297 - val_loss: 1.2996 - val_accuracy: 0.5400\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1256 - accuracy: 0.5892 - val_loss: 1.2764 - val_accuracy: 0.5200\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1295 - accuracy: 0.5784 - val_loss: 1.2553 - val_accuracy: 0.5200\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.3339 - accuracy: 0.5297 - val_loss: 1.2160 - val_accuracy: 0.5800\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2860 - accuracy: 0.5622 - val_loss: 1.2009 - val_accuracy: 0.5800\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2384 - accuracy: 0.5459 - val_loss: 1.1981 - val_accuracy: 0.6400\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1751 - accuracy: 0.5730 - val_loss: 1.2111 - val_accuracy: 0.6000\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2428 - accuracy: 0.5676 - val_loss: 1.2350 - val_accuracy: 0.6800\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.3616 - accuracy: 0.5892 - val_loss: 1.2429 - val_accuracy: 0.6600\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3665 - accuracy: 0.5405 - val_loss: 1.2170 - val_accuracy: 0.6000\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1717 - accuracy: 0.5730 - val_loss: 1.2060 - val_accuracy: 0.5400\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.1284 - accuracy: 0.5730 - val_loss: 1.2141 - val_accuracy: 0.5000\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.1196 - accuracy: 0.5459 - val_loss: 1.2340 - val_accuracy: 0.4800\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1190 - accuracy: 0.5784 - val_loss: 1.2390 - val_accuracy: 0.4800\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2344 - accuracy: 0.5676 - val_loss: 1.2244 - val_accuracy: 0.5400\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.9953 - accuracy: 0.6270 - val_loss: 1.1928 - val_accuracy: 0.5800\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.1279 - accuracy: 0.5730 - val_loss: 1.1784 - val_accuracy: 0.6200\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0559 - accuracy: 0.5730 - val_loss: 1.1673 - val_accuracy: 0.5800\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1796 - accuracy: 0.5676 - val_loss: 1.1482 - val_accuracy: 0.5400\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1236 - accuracy: 0.5892 - val_loss: 1.1456 - val_accuracy: 0.5200\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0586 - accuracy: 0.6324 - val_loss: 1.1514 - val_accuracy: 0.5400\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1330 - accuracy: 0.6054 - val_loss: 1.1545 - val_accuracy: 0.5600\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.1620 - accuracy: 0.6000 - val_loss: 1.1599 - val_accuracy: 0.6000\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.1586 - accuracy: 0.5459 - val_loss: 1.1694 - val_accuracy: 0.5400\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0389 - accuracy: 0.6054 - val_loss: 1.1786 - val_accuracy: 0.6000\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9206 - accuracy: 0.6541 - val_loss: 1.1840 - val_accuracy: 0.6000\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9404 - accuracy: 0.6108 - val_loss: 1.1817 - val_accuracy: 0.5800\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1150 - accuracy: 0.5946 - val_loss: 1.1753 - val_accuracy: 0.5600\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9549 - accuracy: 0.6378 - val_loss: 1.1572 - val_accuracy: 0.5800\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0143 - accuracy: 0.5838 - val_loss: 1.1490 - val_accuracy: 0.6000\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.8976 - accuracy: 0.6595 - val_loss: 1.1590 - val_accuracy: 0.6000\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9908 - accuracy: 0.6541 - val_loss: 1.1561 - val_accuracy: 0.6000\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8716 - accuracy: 0.6757 - val_loss: 1.1459 - val_accuracy: 0.6000\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.9477 - accuracy: 0.6378 - val_loss: 1.1511 - val_accuracy: 0.6000\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9158 - accuracy: 0.6595 - val_loss: 1.1453 - val_accuracy: 0.6000\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8708 - accuracy: 0.6757 - val_loss: 1.1374 - val_accuracy: 0.6000\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.7732 - accuracy: 0.7027 - val_loss: 1.1129 - val_accuracy: 0.6200\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8615 - accuracy: 0.7081 - val_loss: 1.1039 - val_accuracy: 0.6400\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.7303 - accuracy: 0.6973 - val_loss: 1.0982 - val_accuracy: 0.6000\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.8452 - accuracy: 0.6649 - val_loss: 1.0964 - val_accuracy: 0.6000\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8172 - accuracy: 0.7189 - val_loss: 1.0885 - val_accuracy: 0.6000\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8774 - accuracy: 0.6432 - val_loss: 1.0864 - val_accuracy: 0.6000\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8448 - accuracy: 0.7027 - val_loss: 1.0855 - val_accuracy: 0.6400\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7219 - accuracy: 0.7351 - val_loss: 1.0693 - val_accuracy: 0.6800\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9714 - accuracy: 0.6595 - val_loss: 1.0624 - val_accuracy: 0.6400\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8079 - accuracy: 0.6919 - val_loss: 1.0783 - val_accuracy: 0.6200\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7683 - accuracy: 0.7027 - val_loss: 1.0898 - val_accuracy: 0.6000\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6377 - accuracy: 0.7514 - val_loss: 1.1093 - val_accuracy: 0.6600\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7681 - accuracy: 0.7135 - val_loss: 1.1225 - val_accuracy: 0.6200\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7868 - accuracy: 0.6541 - val_loss: 1.1339 - val_accuracy: 0.6200\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.7775 - accuracy: 0.7135 - val_loss: 1.1443 - val_accuracy: 0.6200\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.7005 - accuracy: 0.7135 - val_loss: 1.1506 - val_accuracy: 0.6000\n",
            "Test accuracy of the CNN-LSTM model for subject 4: 0.5265957713127136\n",
            "Shape of X after trimming: (236, 22, 500)\n",
            "Shape of X after maxpooling: (236, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (472, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (944, 22, 250)\n",
            "Shape of X after trimming: (49, 22, 500)\n",
            "Shape of X after maxpooling: (49, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (98, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (196, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 2.5734 - accuracy: 0.3011 - val_loss: 2.6204 - val_accuracy: 0.3200\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.6501 - accuracy: 0.2796 - val_loss: 3.2164 - val_accuracy: 0.2600\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.2134 - accuracy: 0.2957 - val_loss: 3.6512 - val_accuracy: 0.2400\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.2217 - accuracy: 0.2903 - val_loss: 3.4382 - val_accuracy: 0.2400\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.2581 - accuracy: 0.3011 - val_loss: 3.2177 - val_accuracy: 0.2400\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.2983 - accuracy: 0.3172 - val_loss: 2.9361 - val_accuracy: 0.3000\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.5313 - accuracy: 0.2688 - val_loss: 2.7615 - val_accuracy: 0.3200\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1601 - accuracy: 0.3226 - val_loss: 2.6351 - val_accuracy: 0.3200\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.0154 - accuracy: 0.3871 - val_loss: 2.6629 - val_accuracy: 0.3000\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0422 - accuracy: 0.3118 - val_loss: 2.7661 - val_accuracy: 0.2800\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.1726 - accuracy: 0.3226 - val_loss: 2.8961 - val_accuracy: 0.2600\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 1.8786 - accuracy: 0.3656 - val_loss: 3.0484 - val_accuracy: 0.2600\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9733 - accuracy: 0.3441 - val_loss: 3.1058 - val_accuracy: 0.2600\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.7703 - accuracy: 0.4140 - val_loss: 3.0143 - val_accuracy: 0.2600\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0629 - accuracy: 0.3871 - val_loss: 2.7968 - val_accuracy: 0.2600\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.7701 - accuracy: 0.3763 - val_loss: 2.5731 - val_accuracy: 0.2600\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.9538 - accuracy: 0.4086 - val_loss: 2.2941 - val_accuracy: 0.3200\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8666 - accuracy: 0.3978 - val_loss: 2.0991 - val_accuracy: 0.3400\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.8628 - accuracy: 0.4032 - val_loss: 1.9673 - val_accuracy: 0.3600\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8132 - accuracy: 0.3978 - val_loss: 1.9019 - val_accuracy: 0.3600\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.8313 - accuracy: 0.3978 - val_loss: 1.8659 - val_accuracy: 0.3600\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.8708 - accuracy: 0.3817 - val_loss: 1.8544 - val_accuracy: 0.3400\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.7942 - accuracy: 0.4409 - val_loss: 1.8647 - val_accuracy: 0.3200\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8679 - accuracy: 0.3763 - val_loss: 1.9334 - val_accuracy: 0.3400\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6915 - accuracy: 0.4785 - val_loss: 2.0046 - val_accuracy: 0.3200\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8042 - accuracy: 0.4462 - val_loss: 1.9901 - val_accuracy: 0.3000\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9968 - accuracy: 0.3817 - val_loss: 1.9798 - val_accuracy: 0.3200\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6763 - accuracy: 0.4301 - val_loss: 1.8549 - val_accuracy: 0.3000\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6751 - accuracy: 0.4946 - val_loss: 1.7590 - val_accuracy: 0.3000\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6667 - accuracy: 0.3978 - val_loss: 1.7332 - val_accuracy: 0.2800\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6542 - accuracy: 0.4301 - val_loss: 1.7087 - val_accuracy: 0.3200\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6940 - accuracy: 0.3710 - val_loss: 1.7372 - val_accuracy: 0.3200\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7673 - accuracy: 0.4462 - val_loss: 1.7649 - val_accuracy: 0.3200\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7598 - accuracy: 0.4032 - val_loss: 1.7907 - val_accuracy: 0.3400\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.7701 - accuracy: 0.3763 - val_loss: 1.7970 - val_accuracy: 0.3400\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4698 - accuracy: 0.4624 - val_loss: 1.7898 - val_accuracy: 0.3400\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6373 - accuracy: 0.4086 - val_loss: 1.7804 - val_accuracy: 0.3400\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.6553 - accuracy: 0.4140 - val_loss: 1.7920 - val_accuracy: 0.3400\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5903 - accuracy: 0.4677 - val_loss: 1.7705 - val_accuracy: 0.3800\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5025 - accuracy: 0.4839 - val_loss: 1.7497 - val_accuracy: 0.3600\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6024 - accuracy: 0.4247 - val_loss: 1.7339 - val_accuracy: 0.3400\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5892 - accuracy: 0.4570 - val_loss: 1.7422 - val_accuracy: 0.3400\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4998 - accuracy: 0.4247 - val_loss: 1.7655 - val_accuracy: 0.3400\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3832 - accuracy: 0.4785 - val_loss: 1.7785 - val_accuracy: 0.3200\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6355 - accuracy: 0.4032 - val_loss: 1.7790 - val_accuracy: 0.3200\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4168 - accuracy: 0.5108 - val_loss: 1.7640 - val_accuracy: 0.2800\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4157 - accuracy: 0.4731 - val_loss: 1.7612 - val_accuracy: 0.2800\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.5049 - accuracy: 0.4624 - val_loss: 1.7457 - val_accuracy: 0.2800\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3181 - accuracy: 0.5108 - val_loss: 1.7489 - val_accuracy: 0.2800\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4389 - accuracy: 0.4892 - val_loss: 1.7582 - val_accuracy: 0.3000\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4666 - accuracy: 0.4731 - val_loss: 1.7728 - val_accuracy: 0.3000\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6063 - accuracy: 0.4409 - val_loss: 1.7726 - val_accuracy: 0.2800\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3574 - accuracy: 0.4677 - val_loss: 1.7461 - val_accuracy: 0.2600\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3723 - accuracy: 0.5054 - val_loss: 1.7245 - val_accuracy: 0.2800\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4815 - accuracy: 0.4624 - val_loss: 1.7125 - val_accuracy: 0.2800\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2426 - accuracy: 0.5645 - val_loss: 1.7201 - val_accuracy: 0.2600\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4715 - accuracy: 0.5108 - val_loss: 1.7169 - val_accuracy: 0.2400\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.3937 - accuracy: 0.4946 - val_loss: 1.7155 - val_accuracy: 0.2200\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2603 - accuracy: 0.4946 - val_loss: 1.7232 - val_accuracy: 0.2400\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4487 - accuracy: 0.4516 - val_loss: 1.7349 - val_accuracy: 0.2400\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4672 - accuracy: 0.4677 - val_loss: 1.7618 - val_accuracy: 0.2400\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4409 - accuracy: 0.4785 - val_loss: 1.7745 - val_accuracy: 0.2800\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4636 - accuracy: 0.4677 - val_loss: 1.7658 - val_accuracy: 0.2800\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4293 - accuracy: 0.4462 - val_loss: 1.7435 - val_accuracy: 0.2800\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.2422 - accuracy: 0.5000 - val_loss: 1.6946 - val_accuracy: 0.3200\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2698 - accuracy: 0.5215 - val_loss: 1.6695 - val_accuracy: 0.3200\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2276 - accuracy: 0.5645 - val_loss: 1.6587 - val_accuracy: 0.3000\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1681 - accuracy: 0.5323 - val_loss: 1.6686 - val_accuracy: 0.3200\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2518 - accuracy: 0.5215 - val_loss: 1.6762 - val_accuracy: 0.3200\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2570 - accuracy: 0.5215 - val_loss: 1.6847 - val_accuracy: 0.3400\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.1741 - accuracy: 0.5753 - val_loss: 1.7009 - val_accuracy: 0.3400\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2749 - accuracy: 0.4785 - val_loss: 1.7225 - val_accuracy: 0.3200\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.3177 - accuracy: 0.5161 - val_loss: 1.7720 - val_accuracy: 0.3200\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3027 - accuracy: 0.4839 - val_loss: 1.7996 - val_accuracy: 0.2800\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1347 - accuracy: 0.4892 - val_loss: 1.8186 - val_accuracy: 0.2800\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1886 - accuracy: 0.5538 - val_loss: 1.8024 - val_accuracy: 0.2800\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0890 - accuracy: 0.5269 - val_loss: 1.7835 - val_accuracy: 0.2800\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2780 - accuracy: 0.4785 - val_loss: 1.8061 - val_accuracy: 0.2800\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2169 - accuracy: 0.5269 - val_loss: 1.8090 - val_accuracy: 0.3000\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1706 - accuracy: 0.5376 - val_loss: 1.8151 - val_accuracy: 0.3000\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1564 - accuracy: 0.5161 - val_loss: 1.8079 - val_accuracy: 0.3000\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.1274 - accuracy: 0.5645 - val_loss: 1.8165 - val_accuracy: 0.3000\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0757 - accuracy: 0.5538 - val_loss: 1.8161 - val_accuracy: 0.3000\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1608 - accuracy: 0.5484 - val_loss: 1.8156 - val_accuracy: 0.3000\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1437 - accuracy: 0.5753 - val_loss: 1.8347 - val_accuracy: 0.3000\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0420 - accuracy: 0.5591 - val_loss: 1.8650 - val_accuracy: 0.3000\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.1299 - accuracy: 0.5968 - val_loss: 1.8681 - val_accuracy: 0.2800\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1911 - accuracy: 0.5430 - val_loss: 1.8300 - val_accuracy: 0.2800\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1633 - accuracy: 0.5430 - val_loss: 1.7971 - val_accuracy: 0.2600\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0649 - accuracy: 0.5699 - val_loss: 1.7651 - val_accuracy: 0.2600\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0302 - accuracy: 0.5645 - val_loss: 1.7465 - val_accuracy: 0.2600\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1060 - accuracy: 0.5645 - val_loss: 1.7657 - val_accuracy: 0.2800\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1243 - accuracy: 0.5591 - val_loss: 1.7799 - val_accuracy: 0.2800\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0238 - accuracy: 0.6183 - val_loss: 1.8002 - val_accuracy: 0.2800\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9969 - accuracy: 0.6290 - val_loss: 1.7976 - val_accuracy: 0.2800\n",
            "Test accuracy of the CNN-LSTM model for subject 5: 0.4030612111091614\n",
            "Shape of X after trimming: (238, 22, 500)\n",
            "Shape of X after maxpooling: (238, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (476, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (952, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 2s 281ms/step - loss: 2.4941 - accuracy: 0.3245 - val_loss: 2.1558 - val_accuracy: 0.3000\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.4609 - accuracy: 0.2553 - val_loss: 1.4880 - val_accuracy: 0.3000\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 2.2043 - accuracy: 0.3723 - val_loss: 2.4052 - val_accuracy: 0.2600\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.0963 - accuracy: 0.3617 - val_loss: 2.9598 - val_accuracy: 0.2600\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.2470 - accuracy: 0.3670 - val_loss: 2.8361 - val_accuracy: 0.3400\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8625 - accuracy: 0.3883 - val_loss: 2.6620 - val_accuracy: 0.4000\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0310 - accuracy: 0.3351 - val_loss: 2.5245 - val_accuracy: 0.4000\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.0062 - accuracy: 0.3617 - val_loss: 2.5344 - val_accuracy: 0.4200\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.9805 - accuracy: 0.3936 - val_loss: 2.3329 - val_accuracy: 0.4200\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7369 - accuracy: 0.3617 - val_loss: 2.0200 - val_accuracy: 0.4000\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9164 - accuracy: 0.3723 - val_loss: 1.8609 - val_accuracy: 0.4000\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9838 - accuracy: 0.3617 - val_loss: 1.7517 - val_accuracy: 0.3400\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.8848 - accuracy: 0.4309 - val_loss: 1.6480 - val_accuracy: 0.3800\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.1554 - accuracy: 0.3457 - val_loss: 1.5646 - val_accuracy: 0.4000\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8631 - accuracy: 0.4202 - val_loss: 1.5079 - val_accuracy: 0.4000\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.7055 - accuracy: 0.4628 - val_loss: 1.4741 - val_accuracy: 0.3800\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6416 - accuracy: 0.4468 - val_loss: 1.4853 - val_accuracy: 0.3800\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8874 - accuracy: 0.3936 - val_loss: 1.4808 - val_accuracy: 0.3600\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.7454 - accuracy: 0.3670 - val_loss: 1.5404 - val_accuracy: 0.3800\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7527 - accuracy: 0.4468 - val_loss: 1.5481 - val_accuracy: 0.3600\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.8831 - accuracy: 0.4362 - val_loss: 1.4708 - val_accuracy: 0.4000\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8721 - accuracy: 0.4043 - val_loss: 1.4277 - val_accuracy: 0.4200\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6840 - accuracy: 0.4202 - val_loss: 1.4070 - val_accuracy: 0.4000\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4998 - accuracy: 0.4947 - val_loss: 1.3786 - val_accuracy: 0.4000\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5247 - accuracy: 0.4468 - val_loss: 1.3470 - val_accuracy: 0.4000\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6425 - accuracy: 0.4255 - val_loss: 1.3227 - val_accuracy: 0.4200\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4860 - accuracy: 0.5160 - val_loss: 1.2792 - val_accuracy: 0.4000\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.3833 - accuracy: 0.5000 - val_loss: 1.2439 - val_accuracy: 0.3800\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.7067 - accuracy: 0.4309 - val_loss: 1.2224 - val_accuracy: 0.4200\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5710 - accuracy: 0.4628 - val_loss: 1.2048 - val_accuracy: 0.4400\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6138 - accuracy: 0.4202 - val_loss: 1.1825 - val_accuracy: 0.4000\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4837 - accuracy: 0.4734 - val_loss: 1.1703 - val_accuracy: 0.3800\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6938 - accuracy: 0.4255 - val_loss: 1.1499 - val_accuracy: 0.4000\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6199 - accuracy: 0.4415 - val_loss: 1.1276 - val_accuracy: 0.4200\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.5429 - accuracy: 0.4681 - val_loss: 1.1085 - val_accuracy: 0.4200\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6466 - accuracy: 0.4628 - val_loss: 1.1029 - val_accuracy: 0.4000\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5057 - accuracy: 0.4628 - val_loss: 1.1029 - val_accuracy: 0.4000\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.3893 - accuracy: 0.4894 - val_loss: 1.0996 - val_accuracy: 0.4800\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.3853 - accuracy: 0.5000 - val_loss: 1.1018 - val_accuracy: 0.5000\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3092 - accuracy: 0.5053 - val_loss: 1.1117 - val_accuracy: 0.4800\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5199 - accuracy: 0.4840 - val_loss: 1.1230 - val_accuracy: 0.4800\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4359 - accuracy: 0.5053 - val_loss: 1.1318 - val_accuracy: 0.4600\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5464 - accuracy: 0.4415 - val_loss: 1.1391 - val_accuracy: 0.4800\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4488 - accuracy: 0.4894 - val_loss: 1.1344 - val_accuracy: 0.4800\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2854 - accuracy: 0.5585 - val_loss: 1.1199 - val_accuracy: 0.4600\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3199 - accuracy: 0.4734 - val_loss: 1.1140 - val_accuracy: 0.5000\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4217 - accuracy: 0.5000 - val_loss: 1.1224 - val_accuracy: 0.5200\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2639 - accuracy: 0.5160 - val_loss: 1.1174 - val_accuracy: 0.5400\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3613 - accuracy: 0.4947 - val_loss: 1.1233 - val_accuracy: 0.5400\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2826 - accuracy: 0.5000 - val_loss: 1.1453 - val_accuracy: 0.5000\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4608 - accuracy: 0.4574 - val_loss: 1.1681 - val_accuracy: 0.4200\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3157 - accuracy: 0.5266 - val_loss: 1.1976 - val_accuracy: 0.4200\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2527 - accuracy: 0.5213 - val_loss: 1.2215 - val_accuracy: 0.4600\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2262 - accuracy: 0.5160 - val_loss: 1.2283 - val_accuracy: 0.4600\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.2392 - accuracy: 0.5372 - val_loss: 1.2187 - val_accuracy: 0.4400\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.2173 - accuracy: 0.5319 - val_loss: 1.2027 - val_accuracy: 0.4800\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2595 - accuracy: 0.5160 - val_loss: 1.2044 - val_accuracy: 0.4400\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.3865 - accuracy: 0.5000 - val_loss: 1.1887 - val_accuracy: 0.4600\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2352 - accuracy: 0.5426 - val_loss: 1.1870 - val_accuracy: 0.4400\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1508 - accuracy: 0.5957 - val_loss: 1.1930 - val_accuracy: 0.4400\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0550 - accuracy: 0.5851 - val_loss: 1.2110 - val_accuracy: 0.4400\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.1166 - accuracy: 0.6064 - val_loss: 1.2270 - val_accuracy: 0.4200\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1374 - accuracy: 0.5638 - val_loss: 1.2284 - val_accuracy: 0.4200\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.2287 - accuracy: 0.5319 - val_loss: 1.2260 - val_accuracy: 0.4200\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1527 - accuracy: 0.5638 - val_loss: 1.2354 - val_accuracy: 0.4200\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1133 - accuracy: 0.5798 - val_loss: 1.2157 - val_accuracy: 0.4600\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0404 - accuracy: 0.5904 - val_loss: 1.1983 - val_accuracy: 0.4800\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0466 - accuracy: 0.5798 - val_loss: 1.2125 - val_accuracy: 0.4400\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0570 - accuracy: 0.6011 - val_loss: 1.2007 - val_accuracy: 0.4400\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1505 - accuracy: 0.5745 - val_loss: 1.1938 - val_accuracy: 0.4400\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0479 - accuracy: 0.5585 - val_loss: 1.1876 - val_accuracy: 0.4600\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0153 - accuracy: 0.6436 - val_loss: 1.1986 - val_accuracy: 0.4600\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.1145 - accuracy: 0.5585 - val_loss: 1.2514 - val_accuracy: 0.4400\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0937 - accuracy: 0.5691 - val_loss: 1.3116 - val_accuracy: 0.4400\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9865 - accuracy: 0.6223 - val_loss: 1.3359 - val_accuracy: 0.4400\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9332 - accuracy: 0.5798 - val_loss: 1.3647 - val_accuracy: 0.4000\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8266 - accuracy: 0.6809 - val_loss: 1.3629 - val_accuracy: 0.3800\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0858 - accuracy: 0.6117 - val_loss: 1.3507 - val_accuracy: 0.4000\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9730 - accuracy: 0.6330 - val_loss: 1.3369 - val_accuracy: 0.4000\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8203 - accuracy: 0.6755 - val_loss: 1.3375 - val_accuracy: 0.4000\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9223 - accuracy: 0.6596 - val_loss: 1.3415 - val_accuracy: 0.4000\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9717 - accuracy: 0.6277 - val_loss: 1.3191 - val_accuracy: 0.4000\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8668 - accuracy: 0.6543 - val_loss: 1.3273 - val_accuracy: 0.4000\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9409 - accuracy: 0.6436 - val_loss: 1.3289 - val_accuracy: 0.4000\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9368 - accuracy: 0.6543 - val_loss: 1.3161 - val_accuracy: 0.4000\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8132 - accuracy: 0.7021 - val_loss: 1.3215 - val_accuracy: 0.4000\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7690 - accuracy: 0.7021 - val_loss: 1.3352 - val_accuracy: 0.4000\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9889 - accuracy: 0.6277 - val_loss: 1.3695 - val_accuracy: 0.4000\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9136 - accuracy: 0.6543 - val_loss: 1.3830 - val_accuracy: 0.4000\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9000 - accuracy: 0.6436 - val_loss: 1.3953 - val_accuracy: 0.4200\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.7652 - accuracy: 0.6915 - val_loss: 1.3840 - val_accuracy: 0.4000\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.7298 - accuracy: 0.7021 - val_loss: 1.3296 - val_accuracy: 0.4000\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8753 - accuracy: 0.6915 - val_loss: 1.2927 - val_accuracy: 0.4000\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8421 - accuracy: 0.6915 - val_loss: 1.2566 - val_accuracy: 0.4000\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7951 - accuracy: 0.6862 - val_loss: 1.2441 - val_accuracy: 0.4200\n",
            "Test accuracy of the CNN-LSTM model for subject 6: 0.5799999833106995\n",
            "Shape of X after trimming: (232, 22, 500)\n",
            "Shape of X after maxpooling: (232, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (464, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (928, 22, 250)\n",
            "Shape of X after trimming: (50, 22, 500)\n",
            "Shape of X after maxpooling: (50, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 2s 287ms/step - loss: 2.6380 - accuracy: 0.2527 - val_loss: 2.5333 - val_accuracy: 0.4000\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 2.4160 - accuracy: 0.2473 - val_loss: 2.8990 - val_accuracy: 0.4200\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2.4104 - accuracy: 0.3077 - val_loss: 2.7996 - val_accuracy: 0.3400\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.2722 - accuracy: 0.3297 - val_loss: 2.5273 - val_accuracy: 0.3800\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.3456 - accuracy: 0.3297 - val_loss: 2.4187 - val_accuracy: 0.3400\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.5089 - accuracy: 0.2967 - val_loss: 2.1689 - val_accuracy: 0.3800\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.2407 - accuracy: 0.2967 - val_loss: 1.8527 - val_accuracy: 0.4000\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1402 - accuracy: 0.3462 - val_loss: 1.5581 - val_accuracy: 0.4400\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.4112 - accuracy: 0.2692 - val_loss: 1.4057 - val_accuracy: 0.4600\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.1560 - accuracy: 0.4011 - val_loss: 1.3658 - val_accuracy: 0.4600\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8639 - accuracy: 0.4011 - val_loss: 1.3337 - val_accuracy: 0.5000\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9404 - accuracy: 0.3956 - val_loss: 1.3327 - val_accuracy: 0.5600\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.1919 - accuracy: 0.3187 - val_loss: 1.2871 - val_accuracy: 0.5400\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8538 - accuracy: 0.4231 - val_loss: 1.2426 - val_accuracy: 0.5600\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.7819 - accuracy: 0.4560 - val_loss: 1.2087 - val_accuracy: 0.5600\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.9509 - accuracy: 0.3407 - val_loss: 1.2034 - val_accuracy: 0.5400\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8131 - accuracy: 0.4176 - val_loss: 1.1752 - val_accuracy: 0.5400\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.1318 - accuracy: 0.3681 - val_loss: 1.1615 - val_accuracy: 0.5400\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.8561 - accuracy: 0.3791 - val_loss: 1.1421 - val_accuracy: 0.5400\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.6597 - accuracy: 0.4341 - val_loss: 1.1106 - val_accuracy: 0.5800\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.7538 - accuracy: 0.3736 - val_loss: 1.0988 - val_accuracy: 0.5400\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9410 - accuracy: 0.4011 - val_loss: 1.1031 - val_accuracy: 0.5200\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.9075 - accuracy: 0.4011 - val_loss: 1.1143 - val_accuracy: 0.5400\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.8180 - accuracy: 0.4176 - val_loss: 1.1289 - val_accuracy: 0.5200\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.8878 - accuracy: 0.4011 - val_loss: 1.1710 - val_accuracy: 0.5400\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.7589 - accuracy: 0.4121 - val_loss: 1.1852 - val_accuracy: 0.5400\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.5902 - accuracy: 0.4286 - val_loss: 1.1669 - val_accuracy: 0.5600\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.8875 - accuracy: 0.4396 - val_loss: 1.1270 - val_accuracy: 0.5600\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6893 - accuracy: 0.4121 - val_loss: 1.1026 - val_accuracy: 0.5600\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.7437 - accuracy: 0.3901 - val_loss: 1.0980 - val_accuracy: 0.5600\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.8094 - accuracy: 0.4066 - val_loss: 1.1013 - val_accuracy: 0.5800\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.6958 - accuracy: 0.4615 - val_loss: 1.1053 - val_accuracy: 0.5600\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.6217 - accuracy: 0.3791 - val_loss: 1.1141 - val_accuracy: 0.5600\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6679 - accuracy: 0.4066 - val_loss: 1.1392 - val_accuracy: 0.5600\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5585 - accuracy: 0.4176 - val_loss: 1.1746 - val_accuracy: 0.5200\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.6977 - accuracy: 0.4176 - val_loss: 1.1944 - val_accuracy: 0.5200\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.5396 - accuracy: 0.4560 - val_loss: 1.2088 - val_accuracy: 0.5000\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6250 - accuracy: 0.4176 - val_loss: 1.2103 - val_accuracy: 0.5000\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4482 - accuracy: 0.5440 - val_loss: 1.2121 - val_accuracy: 0.5400\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7096 - accuracy: 0.4341 - val_loss: 1.2232 - val_accuracy: 0.5200\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5796 - accuracy: 0.4341 - val_loss: 1.2377 - val_accuracy: 0.5200\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.4474 - accuracy: 0.4615 - val_loss: 1.2499 - val_accuracy: 0.5000\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4885 - accuracy: 0.4231 - val_loss: 1.2629 - val_accuracy: 0.4800\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.7016 - accuracy: 0.4231 - val_loss: 1.2545 - val_accuracy: 0.4600\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4621 - accuracy: 0.4780 - val_loss: 1.2476 - val_accuracy: 0.5000\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5936 - accuracy: 0.4780 - val_loss: 1.2461 - val_accuracy: 0.5200\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3349 - accuracy: 0.5275 - val_loss: 1.2498 - val_accuracy: 0.5400\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.4575 - accuracy: 0.4560 - val_loss: 1.2527 - val_accuracy: 0.5400\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5741 - accuracy: 0.4505 - val_loss: 1.2597 - val_accuracy: 0.5000\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.5894 - accuracy: 0.4396 - val_loss: 1.2577 - val_accuracy: 0.4800\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.5058 - accuracy: 0.4670 - val_loss: 1.2438 - val_accuracy: 0.5200\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3333 - accuracy: 0.5165 - val_loss: 1.2422 - val_accuracy: 0.5000\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4772 - accuracy: 0.4396 - val_loss: 1.2409 - val_accuracy: 0.5000\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4966 - accuracy: 0.4396 - val_loss: 1.2467 - val_accuracy: 0.5000\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3744 - accuracy: 0.4890 - val_loss: 1.2600 - val_accuracy: 0.5000\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3917 - accuracy: 0.4670 - val_loss: 1.2625 - val_accuracy: 0.5000\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5155 - accuracy: 0.4505 - val_loss: 1.2498 - val_accuracy: 0.5000\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2641 - accuracy: 0.5110 - val_loss: 1.2217 - val_accuracy: 0.5000\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3892 - accuracy: 0.5000 - val_loss: 1.1955 - val_accuracy: 0.5400\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4780 - accuracy: 0.4780 - val_loss: 1.1737 - val_accuracy: 0.5600\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2207 - accuracy: 0.5000 - val_loss: 1.1756 - val_accuracy: 0.6000\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2313 - accuracy: 0.5440 - val_loss: 1.1772 - val_accuracy: 0.5600\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.6398 - accuracy: 0.4725 - val_loss: 1.1872 - val_accuracy: 0.5600\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2833 - accuracy: 0.4945 - val_loss: 1.2015 - val_accuracy: 0.5600\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4064 - accuracy: 0.4670 - val_loss: 1.2097 - val_accuracy: 0.5600\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2184 - accuracy: 0.5055 - val_loss: 1.2091 - val_accuracy: 0.5600\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2010 - accuracy: 0.5385 - val_loss: 1.2113 - val_accuracy: 0.5400\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.1479 - accuracy: 0.5495 - val_loss: 1.2148 - val_accuracy: 0.5400\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2794 - accuracy: 0.5000 - val_loss: 1.2120 - val_accuracy: 0.5400\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2318 - accuracy: 0.5330 - val_loss: 1.2007 - val_accuracy: 0.5600\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2890 - accuracy: 0.5495 - val_loss: 1.1753 - val_accuracy: 0.5200\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1866 - accuracy: 0.5165 - val_loss: 1.1615 - val_accuracy: 0.5200\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3982 - accuracy: 0.5055 - val_loss: 1.1499 - val_accuracy: 0.5600\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4176 - accuracy: 0.4670 - val_loss: 1.1369 - val_accuracy: 0.5800\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1590 - accuracy: 0.5275 - val_loss: 1.1368 - val_accuracy: 0.5800\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1479 - accuracy: 0.5165 - val_loss: 1.1286 - val_accuracy: 0.5600\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0519 - accuracy: 0.5714 - val_loss: 1.1295 - val_accuracy: 0.5600\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1281 - accuracy: 0.5110 - val_loss: 1.1258 - val_accuracy: 0.5600\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.2238 - accuracy: 0.5495 - val_loss: 1.1276 - val_accuracy: 0.5600\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.0255 - accuracy: 0.6154 - val_loss: 1.1196 - val_accuracy: 0.5400\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 1.0309 - accuracy: 0.5659 - val_loss: 1.1099 - val_accuracy: 0.5600\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0438 - accuracy: 0.5495 - val_loss: 1.1161 - val_accuracy: 0.5600\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2052 - accuracy: 0.5385 - val_loss: 1.1184 - val_accuracy: 0.5400\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2006 - accuracy: 0.5385 - val_loss: 1.1379 - val_accuracy: 0.5600\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.1489 - accuracy: 0.5440 - val_loss: 1.1466 - val_accuracy: 0.5400\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0968 - accuracy: 0.5549 - val_loss: 1.1412 - val_accuracy: 0.5200\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9643 - accuracy: 0.5824 - val_loss: 1.1437 - val_accuracy: 0.5200\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0648 - accuracy: 0.5824 - val_loss: 1.1455 - val_accuracy: 0.5000\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1012 - accuracy: 0.6209 - val_loss: 1.1411 - val_accuracy: 0.4800\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0438 - accuracy: 0.6374 - val_loss: 1.1370 - val_accuracy: 0.5200\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0581 - accuracy: 0.5604 - val_loss: 1.1597 - val_accuracy: 0.4800\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0727 - accuracy: 0.5714 - val_loss: 1.1548 - val_accuracy: 0.5200\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8862 - accuracy: 0.6374 - val_loss: 1.1564 - val_accuracy: 0.5000\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0036 - accuracy: 0.5659 - val_loss: 1.1625 - val_accuracy: 0.4800\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.9573 - accuracy: 0.6374 - val_loss: 1.1637 - val_accuracy: 0.4800\n",
            "Test accuracy of the CNN-LSTM model for subject 7: 0.4300000071525574\n",
            "Shape of X after trimming: (231, 22, 500)\n",
            "Shape of X after maxpooling: (231, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (462, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (924, 22, 250)\n",
            "Shape of X after trimming: (47, 22, 500)\n",
            "Shape of X after maxpooling: (47, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (94, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (188, 22, 250)\n",
            "\n",
            "Epoch 1/95\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 2.4571 - accuracy: 0.3149 - val_loss: 8.5949 - val_accuracy: 0.3000\n",
            "Epoch 2/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.3402 - accuracy: 0.3204 - val_loss: 9.4594 - val_accuracy: 0.3000\n",
            "Epoch 3/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.2330 - accuracy: 0.3260 - val_loss: 9.1344 - val_accuracy: 0.3000\n",
            "Epoch 4/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9909 - accuracy: 0.4309 - val_loss: 7.7897 - val_accuracy: 0.3000\n",
            "Epoch 5/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.0204 - accuracy: 0.3867 - val_loss: 6.5478 - val_accuracy: 0.3000\n",
            "Epoch 6/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.1153 - accuracy: 0.4365 - val_loss: 5.4414 - val_accuracy: 0.3000\n",
            "Epoch 7/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.8483 - accuracy: 0.3536 - val_loss: 4.3339 - val_accuracy: 0.3000\n",
            "Epoch 8/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9127 - accuracy: 0.3812 - val_loss: 3.8566 - val_accuracy: 0.3000\n",
            "Epoch 9/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.8421 - accuracy: 0.3757 - val_loss: 3.7367 - val_accuracy: 0.3000\n",
            "Epoch 10/95\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.5367 - accuracy: 0.4144 - val_loss: 3.7874 - val_accuracy: 0.3000\n",
            "Epoch 11/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.9544 - accuracy: 0.3978 - val_loss: 3.6863 - val_accuracy: 0.3000\n",
            "Epoch 12/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.6165 - accuracy: 0.4144 - val_loss: 3.4185 - val_accuracy: 0.3000\n",
            "Epoch 13/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.0630 - accuracy: 0.3978 - val_loss: 3.2507 - val_accuracy: 0.3000\n",
            "Epoch 14/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.6924 - accuracy: 0.4586 - val_loss: 2.9856 - val_accuracy: 0.3000\n",
            "Epoch 15/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.5647 - accuracy: 0.4696 - val_loss: 2.6673 - val_accuracy: 0.3000\n",
            "Epoch 16/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.6658 - accuracy: 0.4254 - val_loss: 2.5330 - val_accuracy: 0.3000\n",
            "Epoch 17/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.5848 - accuracy: 0.4807 - val_loss: 2.4081 - val_accuracy: 0.3000\n",
            "Epoch 18/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4809 - accuracy: 0.4862 - val_loss: 2.2432 - val_accuracy: 0.3400\n",
            "Epoch 19/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.8089 - accuracy: 0.3978 - val_loss: 2.0070 - val_accuracy: 0.3400\n",
            "Epoch 20/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4915 - accuracy: 0.4807 - val_loss: 1.8670 - val_accuracy: 0.4000\n",
            "Epoch 21/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.5478 - accuracy: 0.4917 - val_loss: 1.8154 - val_accuracy: 0.3800\n",
            "Epoch 22/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.2979 - accuracy: 0.5083 - val_loss: 1.8174 - val_accuracy: 0.3600\n",
            "Epoch 23/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4642 - accuracy: 0.5193 - val_loss: 1.7807 - val_accuracy: 0.3600\n",
            "Epoch 24/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.4817 - accuracy: 0.4972 - val_loss: 1.7306 - val_accuracy: 0.3600\n",
            "Epoch 25/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.5409 - accuracy: 0.4972 - val_loss: 1.6623 - val_accuracy: 0.3800\n",
            "Epoch 26/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.4302 - accuracy: 0.5470 - val_loss: 1.5310 - val_accuracy: 0.3800\n",
            "Epoch 27/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.3243 - accuracy: 0.5470 - val_loss: 1.4512 - val_accuracy: 0.4000\n",
            "Epoch 28/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.4874 - accuracy: 0.5083 - val_loss: 1.3629 - val_accuracy: 0.3800\n",
            "Epoch 29/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2902 - accuracy: 0.5359 - val_loss: 1.2384 - val_accuracy: 0.4400\n",
            "Epoch 30/95\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.3815 - accuracy: 0.4530 - val_loss: 1.1824 - val_accuracy: 0.4400\n",
            "Epoch 31/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.3891 - accuracy: 0.5359 - val_loss: 1.1723 - val_accuracy: 0.4200\n",
            "Epoch 32/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2776 - accuracy: 0.5414 - val_loss: 1.1485 - val_accuracy: 0.4200\n",
            "Epoch 33/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.3326 - accuracy: 0.5193 - val_loss: 1.1337 - val_accuracy: 0.4400\n",
            "Epoch 34/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2832 - accuracy: 0.5912 - val_loss: 1.1035 - val_accuracy: 0.4400\n",
            "Epoch 35/95\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.1443 - accuracy: 0.5801 - val_loss: 1.0675 - val_accuracy: 0.5000\n",
            "Epoch 36/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.3777 - accuracy: 0.5249 - val_loss: 1.0380 - val_accuracy: 0.5200\n",
            "Epoch 37/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3506 - accuracy: 0.5635 - val_loss: 0.9851 - val_accuracy: 0.5000\n",
            "Epoch 38/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.9798 - accuracy: 0.5967 - val_loss: 0.9494 - val_accuracy: 0.4800\n",
            "Epoch 39/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2873 - accuracy: 0.5580 - val_loss: 0.9260 - val_accuracy: 0.5000\n",
            "Epoch 40/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.4049 - accuracy: 0.5249 - val_loss: 0.9147 - val_accuracy: 0.5400\n",
            "Epoch 41/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2951 - accuracy: 0.4641 - val_loss: 0.9071 - val_accuracy: 0.5800\n",
            "Epoch 42/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1457 - accuracy: 0.5304 - val_loss: 0.9006 - val_accuracy: 0.6000\n",
            "Epoch 43/95\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0543 - accuracy: 0.6133 - val_loss: 0.8988 - val_accuracy: 0.5600\n",
            "Epoch 44/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.1506 - accuracy: 0.5746 - val_loss: 0.9063 - val_accuracy: 0.5400\n",
            "Epoch 45/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0856 - accuracy: 0.5801 - val_loss: 0.9152 - val_accuracy: 0.5200\n",
            "Epoch 46/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.0951 - accuracy: 0.5525 - val_loss: 0.9458 - val_accuracy: 0.5000\n",
            "Epoch 47/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1164 - accuracy: 0.5691 - val_loss: 0.9861 - val_accuracy: 0.5200\n",
            "Epoch 48/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.0276 - accuracy: 0.6685 - val_loss: 1.0201 - val_accuracy: 0.4600\n",
            "Epoch 49/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0624 - accuracy: 0.6409 - val_loss: 1.0206 - val_accuracy: 0.4600\n",
            "Epoch 50/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0597 - accuracy: 0.5967 - val_loss: 1.0018 - val_accuracy: 0.4800\n",
            "Epoch 51/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.0396 - accuracy: 0.5967 - val_loss: 0.9758 - val_accuracy: 0.5000\n",
            "Epoch 52/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1641 - accuracy: 0.5580 - val_loss: 0.9445 - val_accuracy: 0.6000\n",
            "Epoch 53/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1816 - accuracy: 0.6077 - val_loss: 0.9292 - val_accuracy: 0.6000\n",
            "Epoch 54/95\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0029 - accuracy: 0.6298 - val_loss: 0.9552 - val_accuracy: 0.6000\n",
            "Epoch 55/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0648 - accuracy: 0.6133 - val_loss: 0.9913 - val_accuracy: 0.5800\n",
            "Epoch 56/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9724 - accuracy: 0.6575 - val_loss: 1.0350 - val_accuracy: 0.5400\n",
            "Epoch 57/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.1097 - accuracy: 0.6077 - val_loss: 1.0931 - val_accuracy: 0.5200\n",
            "Epoch 58/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9864 - accuracy: 0.5967 - val_loss: 1.1532 - val_accuracy: 0.4200\n",
            "Epoch 59/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9267 - accuracy: 0.6243 - val_loss: 1.1653 - val_accuracy: 0.4800\n",
            "Epoch 60/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0641 - accuracy: 0.5801 - val_loss: 1.1436 - val_accuracy: 0.5200\n",
            "Epoch 61/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.0540 - accuracy: 0.6298 - val_loss: 1.1279 - val_accuracy: 0.5600\n",
            "Epoch 62/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7670 - accuracy: 0.6961 - val_loss: 1.1094 - val_accuracy: 0.5800\n",
            "Epoch 63/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8357 - accuracy: 0.6740 - val_loss: 1.0978 - val_accuracy: 0.5200\n",
            "Epoch 64/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8562 - accuracy: 0.6796 - val_loss: 1.0841 - val_accuracy: 0.5600\n",
            "Epoch 65/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9495 - accuracy: 0.6685 - val_loss: 1.1124 - val_accuracy: 0.5600\n",
            "Epoch 66/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8975 - accuracy: 0.6685 - val_loss: 1.1440 - val_accuracy: 0.5200\n",
            "Epoch 67/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8947 - accuracy: 0.6298 - val_loss: 1.1817 - val_accuracy: 0.5200\n",
            "Epoch 68/95\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9299 - accuracy: 0.6298 - val_loss: 1.2408 - val_accuracy: 0.5200\n",
            "Epoch 69/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.7087 - accuracy: 0.7127 - val_loss: 1.3037 - val_accuracy: 0.4400\n",
            "Epoch 70/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9049 - accuracy: 0.6796 - val_loss: 1.3592 - val_accuracy: 0.3800\n",
            "Epoch 71/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.8249 - accuracy: 0.7238 - val_loss: 1.3729 - val_accuracy: 0.3800\n",
            "Epoch 72/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9682 - accuracy: 0.6961 - val_loss: 1.3678 - val_accuracy: 0.4200\n",
            "Epoch 73/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.8534 - accuracy: 0.6630 - val_loss: 1.3534 - val_accuracy: 0.4400\n",
            "Epoch 74/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0284 - accuracy: 0.6243 - val_loss: 1.3413 - val_accuracy: 0.4200\n",
            "Epoch 75/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8932 - accuracy: 0.6630 - val_loss: 1.3216 - val_accuracy: 0.4400\n",
            "Epoch 76/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.7595 - accuracy: 0.7127 - val_loss: 1.3087 - val_accuracy: 0.4200\n",
            "Epoch 77/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7799 - accuracy: 0.6906 - val_loss: 1.3081 - val_accuracy: 0.4200\n",
            "Epoch 78/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0182 - accuracy: 0.6630 - val_loss: 1.2981 - val_accuracy: 0.4200\n",
            "Epoch 79/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7251 - accuracy: 0.7293 - val_loss: 1.3109 - val_accuracy: 0.4200\n",
            "Epoch 80/95\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.8489 - accuracy: 0.6630 - val_loss: 1.3335 - val_accuracy: 0.4200\n",
            "Epoch 81/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7814 - accuracy: 0.7072 - val_loss: 1.3824 - val_accuracy: 0.4200\n",
            "Epoch 82/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8408 - accuracy: 0.6906 - val_loss: 1.4409 - val_accuracy: 0.4200\n",
            "Epoch 83/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8622 - accuracy: 0.6851 - val_loss: 1.4633 - val_accuracy: 0.4200\n",
            "Epoch 84/95\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9916 - accuracy: 0.6685 - val_loss: 1.4948 - val_accuracy: 0.4000\n",
            "Epoch 85/95\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.7663 - accuracy: 0.7182 - val_loss: 1.5126 - val_accuracy: 0.4200\n",
            "Epoch 86/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7684 - accuracy: 0.6409 - val_loss: 1.4853 - val_accuracy: 0.4400\n",
            "Epoch 87/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6952 - accuracy: 0.7403 - val_loss: 1.4671 - val_accuracy: 0.4400\n",
            "Epoch 88/95\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6501 - accuracy: 0.7459 - val_loss: 1.4555 - val_accuracy: 0.4200\n",
            "Epoch 89/95\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.8422 - accuracy: 0.6961 - val_loss: 1.4830 - val_accuracy: 0.4200\n",
            "Epoch 90/95\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.7858 - accuracy: 0.7182 - val_loss: 1.5274 - val_accuracy: 0.4000\n",
            "Epoch 91/95\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.7570 - accuracy: 0.7072 - val_loss: 1.5447 - val_accuracy: 0.4000\n",
            "Epoch 92/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7775 - accuracy: 0.7127 - val_loss: 1.5786 - val_accuracy: 0.4000\n",
            "Epoch 93/95\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8142 - accuracy: 0.6851 - val_loss: 1.6228 - val_accuracy: 0.4000\n",
            "Epoch 94/95\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7255 - accuracy: 0.6796 - val_loss: 1.6325 - val_accuracy: 0.4000\n",
            "Epoch 95/95\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6666 - accuracy: 0.7569 - val_loss: 1.6572 - val_accuracy: 0.4000\n",
            "Test accuracy of the CNN-LSTM model for subject 8: 0.44680851697921753\n",
            "Test Accuracy CNN-LSTM on subject wise training: [0.3149999976158142, 0.3700000047683716, 0.5149999856948853, 0.3149999976158142, 0.5265957713127136, 0.4030612111091614, 0.5799999833106995, 0.4300000071525574, 0.44680851697921753]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kPZc_Kzx6PM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis with respect to time"
      ],
      "metadata": {
        "id": "XMytUMMgKcu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading and visualizing the data\n",
        "\n",
        "## Loading the dataset\n",
        "\n",
        "\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Printing the shapes of the numpy arrays\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnzDdpTWSnFb",
        "outputId": "225c2595-9152-45ba-9dec-f078f8637d89"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_valid[y_train_valid==769] = 0\n",
        "y_train_valid[y_train_valid==770] = 1\n",
        "y_train_valid[y_train_valid==771] = 2\n",
        "y_train_valid[y_train_valid==772] = 3\n",
        "\n",
        "y_test[y_test==769] = 0\n",
        "y_test[y_test==770] = 1\n",
        "y_test[y_test==771] = 2\n",
        "y_test[y_test==772] = 3"
      ],
      "metadata": {
        "id": "q4dm0E6VSydw"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random splitting\n",
        "ind_valid = np.random.choice(2115, 500, replace=False)\n",
        "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
        "(x_train, x_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
        "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 4)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 4)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "x_train = np.swapaxes(x_train, 1,3)\n",
        "x_train = np.swapaxes(x_train, 1,2)\n",
        "x_valid = np.swapaxes(x_valid, 1,3)\n",
        "x_valid = np.swapaxes(x_valid, 1,2)\n",
        "\n",
        "x_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "x_test = np.swapaxes(x_test, 1,3)\n",
        "x_test = np.swapaxes(x_test, 1,2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 4)\n",
        "\n",
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "print (x_test.shape)\n",
        "print (y_test.shape)\n",
        "print (x_valid.shape)\n",
        "print (y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r50rpgFfSawU",
        "outputId": "2f2ba0a6-9a4f-43e7-f387-6afe98ff8cb7"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1615, 1000, 1, 22)\n",
            "(1615, 4)\n",
            "(443, 1000, 1, 22)\n",
            "(443, 4)\n",
            "(500, 1000, 1, 22)\n",
            "(500, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0V-vx2-3Ke33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = 0.5\n",
        "learning_rate = 0.00074\n",
        "score_time = np.zeros(5)\n",
        "time       = np.zeros(5)\n",
        "for t in range(5):\n",
        "    basic_cnn_model = Sequential()\n",
        "\n",
        "    # Conv. block 1\n",
        "    basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(100 + t*200,1,22)))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 2\n",
        "    basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 3\n",
        "    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "    # Conv. block 4\n",
        "    basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='relu'))\n",
        "    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    basic_cnn_model.add(BatchNormalization())\n",
        "    basic_cnn_model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "\n",
        "    # Output layer with Softmax activation\n",
        "    basic_cnn_model.add(Flatten()) # Flattens the input\n",
        "\n",
        "    basic_cnn_model.add(tf.keras.layers.Dense((100)))\n",
        "    basic_cnn_model.add(tf.keras.layers.Reshape((100,1)))\n",
        "    basic_cnn_model.add(tf.keras.layers.LSTM(20, dropout=0.6, input_shape=(100,1), return_sequences=False))\n",
        "    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "\n",
        "    # Model parameters\n",
        "    learning_rate =  learning_rate\n",
        "    epochs = 90\n",
        "    cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    # Compiling the model\n",
        "    basic_cnn_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=cnn_optimizer,\n",
        "                    metrics=['accuracy'])\n",
        "    \n",
        "    time[t]   = 100 + t*200\n",
        "    x_train_t = x_train[:,0:100 + t*200,:,:]\n",
        "    x_valid_t = x_valid[:,0:100 + t*200,:,:]  \n",
        "\n",
        "    # Training and validating the model\n",
        "    basic_cnn_model_results = basic_cnn_model.fit(x_train_t,\n",
        "                y_train,\n",
        "                batch_size=64,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_valid_t, y_valid), verbose=True)\n",
        "    \n",
        "    score_time[t] = basic_cnn_model.evaluate(x_valid_t,y_valid, verbose=0)[1]\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xND0xxU8w0rV",
        "outputId": "40ff9cb8-df39-4b8e-bef2-3d97efc99e1d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 1s 15ms/step - loss: 2.4551 - accuracy: 0.2632 - val_loss: 1.4080 - val_accuracy: 0.2900\n",
            "Epoch 2/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 2.3093 - accuracy: 0.2737 - val_loss: 1.4243 - val_accuracy: 0.2960\n",
            "Epoch 3/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2.2172 - accuracy: 0.2731 - val_loss: 1.3881 - val_accuracy: 0.3060\n",
            "Epoch 4/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1090 - accuracy: 0.2409 - val_loss: 1.3703 - val_accuracy: 0.3080\n",
            "Epoch 5/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.9496 - accuracy: 0.2619 - val_loss: 1.3813 - val_accuracy: 0.3100\n",
            "Epoch 6/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.8921 - accuracy: 0.2700 - val_loss: 1.3814 - val_accuracy: 0.2780\n",
            "Epoch 7/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.8525 - accuracy: 0.2706 - val_loss: 1.3631 - val_accuracy: 0.3120\n",
            "Epoch 8/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7998 - accuracy: 0.2780 - val_loss: 1.4152 - val_accuracy: 0.3020\n",
            "Epoch 9/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.7481 - accuracy: 0.2768 - val_loss: 1.3723 - val_accuracy: 0.3160\n",
            "Epoch 10/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.6733 - accuracy: 0.2755 - val_loss: 1.3727 - val_accuracy: 0.3140\n",
            "Epoch 11/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6956 - accuracy: 0.2613 - val_loss: 1.3777 - val_accuracy: 0.2840\n",
            "Epoch 12/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6419 - accuracy: 0.2947 - val_loss: 1.3848 - val_accuracy: 0.2860\n",
            "Epoch 13/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5918 - accuracy: 0.2805 - val_loss: 1.3719 - val_accuracy: 0.3440\n",
            "Epoch 14/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.5809 - accuracy: 0.2706 - val_loss: 1.3627 - val_accuracy: 0.3080\n",
            "Epoch 15/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.5379 - accuracy: 0.2947 - val_loss: 1.3698 - val_accuracy: 0.3320\n",
            "Epoch 16/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5445 - accuracy: 0.2854 - val_loss: 1.3938 - val_accuracy: 0.2800\n",
            "Epoch 17/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4969 - accuracy: 0.2991 - val_loss: 1.3707 - val_accuracy: 0.3060\n",
            "Epoch 18/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.5102 - accuracy: 0.2811 - val_loss: 1.3714 - val_accuracy: 0.2940\n",
            "Epoch 19/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4822 - accuracy: 0.2910 - val_loss: 1.3918 - val_accuracy: 0.2820\n",
            "Epoch 20/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4841 - accuracy: 0.2830 - val_loss: 1.3713 - val_accuracy: 0.3340\n",
            "Epoch 21/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4651 - accuracy: 0.3046 - val_loss: 1.3835 - val_accuracy: 0.2680\n",
            "Epoch 22/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.4665 - accuracy: 0.2966 - val_loss: 1.3527 - val_accuracy: 0.3320\n",
            "Epoch 23/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4592 - accuracy: 0.2799 - val_loss: 1.3749 - val_accuracy: 0.3120\n",
            "Epoch 24/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4174 - accuracy: 0.3406 - val_loss: 1.3620 - val_accuracy: 0.3120\n",
            "Epoch 25/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4393 - accuracy: 0.3028 - val_loss: 1.3621 - val_accuracy: 0.3640\n",
            "Epoch 26/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4444 - accuracy: 0.2991 - val_loss: 1.3645 - val_accuracy: 0.2980\n",
            "Epoch 27/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4143 - accuracy: 0.3133 - val_loss: 1.3625 - val_accuracy: 0.2960\n",
            "Epoch 28/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4155 - accuracy: 0.3003 - val_loss: 1.3704 - val_accuracy: 0.2800\n",
            "Epoch 29/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3995 - accuracy: 0.3356 - val_loss: 1.3801 - val_accuracy: 0.2880\n",
            "Epoch 30/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3887 - accuracy: 0.3238 - val_loss: 1.3629 - val_accuracy: 0.3320\n",
            "Epoch 31/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3945 - accuracy: 0.3096 - val_loss: 1.3585 - val_accuracy: 0.3480\n",
            "Epoch 32/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3878 - accuracy: 0.3133 - val_loss: 1.3721 - val_accuracy: 0.2940\n",
            "Epoch 33/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3859 - accuracy: 0.3294 - val_loss: 1.3732 - val_accuracy: 0.3180\n",
            "Epoch 34/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3858 - accuracy: 0.3362 - val_loss: 1.3744 - val_accuracy: 0.2940\n",
            "Epoch 35/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.4024 - accuracy: 0.3276 - val_loss: 1.3538 - val_accuracy: 0.3080\n",
            "Epoch 36/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3881 - accuracy: 0.3294 - val_loss: 1.3535 - val_accuracy: 0.3220\n",
            "Epoch 37/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3618 - accuracy: 0.3461 - val_loss: 1.3642 - val_accuracy: 0.3040\n",
            "Epoch 38/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3589 - accuracy: 0.3523 - val_loss: 1.3431 - val_accuracy: 0.3420\n",
            "Epoch 39/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3598 - accuracy: 0.3480 - val_loss: 1.3403 - val_accuracy: 0.3700\n",
            "Epoch 40/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3433 - accuracy: 0.3523 - val_loss: 1.3415 - val_accuracy: 0.3560\n",
            "Epoch 41/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3523 - accuracy: 0.3542 - val_loss: 1.3492 - val_accuracy: 0.3320\n",
            "Epoch 42/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3525 - accuracy: 0.3505 - val_loss: 1.3493 - val_accuracy: 0.3440\n",
            "Epoch 43/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3330 - accuracy: 0.3554 - val_loss: 1.3348 - val_accuracy: 0.3740\n",
            "Epoch 44/90\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 1.3514 - accuracy: 0.3498 - val_loss: 1.3254 - val_accuracy: 0.3780\n",
            "Epoch 45/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3377 - accuracy: 0.3622 - val_loss: 1.3244 - val_accuracy: 0.3860\n",
            "Epoch 46/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3344 - accuracy: 0.3567 - val_loss: 1.3193 - val_accuracy: 0.3940\n",
            "Epoch 47/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3272 - accuracy: 0.3703 - val_loss: 1.3323 - val_accuracy: 0.3780\n",
            "Epoch 48/90\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 1.3218 - accuracy: 0.3783 - val_loss: 1.3292 - val_accuracy: 0.3960\n",
            "Epoch 49/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3228 - accuracy: 0.3666 - val_loss: 1.3257 - val_accuracy: 0.3860\n",
            "Epoch 50/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3236 - accuracy: 0.3703 - val_loss: 1.3284 - val_accuracy: 0.3940\n",
            "Epoch 51/90\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 1.3131 - accuracy: 0.3957 - val_loss: 1.3007 - val_accuracy: 0.4060\n",
            "Epoch 52/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3033 - accuracy: 0.3721 - val_loss: 1.3143 - val_accuracy: 0.3800\n",
            "Epoch 53/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3031 - accuracy: 0.3932 - val_loss: 1.2985 - val_accuracy: 0.4100\n",
            "Epoch 54/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3238 - accuracy: 0.3690 - val_loss: 1.2969 - val_accuracy: 0.4280\n",
            "Epoch 55/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2992 - accuracy: 0.3814 - val_loss: 1.2856 - val_accuracy: 0.4160\n",
            "Epoch 56/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3333 - accuracy: 0.3839 - val_loss: 1.2913 - val_accuracy: 0.4160\n",
            "Epoch 57/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2955 - accuracy: 0.4012 - val_loss: 1.3290 - val_accuracy: 0.3880\n",
            "Epoch 58/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2998 - accuracy: 0.3783 - val_loss: 1.3017 - val_accuracy: 0.4080\n",
            "Epoch 59/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2990 - accuracy: 0.3975 - val_loss: 1.3106 - val_accuracy: 0.4040\n",
            "Epoch 60/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3003 - accuracy: 0.3851 - val_loss: 1.3012 - val_accuracy: 0.4000\n",
            "Epoch 61/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2970 - accuracy: 0.4050 - val_loss: 1.3131 - val_accuracy: 0.3940\n",
            "Epoch 62/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.3051 - accuracy: 0.3944 - val_loss: 1.2734 - val_accuracy: 0.4260\n",
            "Epoch 63/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2949 - accuracy: 0.3932 - val_loss: 1.3063 - val_accuracy: 0.4120\n",
            "Epoch 64/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2768 - accuracy: 0.4235 - val_loss: 1.2967 - val_accuracy: 0.3980\n",
            "Epoch 65/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2808 - accuracy: 0.4043 - val_loss: 1.2649 - val_accuracy: 0.4180\n",
            "Epoch 66/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2708 - accuracy: 0.3932 - val_loss: 1.2945 - val_accuracy: 0.3920\n",
            "Epoch 67/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2531 - accuracy: 0.4334 - val_loss: 1.2999 - val_accuracy: 0.4220\n",
            "Epoch 68/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2524 - accuracy: 0.4192 - val_loss: 1.3021 - val_accuracy: 0.3880\n",
            "Epoch 69/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2646 - accuracy: 0.4272 - val_loss: 1.2916 - val_accuracy: 0.4040\n",
            "Epoch 70/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2801 - accuracy: 0.4031 - val_loss: 1.2662 - val_accuracy: 0.4260\n",
            "Epoch 71/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2670 - accuracy: 0.4359 - val_loss: 1.2367 - val_accuracy: 0.4460\n",
            "Epoch 72/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2458 - accuracy: 0.4384 - val_loss: 1.2777 - val_accuracy: 0.4100\n",
            "Epoch 73/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2496 - accuracy: 0.4198 - val_loss: 1.2431 - val_accuracy: 0.4420\n",
            "Epoch 74/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2540 - accuracy: 0.4279 - val_loss: 1.2546 - val_accuracy: 0.4180\n",
            "Epoch 75/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2554 - accuracy: 0.4229 - val_loss: 1.2379 - val_accuracy: 0.4400\n",
            "Epoch 76/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2312 - accuracy: 0.4409 - val_loss: 1.2771 - val_accuracy: 0.4060\n",
            "Epoch 77/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2290 - accuracy: 0.4433 - val_loss: 1.2313 - val_accuracy: 0.4480\n",
            "Epoch 78/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2663 - accuracy: 0.4241 - val_loss: 1.2821 - val_accuracy: 0.4000\n",
            "Epoch 79/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2555 - accuracy: 0.4223 - val_loss: 1.2657 - val_accuracy: 0.4100\n",
            "Epoch 80/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2336 - accuracy: 0.4533 - val_loss: 1.2731 - val_accuracy: 0.3920\n",
            "Epoch 81/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2407 - accuracy: 0.4452 - val_loss: 1.2353 - val_accuracy: 0.4360\n",
            "Epoch 82/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2201 - accuracy: 0.4483 - val_loss: 1.2182 - val_accuracy: 0.4460\n",
            "Epoch 83/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2365 - accuracy: 0.4402 - val_loss: 1.2452 - val_accuracy: 0.4220\n",
            "Epoch 84/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2288 - accuracy: 0.4353 - val_loss: 1.2210 - val_accuracy: 0.4640\n",
            "Epoch 85/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2118 - accuracy: 0.4613 - val_loss: 1.2423 - val_accuracy: 0.4320\n",
            "Epoch 86/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2059 - accuracy: 0.4545 - val_loss: 1.2750 - val_accuracy: 0.4260\n",
            "Epoch 87/90\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.2084 - accuracy: 0.4551 - val_loss: 1.2017 - val_accuracy: 0.4560\n",
            "Epoch 88/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2028 - accuracy: 0.4700 - val_loss: 1.2258 - val_accuracy: 0.4400\n",
            "Epoch 89/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2096 - accuracy: 0.4712 - val_loss: 1.2069 - val_accuracy: 0.4680\n",
            "Epoch 90/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2246 - accuracy: 0.4576 - val_loss: 1.1841 - val_accuracy: 0.4620\n",
            "Epoch 1/90\n",
            "26/26 [==============================] - 1s 18ms/step - loss: 2.4313 - accuracy: 0.2836 - val_loss: 1.9062 - val_accuracy: 0.2620\n",
            "Epoch 2/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3189 - accuracy: 0.2644 - val_loss: 1.4158 - val_accuracy: 0.3260\n",
            "Epoch 3/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2320 - accuracy: 0.2892 - val_loss: 1.3847 - val_accuracy: 0.3180\n",
            "Epoch 4/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.1831 - accuracy: 0.2749 - val_loss: 1.3468 - val_accuracy: 0.3540\n",
            "Epoch 5/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.0152 - accuracy: 0.2879 - val_loss: 1.3572 - val_accuracy: 0.3200\n",
            "Epoch 6/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.9171 - accuracy: 0.3040 - val_loss: 1.3737 - val_accuracy: 0.2960\n",
            "Epoch 7/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.8533 - accuracy: 0.2991 - val_loss: 1.3631 - val_accuracy: 0.3160\n",
            "Epoch 8/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.7438 - accuracy: 0.3071 - val_loss: 1.4434 - val_accuracy: 0.2580\n",
            "Epoch 9/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.7806 - accuracy: 0.2904 - val_loss: 1.3704 - val_accuracy: 0.2820\n",
            "Epoch 10/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.7203 - accuracy: 0.3090 - val_loss: 1.4031 - val_accuracy: 0.2720\n",
            "Epoch 11/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.6214 - accuracy: 0.3189 - val_loss: 1.3869 - val_accuracy: 0.2700\n",
            "Epoch 12/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.6432 - accuracy: 0.3139 - val_loss: 1.3634 - val_accuracy: 0.2880\n",
            "Epoch 13/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6040 - accuracy: 0.3183 - val_loss: 1.3774 - val_accuracy: 0.3040\n",
            "Epoch 14/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5810 - accuracy: 0.3034 - val_loss: 1.3453 - val_accuracy: 0.3060\n",
            "Epoch 15/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5257 - accuracy: 0.3418 - val_loss: 1.3624 - val_accuracy: 0.3140\n",
            "Epoch 16/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5168 - accuracy: 0.3232 - val_loss: 1.4064 - val_accuracy: 0.2740\n",
            "Epoch 17/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.4707 - accuracy: 0.3362 - val_loss: 1.4222 - val_accuracy: 0.2460\n",
            "Epoch 18/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4298 - accuracy: 0.3678 - val_loss: 1.3451 - val_accuracy: 0.3100\n",
            "Epoch 19/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.4504 - accuracy: 0.3375 - val_loss: 1.3753 - val_accuracy: 0.3100\n",
            "Epoch 20/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4282 - accuracy: 0.3573 - val_loss: 1.3652 - val_accuracy: 0.3200\n",
            "Epoch 21/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4027 - accuracy: 0.3560 - val_loss: 1.3805 - val_accuracy: 0.3180\n",
            "Epoch 22/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3966 - accuracy: 0.3690 - val_loss: 1.3322 - val_accuracy: 0.2920\n",
            "Epoch 23/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3546 - accuracy: 0.3759 - val_loss: 1.3453 - val_accuracy: 0.3160\n",
            "Epoch 24/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3428 - accuracy: 0.3913 - val_loss: 1.3291 - val_accuracy: 0.3440\n",
            "Epoch 25/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3354 - accuracy: 0.3839 - val_loss: 1.2966 - val_accuracy: 0.3860\n",
            "Epoch 26/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3263 - accuracy: 0.4111 - val_loss: 1.3135 - val_accuracy: 0.3720\n",
            "Epoch 27/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2836 - accuracy: 0.4118 - val_loss: 1.3395 - val_accuracy: 0.3780\n",
            "Epoch 28/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3041 - accuracy: 0.4025 - val_loss: 1.3472 - val_accuracy: 0.3780\n",
            "Epoch 29/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2911 - accuracy: 0.4093 - val_loss: 1.2981 - val_accuracy: 0.3460\n",
            "Epoch 30/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2961 - accuracy: 0.4080 - val_loss: 1.3554 - val_accuracy: 0.3580\n",
            "Epoch 31/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2788 - accuracy: 0.4322 - val_loss: 1.2820 - val_accuracy: 0.3640\n",
            "Epoch 32/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2716 - accuracy: 0.4390 - val_loss: 1.2558 - val_accuracy: 0.4600\n",
            "Epoch 33/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2540 - accuracy: 0.4341 - val_loss: 1.2879 - val_accuracy: 0.3860\n",
            "Epoch 34/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2429 - accuracy: 0.4254 - val_loss: 1.2521 - val_accuracy: 0.4520\n",
            "Epoch 35/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2391 - accuracy: 0.4489 - val_loss: 1.2574 - val_accuracy: 0.4060\n",
            "Epoch 36/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2237 - accuracy: 0.4613 - val_loss: 1.2460 - val_accuracy: 0.4160\n",
            "Epoch 37/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2172 - accuracy: 0.4625 - val_loss: 1.2416 - val_accuracy: 0.4360\n",
            "Epoch 38/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2245 - accuracy: 0.4613 - val_loss: 1.2558 - val_accuracy: 0.4140\n",
            "Epoch 39/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2090 - accuracy: 0.4588 - val_loss: 1.2419 - val_accuracy: 0.4240\n",
            "Epoch 40/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1899 - accuracy: 0.4836 - val_loss: 1.2233 - val_accuracy: 0.4240\n",
            "Epoch 41/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1980 - accuracy: 0.4700 - val_loss: 1.2102 - val_accuracy: 0.4560\n",
            "Epoch 42/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2105 - accuracy: 0.4675 - val_loss: 1.2302 - val_accuracy: 0.4100\n",
            "Epoch 43/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1905 - accuracy: 0.4749 - val_loss: 1.2006 - val_accuracy: 0.4620\n",
            "Epoch 44/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1928 - accuracy: 0.4762 - val_loss: 1.1969 - val_accuracy: 0.4820\n",
            "Epoch 45/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1641 - accuracy: 0.4972 - val_loss: 1.2151 - val_accuracy: 0.4360\n",
            "Epoch 46/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1844 - accuracy: 0.4836 - val_loss: 1.1873 - val_accuracy: 0.4840\n",
            "Epoch 47/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1771 - accuracy: 0.4805 - val_loss: 1.1953 - val_accuracy: 0.4460\n",
            "Epoch 48/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1474 - accuracy: 0.5102 - val_loss: 1.1721 - val_accuracy: 0.4760\n",
            "Epoch 49/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1545 - accuracy: 0.4991 - val_loss: 1.1888 - val_accuracy: 0.4740\n",
            "Epoch 50/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1856 - accuracy: 0.4923 - val_loss: 1.1655 - val_accuracy: 0.4660\n",
            "Epoch 51/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1179 - accuracy: 0.5337 - val_loss: 1.1956 - val_accuracy: 0.4340\n",
            "Epoch 52/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1356 - accuracy: 0.5046 - val_loss: 1.1511 - val_accuracy: 0.5020\n",
            "Epoch 53/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1266 - accuracy: 0.5040 - val_loss: 1.1477 - val_accuracy: 0.5000\n",
            "Epoch 54/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1363 - accuracy: 0.5077 - val_loss: 1.1646 - val_accuracy: 0.4700\n",
            "Epoch 55/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1095 - accuracy: 0.5288 - val_loss: 1.1507 - val_accuracy: 0.4880\n",
            "Epoch 56/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1230 - accuracy: 0.5220 - val_loss: 1.1433 - val_accuracy: 0.4800\n",
            "Epoch 57/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1241 - accuracy: 0.5152 - val_loss: 1.2014 - val_accuracy: 0.4800\n",
            "Epoch 58/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1182 - accuracy: 0.5133 - val_loss: 1.1458 - val_accuracy: 0.4780\n",
            "Epoch 59/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1003 - accuracy: 0.5201 - val_loss: 1.1651 - val_accuracy: 0.4700\n",
            "Epoch 60/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0924 - accuracy: 0.5412 - val_loss: 1.1152 - val_accuracy: 0.5000\n",
            "Epoch 61/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1026 - accuracy: 0.5350 - val_loss: 1.1115 - val_accuracy: 0.5240\n",
            "Epoch 62/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0780 - accuracy: 0.5474 - val_loss: 1.1134 - val_accuracy: 0.5080\n",
            "Epoch 63/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0931 - accuracy: 0.5257 - val_loss: 1.1544 - val_accuracy: 0.4840\n",
            "Epoch 64/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0619 - accuracy: 0.5412 - val_loss: 1.1131 - val_accuracy: 0.4980\n",
            "Epoch 65/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0730 - accuracy: 0.5276 - val_loss: 1.0900 - val_accuracy: 0.5300\n",
            "Epoch 66/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0622 - accuracy: 0.5542 - val_loss: 1.1034 - val_accuracy: 0.5120\n",
            "Epoch 67/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0590 - accuracy: 0.5467 - val_loss: 1.0868 - val_accuracy: 0.5100\n",
            "Epoch 68/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0419 - accuracy: 0.5598 - val_loss: 1.0830 - val_accuracy: 0.5480\n",
            "Epoch 69/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0647 - accuracy: 0.5517 - val_loss: 1.0727 - val_accuracy: 0.5200\n",
            "Epoch 70/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0233 - accuracy: 0.5715 - val_loss: 1.1107 - val_accuracy: 0.5160\n",
            "Epoch 71/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0434 - accuracy: 0.5610 - val_loss: 1.0601 - val_accuracy: 0.5420\n",
            "Epoch 72/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0236 - accuracy: 0.5635 - val_loss: 1.0491 - val_accuracy: 0.5540\n",
            "Epoch 73/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0177 - accuracy: 0.5777 - val_loss: 1.0467 - val_accuracy: 0.5400\n",
            "Epoch 74/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0397 - accuracy: 0.5616 - val_loss: 1.0447 - val_accuracy: 0.5600\n",
            "Epoch 75/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0165 - accuracy: 0.5783 - val_loss: 1.0395 - val_accuracy: 0.5700\n",
            "Epoch 76/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0066 - accuracy: 0.5783 - val_loss: 1.0323 - val_accuracy: 0.5660\n",
            "Epoch 77/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.0175 - accuracy: 0.5666 - val_loss: 1.0406 - val_accuracy: 0.5580\n",
            "Epoch 78/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0250 - accuracy: 0.5647 - val_loss: 1.0874 - val_accuracy: 0.5260\n",
            "Epoch 79/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9937 - accuracy: 0.5789 - val_loss: 1.0303 - val_accuracy: 0.5580\n",
            "Epoch 80/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9937 - accuracy: 0.5777 - val_loss: 1.1016 - val_accuracy: 0.5400\n",
            "Epoch 81/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0075 - accuracy: 0.5740 - val_loss: 1.0335 - val_accuracy: 0.5460\n",
            "Epoch 82/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9753 - accuracy: 0.5944 - val_loss: 1.0060 - val_accuracy: 0.5680\n",
            "Epoch 83/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9859 - accuracy: 0.5851 - val_loss: 1.0133 - val_accuracy: 0.5700\n",
            "Epoch 84/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9846 - accuracy: 0.5932 - val_loss: 1.0059 - val_accuracy: 0.5920\n",
            "Epoch 85/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9810 - accuracy: 0.6012 - val_loss: 1.0241 - val_accuracy: 0.5600\n",
            "Epoch 86/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9619 - accuracy: 0.6056 - val_loss: 1.0147 - val_accuracy: 0.5680\n",
            "Epoch 87/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9448 - accuracy: 0.6155 - val_loss: 0.9987 - val_accuracy: 0.5800\n",
            "Epoch 88/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9449 - accuracy: 0.5988 - val_loss: 1.0145 - val_accuracy: 0.5580\n",
            "Epoch 89/90\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9366 - accuracy: 0.6167 - val_loss: 1.0673 - val_accuracy: 0.5360\n",
            "Epoch 90/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9341 - accuracy: 0.6142 - val_loss: 0.9991 - val_accuracy: 0.5660\n",
            "Epoch 1/90\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 2.4531 - accuracy: 0.2508 - val_loss: 1.7700 - val_accuracy: 0.3140\n",
            "Epoch 2/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 2.2720 - accuracy: 0.2836 - val_loss: 1.3443 - val_accuracy: 0.3620\n",
            "Epoch 3/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1283 - accuracy: 0.3257 - val_loss: 1.3691 - val_accuracy: 0.3600\n",
            "Epoch 4/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.9970 - accuracy: 0.3152 - val_loss: 1.3734 - val_accuracy: 0.3460\n",
            "Epoch 5/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.9940 - accuracy: 0.3102 - val_loss: 1.4287 - val_accuracy: 0.2940\n",
            "Epoch 6/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.9325 - accuracy: 0.3071 - val_loss: 1.4612 - val_accuracy: 0.2860\n",
            "Epoch 7/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.8979 - accuracy: 0.2978 - val_loss: 1.3781 - val_accuracy: 0.3140\n",
            "Epoch 8/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7512 - accuracy: 0.3368 - val_loss: 1.4510 - val_accuracy: 0.2740\n",
            "Epoch 9/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.6917 - accuracy: 0.3486 - val_loss: 1.3707 - val_accuracy: 0.3400\n",
            "Epoch 10/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7022 - accuracy: 0.3375 - val_loss: 1.3669 - val_accuracy: 0.2960\n",
            "Epoch 11/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6156 - accuracy: 0.3418 - val_loss: 1.4345 - val_accuracy: 0.3100\n",
            "Epoch 12/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5880 - accuracy: 0.3288 - val_loss: 1.4665 - val_accuracy: 0.2980\n",
            "Epoch 13/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.5525 - accuracy: 0.3610 - val_loss: 1.3529 - val_accuracy: 0.3420\n",
            "Epoch 14/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5156 - accuracy: 0.3585 - val_loss: 1.3578 - val_accuracy: 0.3280\n",
            "Epoch 15/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.4789 - accuracy: 0.3666 - val_loss: 1.3245 - val_accuracy: 0.3140\n",
            "Epoch 16/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4728 - accuracy: 0.3666 - val_loss: 1.4338 - val_accuracy: 0.2780\n",
            "Epoch 17/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.4419 - accuracy: 0.4006 - val_loss: 1.4426 - val_accuracy: 0.2920\n",
            "Epoch 18/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3672 - accuracy: 0.4105 - val_loss: 1.2898 - val_accuracy: 0.4040\n",
            "Epoch 19/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3933 - accuracy: 0.4080 - val_loss: 1.4376 - val_accuracy: 0.2980\n",
            "Epoch 20/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3750 - accuracy: 0.4074 - val_loss: 1.3250 - val_accuracy: 0.3420\n",
            "Epoch 21/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.3047 - accuracy: 0.4328 - val_loss: 1.2562 - val_accuracy: 0.4200\n",
            "Epoch 22/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3164 - accuracy: 0.4310 - val_loss: 1.3342 - val_accuracy: 0.3520\n",
            "Epoch 23/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2659 - accuracy: 0.4458 - val_loss: 1.3009 - val_accuracy: 0.3580\n",
            "Epoch 24/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2549 - accuracy: 0.4570 - val_loss: 1.3770 - val_accuracy: 0.3480\n",
            "Epoch 25/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.2360 - accuracy: 0.4650 - val_loss: 1.2222 - val_accuracy: 0.4420\n",
            "Epoch 26/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2602 - accuracy: 0.4452 - val_loss: 1.2472 - val_accuracy: 0.4140\n",
            "Epoch 27/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2415 - accuracy: 0.4588 - val_loss: 1.3250 - val_accuracy: 0.3680\n",
            "Epoch 28/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2408 - accuracy: 0.4601 - val_loss: 1.2150 - val_accuracy: 0.4700\n",
            "Epoch 29/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2357 - accuracy: 0.4489 - val_loss: 1.2320 - val_accuracy: 0.4400\n",
            "Epoch 30/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1998 - accuracy: 0.4842 - val_loss: 1.2418 - val_accuracy: 0.4160\n",
            "Epoch 31/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1905 - accuracy: 0.4712 - val_loss: 1.2385 - val_accuracy: 0.4240\n",
            "Epoch 32/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1519 - accuracy: 0.4960 - val_loss: 1.2047 - val_accuracy: 0.4480\n",
            "Epoch 33/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1468 - accuracy: 0.5028 - val_loss: 1.2763 - val_accuracy: 0.4120\n",
            "Epoch 34/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1889 - accuracy: 0.4786 - val_loss: 1.2448 - val_accuracy: 0.4020\n",
            "Epoch 35/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1679 - accuracy: 0.4892 - val_loss: 1.2439 - val_accuracy: 0.4340\n",
            "Epoch 36/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1811 - accuracy: 0.5046 - val_loss: 1.2125 - val_accuracy: 0.4380\n",
            "Epoch 37/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1494 - accuracy: 0.5127 - val_loss: 1.1647 - val_accuracy: 0.5140\n",
            "Epoch 38/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0984 - accuracy: 0.5201 - val_loss: 1.1294 - val_accuracy: 0.5140\n",
            "Epoch 39/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1160 - accuracy: 0.5220 - val_loss: 1.1671 - val_accuracy: 0.5140\n",
            "Epoch 40/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1045 - accuracy: 0.5207 - val_loss: 1.1406 - val_accuracy: 0.4880\n",
            "Epoch 41/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0976 - accuracy: 0.5418 - val_loss: 1.1676 - val_accuracy: 0.4740\n",
            "Epoch 42/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1382 - accuracy: 0.5294 - val_loss: 1.1283 - val_accuracy: 0.5320\n",
            "Epoch 43/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0770 - accuracy: 0.5560 - val_loss: 1.1642 - val_accuracy: 0.4740\n",
            "Epoch 44/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0551 - accuracy: 0.5585 - val_loss: 1.0940 - val_accuracy: 0.5540\n",
            "Epoch 45/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0501 - accuracy: 0.5659 - val_loss: 1.1252 - val_accuracy: 0.5200\n",
            "Epoch 46/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0379 - accuracy: 0.5659 - val_loss: 1.0650 - val_accuracy: 0.5800\n",
            "Epoch 47/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0298 - accuracy: 0.5523 - val_loss: 1.0803 - val_accuracy: 0.5440\n",
            "Epoch 48/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0276 - accuracy: 0.5777 - val_loss: 1.1026 - val_accuracy: 0.5280\n",
            "Epoch 49/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9908 - accuracy: 0.5833 - val_loss: 1.0673 - val_accuracy: 0.5360\n",
            "Epoch 50/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0243 - accuracy: 0.5789 - val_loss: 1.0343 - val_accuracy: 0.5980\n",
            "Epoch 51/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0182 - accuracy: 0.5628 - val_loss: 1.0585 - val_accuracy: 0.5560\n",
            "Epoch 52/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0329 - accuracy: 0.5715 - val_loss: 1.1306 - val_accuracy: 0.4760\n",
            "Epoch 53/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0123 - accuracy: 0.5882 - val_loss: 1.0989 - val_accuracy: 0.5380\n",
            "Epoch 54/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9573 - accuracy: 0.6105 - val_loss: 1.0956 - val_accuracy: 0.5340\n",
            "Epoch 55/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9866 - accuracy: 0.5889 - val_loss: 1.0690 - val_accuracy: 0.5300\n",
            "Epoch 56/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9637 - accuracy: 0.5944 - val_loss: 1.0014 - val_accuracy: 0.6080\n",
            "Epoch 57/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9866 - accuracy: 0.5870 - val_loss: 1.0374 - val_accuracy: 0.5640\n",
            "Epoch 58/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0029 - accuracy: 0.5858 - val_loss: 1.0512 - val_accuracy: 0.5620\n",
            "Epoch 59/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9582 - accuracy: 0.6111 - val_loss: 1.0553 - val_accuracy: 0.5500\n",
            "Epoch 60/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9491 - accuracy: 0.6087 - val_loss: 0.9860 - val_accuracy: 0.6140\n",
            "Epoch 61/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9503 - accuracy: 0.6006 - val_loss: 1.0164 - val_accuracy: 0.5820\n",
            "Epoch 62/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9361 - accuracy: 0.6272 - val_loss: 0.9639 - val_accuracy: 0.6240\n",
            "Epoch 63/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9444 - accuracy: 0.6111 - val_loss: 0.9615 - val_accuracy: 0.6200\n",
            "Epoch 64/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9506 - accuracy: 0.6074 - val_loss: 1.1270 - val_accuracy: 0.4860\n",
            "Epoch 65/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9461 - accuracy: 0.6068 - val_loss: 0.9939 - val_accuracy: 0.6100\n",
            "Epoch 66/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9160 - accuracy: 0.6211 - val_loss: 0.9698 - val_accuracy: 0.6060\n",
            "Epoch 67/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9287 - accuracy: 0.6192 - val_loss: 0.9954 - val_accuracy: 0.5960\n",
            "Epoch 68/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9090 - accuracy: 0.6477 - val_loss: 0.9653 - val_accuracy: 0.6080\n",
            "Epoch 69/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9123 - accuracy: 0.6328 - val_loss: 0.9539 - val_accuracy: 0.6200\n",
            "Epoch 70/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9066 - accuracy: 0.6359 - val_loss: 0.9408 - val_accuracy: 0.6320\n",
            "Epoch 71/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9070 - accuracy: 0.6328 - val_loss: 1.0022 - val_accuracy: 0.5800\n",
            "Epoch 72/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8928 - accuracy: 0.6502 - val_loss: 0.9594 - val_accuracy: 0.6100\n",
            "Epoch 73/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8884 - accuracy: 0.6477 - val_loss: 0.9053 - val_accuracy: 0.6560\n",
            "Epoch 74/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9412 - accuracy: 0.6149 - val_loss: 0.9311 - val_accuracy: 0.6280\n",
            "Epoch 75/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8913 - accuracy: 0.6341 - val_loss: 1.0084 - val_accuracy: 0.5740\n",
            "Epoch 76/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8731 - accuracy: 0.6440 - val_loss: 0.9081 - val_accuracy: 0.6500\n",
            "Epoch 77/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9009 - accuracy: 0.6322 - val_loss: 0.9133 - val_accuracy: 0.6420\n",
            "Epoch 78/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8268 - accuracy: 0.6625 - val_loss: 0.9506 - val_accuracy: 0.6060\n",
            "Epoch 79/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8773 - accuracy: 0.6409 - val_loss: 0.8892 - val_accuracy: 0.6500\n",
            "Epoch 80/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8345 - accuracy: 0.6582 - val_loss: 0.9020 - val_accuracy: 0.6300\n",
            "Epoch 81/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8390 - accuracy: 0.6576 - val_loss: 0.9037 - val_accuracy: 0.6320\n",
            "Epoch 82/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8510 - accuracy: 0.6514 - val_loss: 0.8823 - val_accuracy: 0.6520\n",
            "Epoch 83/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8324 - accuracy: 0.6588 - val_loss: 0.8770 - val_accuracy: 0.6440\n",
            "Epoch 84/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8141 - accuracy: 0.6669 - val_loss: 0.8419 - val_accuracy: 0.6840\n",
            "Epoch 85/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8221 - accuracy: 0.6718 - val_loss: 0.8563 - val_accuracy: 0.6660\n",
            "Epoch 86/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.7976 - accuracy: 0.6793 - val_loss: 0.9242 - val_accuracy: 0.6300\n",
            "Epoch 87/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8062 - accuracy: 0.6650 - val_loss: 0.9193 - val_accuracy: 0.6360\n",
            "Epoch 88/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.7983 - accuracy: 0.6885 - val_loss: 0.9247 - val_accuracy: 0.6360\n",
            "Epoch 89/90\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7780 - accuracy: 0.6960 - val_loss: 0.8848 - val_accuracy: 0.6620\n",
            "Epoch 90/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.7673 - accuracy: 0.6848 - val_loss: 0.8832 - val_accuracy: 0.6500\n",
            "Epoch 1/90\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 2.6281 - accuracy: 0.2533 - val_loss: 1.8789 - val_accuracy: 0.2660\n",
            "Epoch 2/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2.2427 - accuracy: 0.2799 - val_loss: 2.0084 - val_accuracy: 0.2780\n",
            "Epoch 3/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 2.0961 - accuracy: 0.2916 - val_loss: 1.4754 - val_accuracy: 0.3360\n",
            "Epoch 4/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 2.0194 - accuracy: 0.3152 - val_loss: 1.4077 - val_accuracy: 0.3600\n",
            "Epoch 5/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.9541 - accuracy: 0.3127 - val_loss: 1.4132 - val_accuracy: 0.3560\n",
            "Epoch 6/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.9211 - accuracy: 0.3195 - val_loss: 1.4608 - val_accuracy: 0.3020\n",
            "Epoch 7/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.8317 - accuracy: 0.3399 - val_loss: 1.4441 - val_accuracy: 0.3200\n",
            "Epoch 8/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.7585 - accuracy: 0.3276 - val_loss: 1.3940 - val_accuracy: 0.3200\n",
            "Epoch 9/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.7136 - accuracy: 0.3437 - val_loss: 1.3747 - val_accuracy: 0.3300\n",
            "Epoch 10/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.6763 - accuracy: 0.3492 - val_loss: 1.4750 - val_accuracy: 0.2880\n",
            "Epoch 11/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.5692 - accuracy: 0.3622 - val_loss: 1.3923 - val_accuracy: 0.2920\n",
            "Epoch 12/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.5696 - accuracy: 0.3889 - val_loss: 1.3165 - val_accuracy: 0.3300\n",
            "Epoch 13/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.5367 - accuracy: 0.3858 - val_loss: 1.2675 - val_accuracy: 0.4020\n",
            "Epoch 14/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.4965 - accuracy: 0.4074 - val_loss: 1.3120 - val_accuracy: 0.3160\n",
            "Epoch 15/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.4661 - accuracy: 0.4050 - val_loss: 1.2607 - val_accuracy: 0.4200\n",
            "Epoch 16/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.4240 - accuracy: 0.4136 - val_loss: 1.2510 - val_accuracy: 0.4560\n",
            "Epoch 17/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.4021 - accuracy: 0.4328 - val_loss: 1.2953 - val_accuracy: 0.3920\n",
            "Epoch 18/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3826 - accuracy: 0.4266 - val_loss: 1.2620 - val_accuracy: 0.4160\n",
            "Epoch 19/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3512 - accuracy: 0.4365 - val_loss: 1.2225 - val_accuracy: 0.4280\n",
            "Epoch 20/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.3054 - accuracy: 0.4471 - val_loss: 1.3094 - val_accuracy: 0.3780\n",
            "Epoch 21/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.3677 - accuracy: 0.4223 - val_loss: 1.3238 - val_accuracy: 0.3820\n",
            "Epoch 22/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.3307 - accuracy: 0.4378 - val_loss: 1.2085 - val_accuracy: 0.4520\n",
            "Epoch 23/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2894 - accuracy: 0.4539 - val_loss: 1.1980 - val_accuracy: 0.4460\n",
            "Epoch 24/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2358 - accuracy: 0.4793 - val_loss: 1.2359 - val_accuracy: 0.4300\n",
            "Epoch 25/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.2648 - accuracy: 0.4594 - val_loss: 1.2848 - val_accuracy: 0.3760\n",
            "Epoch 26/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.2139 - accuracy: 0.4910 - val_loss: 1.2524 - val_accuracy: 0.4120\n",
            "Epoch 27/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2502 - accuracy: 0.4718 - val_loss: 1.2453 - val_accuracy: 0.4120\n",
            "Epoch 28/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.2343 - accuracy: 0.4842 - val_loss: 1.2100 - val_accuracy: 0.4260\n",
            "Epoch 29/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2146 - accuracy: 0.4774 - val_loss: 1.2199 - val_accuracy: 0.4640\n",
            "Epoch 30/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1915 - accuracy: 0.4997 - val_loss: 1.2589 - val_accuracy: 0.3980\n",
            "Epoch 31/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1771 - accuracy: 0.5053 - val_loss: 1.1438 - val_accuracy: 0.5100\n",
            "Epoch 32/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1940 - accuracy: 0.5059 - val_loss: 1.2568 - val_accuracy: 0.4220\n",
            "Epoch 33/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.2223 - accuracy: 0.4830 - val_loss: 1.3079 - val_accuracy: 0.4400\n",
            "Epoch 34/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1653 - accuracy: 0.5102 - val_loss: 1.1944 - val_accuracy: 0.4820\n",
            "Epoch 35/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1308 - accuracy: 0.5183 - val_loss: 1.1466 - val_accuracy: 0.5000\n",
            "Epoch 36/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1248 - accuracy: 0.5214 - val_loss: 1.2191 - val_accuracy: 0.4400\n",
            "Epoch 37/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1196 - accuracy: 0.5294 - val_loss: 1.1609 - val_accuracy: 0.4780\n",
            "Epoch 38/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1058 - accuracy: 0.5368 - val_loss: 1.2364 - val_accuracy: 0.4500\n",
            "Epoch 39/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0952 - accuracy: 0.5548 - val_loss: 1.1388 - val_accuracy: 0.4840\n",
            "Epoch 40/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.1253 - accuracy: 0.5201 - val_loss: 1.1429 - val_accuracy: 0.4960\n",
            "Epoch 41/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0845 - accuracy: 0.5542 - val_loss: 1.1309 - val_accuracy: 0.5160\n",
            "Epoch 42/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0943 - accuracy: 0.5313 - val_loss: 1.1908 - val_accuracy: 0.4480\n",
            "Epoch 43/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.0544 - accuracy: 0.5622 - val_loss: 1.0789 - val_accuracy: 0.5220\n",
            "Epoch 44/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.0884 - accuracy: 0.5300 - val_loss: 1.1856 - val_accuracy: 0.4640\n",
            "Epoch 45/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.0650 - accuracy: 0.5604 - val_loss: 1.1566 - val_accuracy: 0.4820\n",
            "Epoch 46/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0412 - accuracy: 0.5709 - val_loss: 1.0730 - val_accuracy: 0.5200\n",
            "Epoch 47/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0378 - accuracy: 0.5684 - val_loss: 1.0979 - val_accuracy: 0.5260\n",
            "Epoch 48/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.0343 - accuracy: 0.5783 - val_loss: 1.0400 - val_accuracy: 0.5360\n",
            "Epoch 49/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0615 - accuracy: 0.5344 - val_loss: 1.0228 - val_accuracy: 0.5640\n",
            "Epoch 50/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0429 - accuracy: 0.5604 - val_loss: 1.1060 - val_accuracy: 0.5040\n",
            "Epoch 51/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.0250 - accuracy: 0.5864 - val_loss: 1.0903 - val_accuracy: 0.5120\n",
            "Epoch 52/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0330 - accuracy: 0.5666 - val_loss: 1.0907 - val_accuracy: 0.5100\n",
            "Epoch 53/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0066 - accuracy: 0.5858 - val_loss: 1.0690 - val_accuracy: 0.5040\n",
            "Epoch 54/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9835 - accuracy: 0.5889 - val_loss: 1.0918 - val_accuracy: 0.5180\n",
            "Epoch 55/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 1.0147 - accuracy: 0.5858 - val_loss: 1.0875 - val_accuracy: 0.5300\n",
            "Epoch 56/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9862 - accuracy: 0.5920 - val_loss: 1.0243 - val_accuracy: 0.5660\n",
            "Epoch 57/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9946 - accuracy: 0.5901 - val_loss: 1.0676 - val_accuracy: 0.5520\n",
            "Epoch 58/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9898 - accuracy: 0.5864 - val_loss: 1.0638 - val_accuracy: 0.5420\n",
            "Epoch 59/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9525 - accuracy: 0.5975 - val_loss: 0.9777 - val_accuracy: 0.5560\n",
            "Epoch 60/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9445 - accuracy: 0.6074 - val_loss: 1.0089 - val_accuracy: 0.5600\n",
            "Epoch 61/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9544 - accuracy: 0.6087 - val_loss: 0.9945 - val_accuracy: 0.5580\n",
            "Epoch 62/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9473 - accuracy: 0.6204 - val_loss: 1.0241 - val_accuracy: 0.5660\n",
            "Epoch 63/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9354 - accuracy: 0.6012 - val_loss: 1.0671 - val_accuracy: 0.5560\n",
            "Epoch 64/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9851 - accuracy: 0.5926 - val_loss: 0.9853 - val_accuracy: 0.5720\n",
            "Epoch 65/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9091 - accuracy: 0.6372 - val_loss: 1.0009 - val_accuracy: 0.5860\n",
            "Epoch 66/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9502 - accuracy: 0.6056 - val_loss: 0.9607 - val_accuracy: 0.6000\n",
            "Epoch 67/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9086 - accuracy: 0.6161 - val_loss: 0.9975 - val_accuracy: 0.5840\n",
            "Epoch 68/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8891 - accuracy: 0.6427 - val_loss: 1.0145 - val_accuracy: 0.5740\n",
            "Epoch 69/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9199 - accuracy: 0.6118 - val_loss: 0.9849 - val_accuracy: 0.5920\n",
            "Epoch 70/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9383 - accuracy: 0.6204 - val_loss: 1.0056 - val_accuracy: 0.5960\n",
            "Epoch 71/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9241 - accuracy: 0.6223 - val_loss: 1.0744 - val_accuracy: 0.5360\n",
            "Epoch 72/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.9020 - accuracy: 0.6402 - val_loss: 0.9858 - val_accuracy: 0.5860\n",
            "Epoch 73/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8734 - accuracy: 0.6452 - val_loss: 1.0092 - val_accuracy: 0.5580\n",
            "Epoch 74/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8617 - accuracy: 0.6433 - val_loss: 0.9123 - val_accuracy: 0.6240\n",
            "Epoch 75/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8702 - accuracy: 0.6533 - val_loss: 0.9848 - val_accuracy: 0.5960\n",
            "Epoch 76/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8557 - accuracy: 0.6502 - val_loss: 0.9653 - val_accuracy: 0.5960\n",
            "Epoch 77/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8811 - accuracy: 0.6495 - val_loss: 0.9153 - val_accuracy: 0.6360\n",
            "Epoch 78/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8528 - accuracy: 0.6588 - val_loss: 0.9067 - val_accuracy: 0.6360\n",
            "Epoch 79/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8458 - accuracy: 0.6545 - val_loss: 0.9657 - val_accuracy: 0.6140\n",
            "Epoch 80/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8436 - accuracy: 0.6539 - val_loss: 1.0507 - val_accuracy: 0.5720\n",
            "Epoch 81/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8277 - accuracy: 0.6533 - val_loss: 1.0114 - val_accuracy: 0.5740\n",
            "Epoch 82/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8424 - accuracy: 0.6693 - val_loss: 0.9436 - val_accuracy: 0.6180\n",
            "Epoch 83/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8646 - accuracy: 0.6514 - val_loss: 1.0211 - val_accuracy: 0.5500\n",
            "Epoch 84/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8582 - accuracy: 0.6656 - val_loss: 0.9027 - val_accuracy: 0.6360\n",
            "Epoch 85/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8589 - accuracy: 0.6526 - val_loss: 0.9408 - val_accuracy: 0.6080\n",
            "Epoch 86/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8047 - accuracy: 0.6904 - val_loss: 0.9679 - val_accuracy: 0.5740\n",
            "Epoch 87/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8215 - accuracy: 0.6731 - val_loss: 0.8667 - val_accuracy: 0.6440\n",
            "Epoch 88/90\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8156 - accuracy: 0.6650 - val_loss: 0.9040 - val_accuracy: 0.6400\n",
            "Epoch 89/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.8325 - accuracy: 0.6570 - val_loss: 0.9204 - val_accuracy: 0.6200\n",
            "Epoch 90/90\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.7858 - accuracy: 0.6892 - val_loss: 0.8783 - val_accuracy: 0.6540\n",
            "Epoch 1/90\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 2.4906 - accuracy: 0.2749 - val_loss: 1.7815 - val_accuracy: 0.2640\n",
            "Epoch 2/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2.3151 - accuracy: 0.2991 - val_loss: 1.3536 - val_accuracy: 0.3340\n",
            "Epoch 3/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 2.2264 - accuracy: 0.2811 - val_loss: 1.4503 - val_accuracy: 0.3100\n",
            "Epoch 4/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2.0909 - accuracy: 0.3040 - val_loss: 1.4074 - val_accuracy: 0.3400\n",
            "Epoch 5/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2.0305 - accuracy: 0.3257 - val_loss: 1.4590 - val_accuracy: 0.3220\n",
            "Epoch 6/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.9499 - accuracy: 0.3022 - val_loss: 1.5054 - val_accuracy: 0.2840\n",
            "Epoch 7/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.8520 - accuracy: 0.3325 - val_loss: 1.4015 - val_accuracy: 0.3380\n",
            "Epoch 8/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.8647 - accuracy: 0.3164 - val_loss: 1.4047 - val_accuracy: 0.3300\n",
            "Epoch 9/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.7977 - accuracy: 0.3238 - val_loss: 1.3193 - val_accuracy: 0.4000\n",
            "Epoch 10/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.7616 - accuracy: 0.3492 - val_loss: 1.4677 - val_accuracy: 0.2860\n",
            "Epoch 11/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.7362 - accuracy: 0.3399 - val_loss: 1.4671 - val_accuracy: 0.3040\n",
            "Epoch 12/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.6617 - accuracy: 0.3517 - val_loss: 1.5336 - val_accuracy: 0.2860\n",
            "Epoch 13/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.5872 - accuracy: 0.3678 - val_loss: 1.4180 - val_accuracy: 0.3400\n",
            "Epoch 14/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.5316 - accuracy: 0.3808 - val_loss: 1.3279 - val_accuracy: 0.3720\n",
            "Epoch 15/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.5259 - accuracy: 0.3789 - val_loss: 1.3169 - val_accuracy: 0.3520\n",
            "Epoch 16/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.5164 - accuracy: 0.3808 - val_loss: 1.3542 - val_accuracy: 0.3500\n",
            "Epoch 17/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.4615 - accuracy: 0.3994 - val_loss: 1.3250 - val_accuracy: 0.3520\n",
            "Epoch 18/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.4737 - accuracy: 0.3988 - val_loss: 1.3604 - val_accuracy: 0.3300\n",
            "Epoch 19/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.4172 - accuracy: 0.4037 - val_loss: 1.3469 - val_accuracy: 0.3460\n",
            "Epoch 20/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.4083 - accuracy: 0.3981 - val_loss: 1.2426 - val_accuracy: 0.4340\n",
            "Epoch 21/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3788 - accuracy: 0.4211 - val_loss: 1.3164 - val_accuracy: 0.3580\n",
            "Epoch 22/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.3898 - accuracy: 0.4223 - val_loss: 1.2720 - val_accuracy: 0.3800\n",
            "Epoch 23/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3621 - accuracy: 0.4167 - val_loss: 1.2989 - val_accuracy: 0.3800\n",
            "Epoch 24/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.3595 - accuracy: 0.3901 - val_loss: 1.2277 - val_accuracy: 0.4340\n",
            "Epoch 25/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3507 - accuracy: 0.4241 - val_loss: 1.2712 - val_accuracy: 0.4120\n",
            "Epoch 26/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3265 - accuracy: 0.4279 - val_loss: 1.3386 - val_accuracy: 0.3560\n",
            "Epoch 27/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.3098 - accuracy: 0.4198 - val_loss: 1.3244 - val_accuracy: 0.3500\n",
            "Epoch 28/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.3155 - accuracy: 0.4303 - val_loss: 1.2636 - val_accuracy: 0.4340\n",
            "Epoch 29/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.2677 - accuracy: 0.4607 - val_loss: 1.2028 - val_accuracy: 0.4740\n",
            "Epoch 30/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.2479 - accuracy: 0.4687 - val_loss: 1.2696 - val_accuracy: 0.4360\n",
            "Epoch 31/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.2896 - accuracy: 0.4638 - val_loss: 1.2997 - val_accuracy: 0.3980\n",
            "Epoch 32/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.2292 - accuracy: 0.4774 - val_loss: 1.2577 - val_accuracy: 0.4120\n",
            "Epoch 33/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.2229 - accuracy: 0.4793 - val_loss: 1.1914 - val_accuracy: 0.4720\n",
            "Epoch 34/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1672 - accuracy: 0.4861 - val_loss: 1.2265 - val_accuracy: 0.4140\n",
            "Epoch 35/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1824 - accuracy: 0.4997 - val_loss: 1.1602 - val_accuracy: 0.4760\n",
            "Epoch 36/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1718 - accuracy: 0.5059 - val_loss: 1.2474 - val_accuracy: 0.4260\n",
            "Epoch 37/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1947 - accuracy: 0.5028 - val_loss: 1.2552 - val_accuracy: 0.4640\n",
            "Epoch 38/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1698 - accuracy: 0.5022 - val_loss: 1.1420 - val_accuracy: 0.5080\n",
            "Epoch 39/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1702 - accuracy: 0.5201 - val_loss: 1.2111 - val_accuracy: 0.4420\n",
            "Epoch 40/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1382 - accuracy: 0.5127 - val_loss: 1.1588 - val_accuracy: 0.4920\n",
            "Epoch 41/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1108 - accuracy: 0.5548 - val_loss: 1.1453 - val_accuracy: 0.4900\n",
            "Epoch 42/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1513 - accuracy: 0.5164 - val_loss: 1.1802 - val_accuracy: 0.4520\n",
            "Epoch 43/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1318 - accuracy: 0.5288 - val_loss: 1.1574 - val_accuracy: 0.4840\n",
            "Epoch 44/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1330 - accuracy: 0.5381 - val_loss: 1.1953 - val_accuracy: 0.4460\n",
            "Epoch 45/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0887 - accuracy: 0.5406 - val_loss: 1.1612 - val_accuracy: 0.5060\n",
            "Epoch 46/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.0757 - accuracy: 0.5505 - val_loss: 1.1133 - val_accuracy: 0.5340\n",
            "Epoch 47/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0931 - accuracy: 0.5337 - val_loss: 1.1195 - val_accuracy: 0.5460\n",
            "Epoch 48/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.0957 - accuracy: 0.5368 - val_loss: 1.1504 - val_accuracy: 0.5000\n",
            "Epoch 49/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0693 - accuracy: 0.5498 - val_loss: 1.1917 - val_accuracy: 0.4760\n",
            "Epoch 50/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.0990 - accuracy: 0.5412 - val_loss: 1.1747 - val_accuracy: 0.4960\n",
            "Epoch 51/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0787 - accuracy: 0.5554 - val_loss: 1.1227 - val_accuracy: 0.4860\n",
            "Epoch 52/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0435 - accuracy: 0.5616 - val_loss: 1.1444 - val_accuracy: 0.4980\n",
            "Epoch 53/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.0256 - accuracy: 0.5759 - val_loss: 1.0352 - val_accuracy: 0.5660\n",
            "Epoch 54/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0127 - accuracy: 0.5771 - val_loss: 1.1307 - val_accuracy: 0.5180\n",
            "Epoch 55/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0303 - accuracy: 0.5808 - val_loss: 1.0626 - val_accuracy: 0.5600\n",
            "Epoch 56/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.0564 - accuracy: 0.5622 - val_loss: 1.1809 - val_accuracy: 0.4580\n",
            "Epoch 57/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0237 - accuracy: 0.5808 - val_loss: 1.1556 - val_accuracy: 0.4840\n",
            "Epoch 58/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0132 - accuracy: 0.5827 - val_loss: 1.2130 - val_accuracy: 0.4620\n",
            "Epoch 59/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9978 - accuracy: 0.5981 - val_loss: 1.0059 - val_accuracy: 0.5840\n",
            "Epoch 60/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9835 - accuracy: 0.5926 - val_loss: 1.0970 - val_accuracy: 0.5060\n",
            "Epoch 61/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9779 - accuracy: 0.5963 - val_loss: 1.2406 - val_accuracy: 0.4560\n",
            "Epoch 62/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9865 - accuracy: 0.5926 - val_loss: 1.0185 - val_accuracy: 0.5600\n",
            "Epoch 63/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9598 - accuracy: 0.6080 - val_loss: 0.9956 - val_accuracy: 0.5940\n",
            "Epoch 64/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9628 - accuracy: 0.6012 - val_loss: 1.0037 - val_accuracy: 0.5720\n",
            "Epoch 65/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9603 - accuracy: 0.6136 - val_loss: 1.0551 - val_accuracy: 0.5680\n",
            "Epoch 66/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9356 - accuracy: 0.6161 - val_loss: 1.1105 - val_accuracy: 0.5240\n",
            "Epoch 67/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9726 - accuracy: 0.6161 - val_loss: 1.0858 - val_accuracy: 0.5380\n",
            "Epoch 68/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9501 - accuracy: 0.6161 - val_loss: 0.9964 - val_accuracy: 0.5720\n",
            "Epoch 69/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8998 - accuracy: 0.6235 - val_loss: 1.0082 - val_accuracy: 0.5620\n",
            "Epoch 70/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9412 - accuracy: 0.6353 - val_loss: 1.1635 - val_accuracy: 0.5040\n",
            "Epoch 71/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9209 - accuracy: 0.6217 - val_loss: 1.0237 - val_accuracy: 0.5660\n",
            "Epoch 72/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9149 - accuracy: 0.6378 - val_loss: 1.1116 - val_accuracy: 0.5220\n",
            "Epoch 73/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9094 - accuracy: 0.6353 - val_loss: 1.0380 - val_accuracy: 0.5680\n",
            "Epoch 74/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9217 - accuracy: 0.6291 - val_loss: 1.0681 - val_accuracy: 0.5460\n",
            "Epoch 75/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9007 - accuracy: 0.6316 - val_loss: 1.0100 - val_accuracy: 0.5920\n",
            "Epoch 76/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9016 - accuracy: 0.6297 - val_loss: 1.0136 - val_accuracy: 0.5800\n",
            "Epoch 77/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8545 - accuracy: 0.6632 - val_loss: 1.1029 - val_accuracy: 0.5380\n",
            "Epoch 78/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.9183 - accuracy: 0.6310 - val_loss: 1.0052 - val_accuracy: 0.5900\n",
            "Epoch 79/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8651 - accuracy: 0.6477 - val_loss: 0.9771 - val_accuracy: 0.6040\n",
            "Epoch 80/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8395 - accuracy: 0.6780 - val_loss: 1.0005 - val_accuracy: 0.5820\n",
            "Epoch 81/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8603 - accuracy: 0.6619 - val_loss: 0.9759 - val_accuracy: 0.5940\n",
            "Epoch 82/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8449 - accuracy: 0.6632 - val_loss: 0.9560 - val_accuracy: 0.6040\n",
            "Epoch 83/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8701 - accuracy: 0.6409 - val_loss: 0.9548 - val_accuracy: 0.6100\n",
            "Epoch 84/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8114 - accuracy: 0.6681 - val_loss: 0.9650 - val_accuracy: 0.6000\n",
            "Epoch 85/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8313 - accuracy: 0.6693 - val_loss: 0.9480 - val_accuracy: 0.6120\n",
            "Epoch 86/90\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8127 - accuracy: 0.6743 - val_loss: 0.9444 - val_accuracy: 0.6120\n",
            "Epoch 87/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8070 - accuracy: 0.6774 - val_loss: 0.9516 - val_accuracy: 0.6180\n",
            "Epoch 88/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8196 - accuracy: 0.6786 - val_loss: 0.9689 - val_accuracy: 0.6000\n",
            "Epoch 89/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8178 - accuracy: 0.6873 - val_loss: 0.8996 - val_accuracy: 0.6440\n",
            "Epoch 90/90\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7882 - accuracy: 0.6916 - val_loss: 0.9427 - val_accuracy: 0.6020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "AtR1grU30CQC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('time')\n",
        "pyplot.plot(time,score_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "jBv_UseDOyVQ",
        "outputId": "e2137724-8806-45e3-f857-53566f7a5416"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8aad233750>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subject Identification"
      ],
      "metadata": {
        "id": "ul2T8DtVQ_LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading and visualizing the data\n",
        "\n",
        "## Loading the dataset\n",
        "\n",
        "\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Printing the shapes of the numpy arrays\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "metadata": {
        "id": "VfFPDSjjRC4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d527b941-5fe7-4aff-8617-c0c215a98add"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "print(y_train_valid)"
      ],
      "metadata": {
        "id": "SlDbH6Tqd3n8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc0760b-1b0a-4714-85a2-a9455838d7b5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 0 ... 3 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
        "ind_valid = np.random.choice(2115, 500, replace=False)\n",
        "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
        "\n",
        "(x_train, x_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
        "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
        "(person_train, person_valid) = person_train_valid[ind_train], person_train_valid[ind_valid]\n",
        "\n",
        "# Reshape input data from (22, 1000) to (28, 28, 1)\n",
        "w, h = 22, 1000\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h)\n",
        "x_test = X_test.reshape(X_test.shape[0], w, h)\n",
        "\n",
        "# One-hot encode the labels\n",
        "\n",
        "#classify tasks\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 4)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 4)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 4)\n",
        "\n",
        "#classify people\n",
        "person_train = tf.keras.utils.to_categorical(person_train, 9)\n",
        "person_valid = tf.keras.utils.to_categorical(person_valid, 9)\n",
        "person_test_n = tf.keras.utils.to_categorical(person_test, 9)\n",
        "\n",
        "# Print training set shape\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training, validation, and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(x_test.shape[0], 'test set')\n",
        "\n",
        "\n",
        "x_train = np.swapaxes(x_train,2,1)\n",
        "x_valid = np.swapaxes(x_valid,2,1)\n",
        "x_test = np.swapaxes(x_test,2,1)\n",
        "\n",
        "x_train = x_train.reshape(1615, h,1,w)\n",
        "x_valid = x_valid.reshape(500,h, 1,w)\n",
        "x_test = x_test.reshape(443,h,1,w)\n"
      ],
      "metadata": {
        "id": "a55uDFLrd7Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60fb14b-d537-4540-cb1c-132c9cc25f7d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (1615, 22, 1000) y_train shape: (1615, 4)\n",
            "1615 train set\n",
            "500 validation set\n",
            "443 test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = 0.5\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "    # Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides = (3,1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(dropout))          \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(dropout))  \n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "   \n",
        "# model.add(tf.keras.layers.Dense((100)))\n",
        "# model.add(tf.keras.layers.Reshape((100,1)))\n",
        "# model.add(tf.keras.layers.LSTM(20, dropout=0.6, recurrent_dropout= 0.15, input_shape=(100,1), return_sequences=False))\n",
        "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "KBoz2wsRfVmU"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size= 64,\n",
        "         epochs=100, validation_data=(x_valid, y_valid))"
      ],
      "metadata": {
        "id": "XZFcjfAbfX6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8a00aa-1fb6-48a0-cbfc-dc05a248a5e5"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 2s 40ms/step - loss: 2.3439 - categorical_accuracy: 0.2824 - val_loss: 1.7872 - val_categorical_accuracy: 0.3220\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 2.0445 - categorical_accuracy: 0.3331 - val_loss: 1.7655 - val_categorical_accuracy: 0.2940\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.8320 - categorical_accuracy: 0.3678 - val_loss: 1.4951 - val_categorical_accuracy: 0.3900\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 17ms/step - loss: 1.8258 - categorical_accuracy: 0.3393 - val_loss: 1.4274 - val_categorical_accuracy: 0.4100\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.7113 - categorical_accuracy: 0.3709 - val_loss: 1.4976 - val_categorical_accuracy: 0.3680\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 1.5915 - categorical_accuracy: 0.4074 - val_loss: 1.6162 - val_categorical_accuracy: 0.4020\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 1.5018 - categorical_accuracy: 0.4303 - val_loss: 1.3272 - val_categorical_accuracy: 0.4300\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 17ms/step - loss: 1.4553 - categorical_accuracy: 0.4285 - val_loss: 1.4264 - val_categorical_accuracy: 0.4300\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 1.4081 - categorical_accuracy: 0.4508 - val_loss: 1.3418 - val_categorical_accuracy: 0.4260\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.3582 - categorical_accuracy: 0.4663 - val_loss: 1.4691 - val_categorical_accuracy: 0.4180\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.3431 - categorical_accuracy: 0.4724 - val_loss: 1.4081 - val_categorical_accuracy: 0.4240\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3237 - categorical_accuracy: 0.5046 - val_loss: 1.3185 - val_categorical_accuracy: 0.4920\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 1.2594 - categorical_accuracy: 0.5003 - val_loss: 1.4114 - val_categorical_accuracy: 0.4320\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.1985 - categorical_accuracy: 0.5269 - val_loss: 1.1754 - val_categorical_accuracy: 0.5220\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1442 - categorical_accuracy: 0.5362 - val_loss: 1.1610 - val_categorical_accuracy: 0.5340\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1270 - categorical_accuracy: 0.5443 - val_loss: 1.2224 - val_categorical_accuracy: 0.4640\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.1585 - categorical_accuracy: 0.5313 - val_loss: 1.1006 - val_categorical_accuracy: 0.5200\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0945 - categorical_accuracy: 0.5474 - val_loss: 1.1140 - val_categorical_accuracy: 0.5340\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0639 - categorical_accuracy: 0.5783 - val_loss: 1.0873 - val_categorical_accuracy: 0.5520\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0594 - categorical_accuracy: 0.5715 - val_loss: 1.0827 - val_categorical_accuracy: 0.5480\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0336 - categorical_accuracy: 0.5802 - val_loss: 1.0840 - val_categorical_accuracy: 0.5700\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1.0157 - categorical_accuracy: 0.5876 - val_loss: 1.1515 - val_categorical_accuracy: 0.5240\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9846 - categorical_accuracy: 0.5975 - val_loss: 1.1910 - val_categorical_accuracy: 0.5240\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.9558 - categorical_accuracy: 0.6149 - val_loss: 1.0806 - val_categorical_accuracy: 0.5700\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9589 - categorical_accuracy: 0.6080 - val_loss: 1.2094 - val_categorical_accuracy: 0.5220\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9381 - categorical_accuracy: 0.6142 - val_loss: 1.0445 - val_categorical_accuracy: 0.6040\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9462 - categorical_accuracy: 0.6241 - val_loss: 1.0829 - val_categorical_accuracy: 0.5520\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9170 - categorical_accuracy: 0.6520 - val_loss: 1.0646 - val_categorical_accuracy: 0.5820\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9287 - categorical_accuracy: 0.6136 - val_loss: 1.0520 - val_categorical_accuracy: 0.5940\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.9157 - categorical_accuracy: 0.6334 - val_loss: 1.0136 - val_categorical_accuracy: 0.6140\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8645 - categorical_accuracy: 0.6427 - val_loss: 0.9686 - val_categorical_accuracy: 0.6220\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8307 - categorical_accuracy: 0.6613 - val_loss: 0.9849 - val_categorical_accuracy: 0.6200\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8540 - categorical_accuracy: 0.6582 - val_loss: 1.0243 - val_categorical_accuracy: 0.6040\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7938 - categorical_accuracy: 0.6910 - val_loss: 1.0425 - val_categorical_accuracy: 0.5980\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.8375 - categorical_accuracy: 0.6854 - val_loss: 1.0109 - val_categorical_accuracy: 0.6360\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.8188 - categorical_accuracy: 0.6768 - val_loss: 1.0757 - val_categorical_accuracy: 0.6080\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.8118 - categorical_accuracy: 0.6724 - val_loss: 0.9605 - val_categorical_accuracy: 0.6360\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7760 - categorical_accuracy: 0.7090 - val_loss: 1.0067 - val_categorical_accuracy: 0.6260\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7703 - categorical_accuracy: 0.7003 - val_loss: 0.9914 - val_categorical_accuracy: 0.6320\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7343 - categorical_accuracy: 0.7170 - val_loss: 1.0510 - val_categorical_accuracy: 0.6300\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7406 - categorical_accuracy: 0.7127 - val_loss: 1.0679 - val_categorical_accuracy: 0.6100\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7373 - categorical_accuracy: 0.7102 - val_loss: 1.0159 - val_categorical_accuracy: 0.6380\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6975 - categorical_accuracy: 0.7214 - val_loss: 1.0265 - val_categorical_accuracy: 0.6400\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6906 - categorical_accuracy: 0.7282 - val_loss: 1.0147 - val_categorical_accuracy: 0.6540\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.7169 - categorical_accuracy: 0.7207 - val_loss: 0.9198 - val_categorical_accuracy: 0.6560\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6987 - categorical_accuracy: 0.7269 - val_loss: 0.9860 - val_categorical_accuracy: 0.6540\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6709 - categorical_accuracy: 0.7399 - val_loss: 0.9819 - val_categorical_accuracy: 0.6560\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6556 - categorical_accuracy: 0.7529 - val_loss: 0.9751 - val_categorical_accuracy: 0.6620\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6362 - categorical_accuracy: 0.7505 - val_loss: 0.9099 - val_categorical_accuracy: 0.6720\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6372 - categorical_accuracy: 0.7529 - val_loss: 0.8990 - val_categorical_accuracy: 0.6740\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6237 - categorical_accuracy: 0.7486 - val_loss: 0.8985 - val_categorical_accuracy: 0.6960\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5999 - categorical_accuracy: 0.7610 - val_loss: 1.0855 - val_categorical_accuracy: 0.6340\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.6353 - categorical_accuracy: 0.7492 - val_loss: 0.9618 - val_categorical_accuracy: 0.6820\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5898 - categorical_accuracy: 0.7690 - val_loss: 0.9135 - val_categorical_accuracy: 0.6800\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5616 - categorical_accuracy: 0.7851 - val_loss: 0.9417 - val_categorical_accuracy: 0.6800\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5852 - categorical_accuracy: 0.7752 - val_loss: 0.9622 - val_categorical_accuracy: 0.6620\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.5637 - categorical_accuracy: 0.7796 - val_loss: 0.9868 - val_categorical_accuracy: 0.6540\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5613 - categorical_accuracy: 0.7653 - val_loss: 1.0020 - val_categorical_accuracy: 0.6700\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5661 - categorical_accuracy: 0.7820 - val_loss: 0.9646 - val_categorical_accuracy: 0.6900\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5507 - categorical_accuracy: 0.7703 - val_loss: 0.9305 - val_categorical_accuracy: 0.6720\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5233 - categorical_accuracy: 0.8050 - val_loss: 0.9488 - val_categorical_accuracy: 0.6860\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5024 - categorical_accuracy: 0.8006 - val_loss: 0.9901 - val_categorical_accuracy: 0.6860\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5389 - categorical_accuracy: 0.7876 - val_loss: 1.0499 - val_categorical_accuracy: 0.6620\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5165 - categorical_accuracy: 0.7994 - val_loss: 1.0674 - val_categorical_accuracy: 0.6700\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5092 - categorical_accuracy: 0.8012 - val_loss: 0.9546 - val_categorical_accuracy: 0.6820\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5242 - categorical_accuracy: 0.7957 - val_loss: 0.9371 - val_categorical_accuracy: 0.7080\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4747 - categorical_accuracy: 0.8198 - val_loss: 1.0114 - val_categorical_accuracy: 0.6640\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4641 - categorical_accuracy: 0.8111 - val_loss: 0.9681 - val_categorical_accuracy: 0.6920\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4787 - categorical_accuracy: 0.8211 - val_loss: 0.9778 - val_categorical_accuracy: 0.6820\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5007 - categorical_accuracy: 0.8099 - val_loss: 0.9930 - val_categorical_accuracy: 0.6740\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.5089 - categorical_accuracy: 0.7988 - val_loss: 1.0277 - val_categorical_accuracy: 0.6760\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4473 - categorical_accuracy: 0.8223 - val_loss: 1.0021 - val_categorical_accuracy: 0.6860\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4905 - categorical_accuracy: 0.8105 - val_loss: 1.0082 - val_categorical_accuracy: 0.6900\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4104 - categorical_accuracy: 0.8384 - val_loss: 0.9959 - val_categorical_accuracy: 0.6800\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.4406 - categorical_accuracy: 0.8341 - val_loss: 0.9667 - val_categorical_accuracy: 0.6620\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4434 - categorical_accuracy: 0.8272 - val_loss: 0.9943 - val_categorical_accuracy: 0.6760\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4371 - categorical_accuracy: 0.8248 - val_loss: 1.0216 - val_categorical_accuracy: 0.7080\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4121 - categorical_accuracy: 0.8551 - val_loss: 0.9904 - val_categorical_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.4189 - categorical_accuracy: 0.8446 - val_loss: 0.9802 - val_categorical_accuracy: 0.6940\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.4126 - categorical_accuracy: 0.8427 - val_loss: 0.9866 - val_categorical_accuracy: 0.6940\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3757 - categorical_accuracy: 0.8440 - val_loss: 0.9624 - val_categorical_accuracy: 0.6960\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3853 - categorical_accuracy: 0.8539 - val_loss: 0.9996 - val_categorical_accuracy: 0.7040\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3746 - categorical_accuracy: 0.8551 - val_loss: 0.9976 - val_categorical_accuracy: 0.6960\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4025 - categorical_accuracy: 0.8495 - val_loss: 0.9774 - val_categorical_accuracy: 0.6900\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3529 - categorical_accuracy: 0.8663 - val_loss: 0.9740 - val_categorical_accuracy: 0.6980\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.4198 - categorical_accuracy: 0.8415 - val_loss: 0.9650 - val_categorical_accuracy: 0.7080\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3407 - categorical_accuracy: 0.8669 - val_loss: 1.0118 - val_categorical_accuracy: 0.6940\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4103 - categorical_accuracy: 0.8433 - val_loss: 1.0165 - val_categorical_accuracy: 0.6820\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4097 - categorical_accuracy: 0.8458 - val_loss: 1.1287 - val_categorical_accuracy: 0.6740\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3835 - categorical_accuracy: 0.8644 - val_loss: 0.9912 - val_categorical_accuracy: 0.6880\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4044 - categorical_accuracy: 0.8458 - val_loss: 1.0142 - val_categorical_accuracy: 0.6900\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3634 - categorical_accuracy: 0.8681 - val_loss: 0.9961 - val_categorical_accuracy: 0.6920\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3511 - categorical_accuracy: 0.8693 - val_loss: 1.0531 - val_categorical_accuracy: 0.7040\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3265 - categorical_accuracy: 0.8805 - val_loss: 1.0303 - val_categorical_accuracy: 0.6980\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3476 - categorical_accuracy: 0.8700 - val_loss: 1.0142 - val_categorical_accuracy: 0.6900\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3586 - categorical_accuracy: 0.8613 - val_loss: 0.9855 - val_categorical_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3378 - categorical_accuracy: 0.8712 - val_loss: 1.0079 - val_categorical_accuracy: 0.6940\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3242 - categorical_accuracy: 0.8793 - val_loss: 1.0119 - val_categorical_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3089 - categorical_accuracy: 0.8842 - val_loss: 1.0080 - val_categorical_accuracy: 0.7020\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3145 - categorical_accuracy: 0.8836 - val_loss: 0.9696 - val_categorical_accuracy: 0.6940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "layer_name = 'flatten_51'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "x_train_pc = intermediate_layer_model.predict(x_train)\n",
        "x_valid_pc = intermediate_layer_model.predict(x_valid)\n",
        "x_test_pc = intermediate_layer_model.predict(x_test)\n",
        "\n",
        "w = x_train_pc.shape[1]\n",
        "x_train_pc = x_train_pc.reshape(x_train_pc.shape[0], w, 1)\n",
        "x_valid_pc = x_valid_pc.reshape(x_valid_pc.shape[0], w,1)\n",
        "x_test_pc  = x_test_pc.reshape(x_test_pc.shape[0], w,1)\n",
        "\n",
        "model1 = tf.keras.Sequential()\n",
        "\n",
        "model1.add(tf.keras.layers.Flatten(input_shape=(w,1)))\n",
        "\n",
        "model1.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "model1.add(tf.keras.layers.Reshape((200,1)))\n",
        "model1.add(tf.keras.layers.LSTM(20, dropout=0.6, recurrent_dropout= 0.15, input_shape=(200,1), return_sequences=False))\n",
        "model1.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UufJP3wPfYXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2005b5ee-7f16-48c3-d9c0-d4d25877e988"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_52 (Flatten)        (None, 2400)              0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 200)               480200    \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 9)                 1809      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 482,009\n",
            "Trainable params: 482,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x_train_pc,\n",
        "         person_train,\n",
        "         batch_size= 64,\n",
        "         epochs=50, validation_data=(x_valid_pc, person_valid))"
      ],
      "metadata": {
        "id": "rUpgMfzUff4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3342da-6147-456c-b3dc-a17557aa38b5"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 1s 10ms/step - loss: 1.0562 - accuracy: 0.6142 - val_loss: 0.5903 - val_accuracy: 0.7880\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9554 - val_loss: 0.4983 - val_accuracy: 0.8140\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9969 - val_loss: 0.4694 - val_accuracy: 0.8180\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8260\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.8260\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.8380\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8360\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.8340\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.8440\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.8420\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.8440\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8440\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8440\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8440\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8420\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8440\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8480\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8460\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.8460\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8500\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8500\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8500\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.8460\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9.8462e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8480\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9.2305e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8480\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8.6380e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.8500\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8.1307e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.8480\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 7.6415e-04 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.8460\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 7.1779e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8480\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 6.7850e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8460\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6.4226e-04 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8480\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6.0907e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.8500\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 5.7682e-04 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.8460\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.4822e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.8520\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 5.2194e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8460\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9669e-04 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8520\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 4.7310e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8500\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 4.5223e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8500\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 4.3207e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8500\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4.1339e-04 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.9527e-04 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8500\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.7884e-04 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8500\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.6482e-04 - accuracy: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.4896e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8500\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.3501e-04 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8500\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3.2155e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.0946e-04 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8500\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2.9754e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8500\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2.8668e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2.7665e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model1.evaluate(x_valid_pc, person_valid)\n",
        "print (score[1])"
      ],
      "metadata": {
        "id": "HdD_zRhpfiNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6d0127-63e1-4d92-c4bd-0ab4bc7b5eda"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8500\n",
            "0.8500000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential()\n",
        "\n",
        "model2.add(tf.keras.layers.Conv2D(filters=25, kernel_size=(3,3), padding='same', activation='elu', input_shape=(1000,1,22)))\n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model2.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(3,3), padding='same', activation='elu'))\n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model2.add(tf.keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(tf.keras.layers.Dropout(0.5))\n",
        "model2.add(tf.keras.layers.Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(tf.keras.layers.Dropout(dropout))  \n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "model2.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Z-VOtUkhfivl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596dd628-18a4-4fe7-e0cf-f6557efc389e"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_208 (Conv2D)         (None, 1000, 1, 25)       4975      \n",
            "                                                                 \n",
            " max_pooling2d_208 (MaxPooli  (None, 334, 1, 25)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_208 (Ba  (None, 334, 1, 25)       100       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_208 (Dropout)       (None, 334, 1, 25)        0         \n",
            "                                                                 \n",
            " conv2d_209 (Conv2D)         (None, 334, 1, 50)        11300     \n",
            "                                                                 \n",
            " max_pooling2d_209 (MaxPooli  (None, 112, 1, 50)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_209 (Ba  (None, 112, 1, 50)       200       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_209 (Dropout)       (None, 112, 1, 50)        0         \n",
            "                                                                 \n",
            " conv2d_210 (Conv2D)         (None, 112, 1, 100)       50100     \n",
            "                                                                 \n",
            " max_pooling2d_210 (MaxPooli  (None, 38, 1, 100)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_210 (Ba  (None, 38, 1, 100)       400       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 38, 1, 100)        0         \n",
            "                                                                 \n",
            " conv2d_211 (Conv2D)         (None, 38, 1, 200)        200200    \n",
            "                                                                 \n",
            " max_pooling2d_211 (MaxPooli  (None, 12, 1, 200)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_211 (Ba  (None, 12, 1, 200)       800       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 12, 1, 200)        0         \n",
            "                                                                 \n",
            " flatten_53 (Flatten)        (None, 2400)              0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 9)                 21609     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,684\n",
            "Trainable params: 288,934\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(x_train,\n",
        "         person_train,\n",
        "         batch_size= 64,\n",
        "         epochs=50, validation_data=(x_valid, person_valid))"
      ],
      "metadata": {
        "id": "BSX5MAG_fltB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f7ec1a5-4ad9-41fb-d1f9-4d89ff06a45a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 2s 41ms/step - loss: 2.1162 - accuracy: 0.3759 - val_loss: 9.1133 - val_accuracy: 0.2200\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1.1720 - accuracy: 0.6012 - val_loss: 3.1595 - val_accuracy: 0.2360\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.7768 - accuracy: 0.7263 - val_loss: 1.5722 - val_accuracy: 0.5560\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.5139 - accuracy: 0.8167 - val_loss: 1.2636 - val_accuracy: 0.6740\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.4017 - accuracy: 0.8625 - val_loss: 1.4990 - val_accuracy: 0.6320\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8904 - val_loss: 1.6874 - val_accuracy: 0.5980\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.2531 - accuracy: 0.9084 - val_loss: 1.9660 - val_accuracy: 0.6120\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.9430 - val_loss: 1.6220 - val_accuracy: 0.6680\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.1539 - accuracy: 0.9505 - val_loss: 1.8636 - val_accuracy: 0.6580\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9455 - val_loss: 1.7592 - val_accuracy: 0.6320\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.1093 - accuracy: 0.9616 - val_loss: 1.6151 - val_accuracy: 0.7380\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0921 - accuracy: 0.9703 - val_loss: 1.8540 - val_accuracy: 0.7060\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0861 - accuracy: 0.9684 - val_loss: 1.3100 - val_accuracy: 0.7560\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 0.9690 - val_loss: 0.9454 - val_accuracy: 0.8220\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 1.0243 - val_accuracy: 0.8100\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9802 - val_loss: 1.2601 - val_accuracy: 0.7980\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9827 - val_loss: 1.2229 - val_accuracy: 0.7820\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 1.2386 - val_accuracy: 0.7860\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0438 - accuracy: 0.9833 - val_loss: 1.2981 - val_accuracy: 0.7840\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 1.3041 - val_accuracy: 0.7860\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 1.2542 - val_accuracy: 0.7880\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.9052 - val_accuracy: 0.8320\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 0.9864 - val_loss: 1.2477 - val_accuracy: 0.7860\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.7598 - val_accuracy: 0.8500\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.6966 - val_accuracy: 0.8580\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0318 - accuracy: 0.9876 - val_loss: 0.9793 - val_accuracy: 0.8060\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 1.1264 - val_accuracy: 0.8020\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 1.1257 - val_accuracy: 0.8200\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 1.4076 - val_accuracy: 0.7960\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.9559 - val_accuracy: 0.8440\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.9783 - val_loss: 1.1497 - val_accuracy: 0.8040\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.8883 - val_accuracy: 0.8360\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9889 - val_loss: 1.1488 - val_accuracy: 0.8100\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.9434 - val_accuracy: 0.8320\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9920 - val_loss: 1.0738 - val_accuracy: 0.8140\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.9498 - val_accuracy: 0.8380\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 1.2067 - val_accuracy: 0.8020\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9901 - val_loss: 0.6093 - val_accuracy: 0.8920\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.8022 - val_accuracy: 0.8520\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.5814 - val_accuracy: 0.8740\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9938 - val_loss: 0.4963 - val_accuracy: 0.8940\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.8097 - val_accuracy: 0.8540\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 1.1862 - val_accuracy: 0.7820\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5111 - val_accuracy: 0.8920\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.9419 - val_accuracy: 0.8300\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.0368 - val_accuracy: 0.8220\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9870 - val_loss: 0.9506 - val_accuracy: 0.8200\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 1.1200 - val_accuracy: 0.8080\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 0.8948 - val_accuracy: 0.8480\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.4506 - val_accuracy: 0.9140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "score = model2.evaluate(x_valid, person_valid)\n",
        "print (score[1])"
      ],
      "metadata": {
        "id": "bDWrgEzZfmG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f04b24-3acb-4cfb-bcc5-5a450d70b230"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4506 - accuracy: 0.9140\n",
            "0.9139999747276306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zSN18XzLfr33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison - Transfer Learning v/s Deep Learning"
      ],
      "metadata": {
        "id": "n1fAjGD9fu1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Niter = 5\n",
        "Eval1 = np.zeros(Niter)\n",
        "Eval2 = np.zeros(Niter)\n",
        "Frac = np.linspace(0,1,Niter)\n",
        "\n",
        "for iter in range(Niter):\n",
        "  subset_size = x_train_pc.shape[0]*(iter+1)//Niter \n",
        "  index = np.random.choice(x_train_pc.shape[0], subset_size, replace=False)\n",
        "  for m in range(5):\n",
        "    model1 = tf.keras.Sequential()\n",
        "\n",
        "    model1.add(tf.keras.layers.Flatten(input_shape=(w,1)))\n",
        "  #   model1.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "    model1.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "#     model1.summary()\n",
        "\n",
        "\n",
        "    model1.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    history1 = model1.fit(x_train_pc[index],\n",
        "           person_train[index],\n",
        "           batch_size= 64,\n",
        "           epochs=50, validation_data=(x_valid_pc, person_valid), verbose=False) \n",
        "    model2 = tf.keras.Sequential()\n",
        "\n",
        "    model2.add(tf.keras.layers.Conv2D(filters=25, kernel_size=(3,3), padding='same', activation='elu', input_shape=(1000,1,22)))\n",
        "    model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "    model2.add(tf.keras.layers.BatchNormalization())\n",
        "    model2.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    #model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(10,25), padding='same', activation=''))\n",
        "    model2.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(3,3), padding='same', activation='elu'))\n",
        "    model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "    model2.add(tf.keras.layers.BatchNormalization())\n",
        "    model2.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model2.add(tf.keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "    model2.add(tf.keras.layers.BatchNormalization())\n",
        "    model2.add(tf.keras.layers.Dropout(0.5))\n",
        "    model2.add(tf.keras.layers.Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "    model2.add(tf.keras.layers.BatchNormalization())\n",
        "    model2.add(tf.keras.layers.Dropout(dropout))  \n",
        "    model2.add(tf.keras.layers.Flatten())\n",
        "    model2.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "#     model2.summary()\n",
        "\n",
        "    model2.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "    history2 = model2.fit(x_train[index],\n",
        "           person_train[index],\n",
        "           batch_size= 64,\n",
        "           epochs=50, validation_data=(x_valid, person_valid), verbose=False)\n",
        "\n",
        "\n",
        "    score1 = model1.evaluate(x_valid_pc, person_valid)\n",
        "    Eval1[iter] +=      score1[1]\n",
        "\n",
        "    score2 = model2.evaluate(x_valid, person_valid)\n",
        "    Eval2[iter] +=      score2[1]  \n",
        "\n",
        "Eval1 = Eval1/5\n",
        "Eval2 = Eval2/5\n",
        "\n",
        "Frac = np.linspace(0,1,Niter)\n"
      ],
      "metadata": {
        "id": "LFAUn2OCfvg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d10baba8-74b8-421a-ab7b-2a1035b1bcf0"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0494 - accuracy: 0.6260\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.2941 - accuracy: 0.3500\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0228 - accuracy: 0.6340\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1875 - accuracy: 0.4740\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0771 - accuracy: 0.6460\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.6413 - accuracy: 0.5140\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1024 - accuracy: 0.6460\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3.2738 - accuracy: 0.4540\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.6220\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.1460 - accuracy: 0.5440\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.7940\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2.5986 - accuracy: 0.6200\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.7660\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4022 - accuracy: 0.7000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.7600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.2250 - accuracy: 0.7320\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7640\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4893 - accuracy: 0.6880\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.7740\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.7536 - accuracy: 0.6940\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7900\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.9545 - accuracy: 0.7320\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.7800\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.7840\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.8040\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8376 - accuracy: 0.8120\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.8060\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.5149 - accuracy: 0.7120\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.7920\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.0526 - accuracy: 0.7900\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8080\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7655 - accuracy: 0.8160\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8340\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.8540\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8160\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.5187 - accuracy: 0.7980\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8220\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.6875 - accuracy: 0.7600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8420\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8104 - accuracy: 0.8260\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8380\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9680 - accuracy: 0.8020\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8520\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.8760\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8320\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8064 - accuracy: 0.8420\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8460\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0582 - accuracy: 0.8100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8380\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8168 - accuracy: 0.8580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46b622e4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot  \n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.xlabel('Portion of data used')\n",
        "pyplot.plot(Frac,Eval1)   \n",
        "\n",
        "pyplot.plot(Frac,Eval2)  \n",
        "pyplot.legend(('Transfer learning','Direct Learning'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "sS_hpiLf1ORa",
        "outputId": "50c2a4b4-6248-4deb-87e7-35368fccc2ee"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46be04ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eXnLdujA4Xfc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}